{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "L5rfZ_hYaQ1Z"
   },
   "source": [
    "<img src=\"http://www.exalumnos.usm.cl/wp-content/uploads/2015/06/Isotipo-Negro.gif\" title=\"Title text\" width=\"30%\" />\n",
    "\n",
    "<hr style=\"height:2px;border:none\"/>\n",
    "<h1 align='center'> INF-395/477 Redes Neuronales Artificiales I-2020 </h1>\n",
    "\n",
    "<H3 align='center'> Tarea 1 - Redes Neuronales y *Deep Learning* </H3>\n",
    "<hr style=\"height:2px;border:none\"/>\n",
    "\n",
    "**Temas**  \n",
    "\n",
    "* Arquitectura Básica de Redes Neuronales. Redes *Feed-Forward*\n",
    "* Entrenamiento de Redes Neuronales. \n",
    "* Redes Convolucionales. \n",
    "\n",
    "**Formalidades**  \n",
    "* Equipos de trabajo de: 3 personas (*cada uno debe estar en condiciones de realizar una presentación y discutir sobre cada punto del trabajo realizado*)\n",
    "* Formato de entrega: envı́o de link Github y link de video Youtube o plataforma a convenir, todo esto vía Aula. \n",
    "\n",
    "<hr style=\"height:2px;border:none\"/>\n",
    "\n",
    "### **Propuesta**\n",
    "* Se debe preparar una presentación de **15 a 20 minutos** donde se explique el cómo se va a realizar/resolver el taller, la metodología o propuesta de las componentes a experimentar y explorar. Más detalles en el Syllabus.\n",
    "* Fecha de encuentro Zoom: 8 de Mayo en horario de clases.\n",
    "* Fecha de entrega de vídeo: Opcional para quienes presentaron y obligatorio para quienes no, a lo más 2 días después del encuentro.\n",
    "* Modalidad de Presentación (Zoom): En el primer bloque, se formarán 3 grupos para que alcancen a recibir feedback todos los equipos. En el segundo bloque, algunos equipos seleccionados presentarán a todo el curso. \n",
    "\n",
    "**Aún si la idea es aprender colaborativamente, valoraremos mucho la diversidad de ideas, por lo que las propuesta debiesen conservar su orientación inicial, excepto por el feedback que les entreguemos**\n",
    "\n",
    "### **Defensa**\n",
    "* Se debe preparar una presentación de **15 a 20 minutos** con los resultados obtenidos y conclusiones de la experiencia. \n",
    "* Se debe entregar el código, de preferencia en un (breve) Jupyter/IPython notebook, de modo que **permita reproducir los resultados** presentados. Si se entrega el código fuente se deben proveer instrucciones para su uso.\n",
    "* Fecha de encuentro Zoom: 29 de Mayo, horario de clases.\n",
    "* Fecha de entrega de vídeo: 27 de Mayo (2 días antes de encuentro).\n",
    "* Fecha de entrega de Jypter (notebook): 27 de Mayo (commits hasta el 29 de Mayo en horario de clases). \n",
    "* Modalidad de Presentación (Zoom): En ambos bloques algunos equipos seleccionados presentarán ante todo el curso, discusión y debate se generará en base a los resultados.\n",
    "\n",
    "<hr style=\"height:2px;border:none\"/>\n",
    "\n",
    "La tarea se divide en secciones:\n",
    "\n",
    "[1.](#primero) Pregunta Libre   \n",
    "[2.](#segundo) Challenge Kaggle\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "fTkbRyusPMok"
   },
   "source": [
    "#### <a id=\"primero\"></a>\n",
    "## 1. Pregunta Libre\n",
    "\n",
    "Refute o evidencie experimentalmente una de las siguientes afirmaciones \n",
    "\n",
    "> **1. Rol de la Profundidad**: Si se toma una arquitectura base cualquiera, $A$, de red neuronal y se añade una capa, $A^{+1}$, siempre se mejorará la tarea objetivo en el conjunto de entrenamiento, validación y pruebas. Eso no depende de la forma de entrenar.\n",
    "\n",
    "R: ¿Que pasa si agrego capas con una neurona?\n",
    "\n",
    "> **2. Teorema de approx. universal**: Una arquitectura de red neuronal tiene la capacidad de aproximar cualquier función y esto es independiente del número de neuronas o capas.\n",
    "\n",
    "R: El detalle, es que la red neuronal tiene la capacidad de aproximar solo funciones **continuas**\n",
    "\n",
    "> **3. Rol de la Profundidad**: Si se toma una arquitectura base $A$ con $n$ neuronas y $L$ capas, y se redistribuyen las neuronas aumentando $L$, será posible aprender mejor y más rápido la tarea. \n",
    "\n",
    "R:\n",
    "\n",
    "> **4. Convergencia**: Con la suficiente cantidad de iteraciones, una red neuronal siempre podrá converger algun mínimo local. El tiempo que tarda es independiente de la tasa de aprendizaje y el tamaño de batch.\n",
    "\n",
    "> **5. Convergencia (2)**: La velocidad de aprendizaje es independiente de la función de activación que se utilice en las capas ocultas y del número de ejemplos de entrenamiento. \n",
    "\n",
    "> **6. Approx universal y tolerancia a ruido**: Una red neuronal tiene la capacidad de aprender en el conjunto entrenado, incluso si el *target* (objetivo de la tarea) es aleatorio. Si el porcentaje de etiquetas corruptas  (por ejemplo con un *shift* o *shuffle* sobre $y$) es pequeño, la red aprende la tarea correcta.\n",
    "\n",
    "> **7. Arquitectura y parámetros de CNN**: Una red convolucional siempre tendrá menor cantidad de parámetros que una red *Feed Forward*, por ende, su desempeño en la tarea estará limitado.\n",
    "\n",
    "> **8. Ventajas de una CNN**: En cualquier problema que se tenga estructura espacial (uni-dimensional como texto o bi-dimensional como imágenes), una red neuronal con arquitectura convolucional será la más **adecuada** para resolverlo.\n",
    "\n",
    "> **9. Aplicaciones de una CNN**: No resulta ventajoso aplicar una red con arquitectura convolucional en problemas de regresión. \n",
    "\n",
    "> **10. Aplicaciones de una NN**: Las redes neuroanles no se aplican correctamente a problemas multi-label.\n",
    "\n",
    "> **11. Limitaciones de una NN**: El desbalanceo de las clases no tiene ningún efecto en el entrenamiento de la red.\n",
    "\n",
    "**Reglas mínimas**: Validar en al menos 1 dataset sintético y 2 reales.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## XOR Example"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n",
      "D:\\Anaconda3\\lib\\site-packages\\tensorflow\\python\\framework\\dtypes.py:516: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint8 = np.dtype([(\"qint8\", np.int8, 1)])\n",
      "D:\\Anaconda3\\lib\\site-packages\\tensorflow\\python\\framework\\dtypes.py:517: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_quint8 = np.dtype([(\"quint8\", np.uint8, 1)])\n",
      "D:\\Anaconda3\\lib\\site-packages\\tensorflow\\python\\framework\\dtypes.py:518: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint16 = np.dtype([(\"qint16\", np.int16, 1)])\n",
      "D:\\Anaconda3\\lib\\site-packages\\tensorflow\\python\\framework\\dtypes.py:519: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_quint16 = np.dtype([(\"quint16\", np.uint16, 1)])\n",
      "D:\\Anaconda3\\lib\\site-packages\\tensorflow\\python\\framework\\dtypes.py:520: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint32 = np.dtype([(\"qint32\", np.int32, 1)])\n",
      "D:\\Anaconda3\\lib\\site-packages\\tensorflow\\python\\framework\\dtypes.py:525: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  np_resource = np.dtype([(\"resource\", np.ubyte, 1)])\n",
      "D:\\Anaconda3\\lib\\site-packages\\tensorboard\\compat\\tensorflow_stub\\dtypes.py:541: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint8 = np.dtype([(\"qint8\", np.int8, 1)])\n",
      "D:\\Anaconda3\\lib\\site-packages\\tensorboard\\compat\\tensorflow_stub\\dtypes.py:542: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_quint8 = np.dtype([(\"quint8\", np.uint8, 1)])\n",
      "D:\\Anaconda3\\lib\\site-packages\\tensorboard\\compat\\tensorflow_stub\\dtypes.py:543: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint16 = np.dtype([(\"qint16\", np.int16, 1)])\n",
      "D:\\Anaconda3\\lib\\site-packages\\tensorboard\\compat\\tensorflow_stub\\dtypes.py:544: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_quint16 = np.dtype([(\"quint16\", np.uint16, 1)])\n",
      "D:\\Anaconda3\\lib\\site-packages\\tensorboard\\compat\\tensorflow_stub\\dtypes.py:545: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint32 = np.dtype([(\"qint32\", np.int32, 1)])\n",
      "D:\\Anaconda3\\lib\\site-packages\\tensorboard\\compat\\tensorflow_stub\\dtypes.py:550: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  np_resource = np.dtype([(\"resource\", np.ubyte, 1)])\n"
     ]
    }
   ],
   "source": [
    "import io\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.dates as mdates\n",
    "from datetime import datetime\n",
    "\n",
    "from sklearn import metrics\n",
    "from sklearn.model_selection import train_test_split\n",
    "from keras.models import Sequential\n",
    "from keras.layers.core import Dense, Dropout, Activation\n",
    "from keras.optimizers import SGD\n",
    "from sklearn.metrics import mean_squared_error\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "from matplotlib import pyplot as plt\n",
    "import numpy as np\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def ANN_regresion_nN(X, y, input_dim, neurons=2, layers=1, activation='relu', epochs=10, batch_size=100, verbose=2):\n",
    "    \n",
    "    X_train, X_test, y_train, y_test = train_test_split(X, y, test_size = 0.20, random_state = 0)\n",
    "    \n",
    "    scaler = MinMaxScaler((-1,1))\n",
    "    X_train_scaled = scaler.fit_transform(X_train)\n",
    "    X_test_scaled = scaler.transform(X_test)\n",
    "    \n",
    "    model = Sequential()\n",
    "    neurons = int(np.round(neurons/layers)) if neurons > 1 else 1\n",
    "    model.add(Dense(units=neurons, input_dim=input_dim, activation='relu'))\n",
    "    for i in range(layers-1):\n",
    "        model.add(Dense(units=neurons, activation='relu'))\n",
    "    model.add(Dense(units=1, activation='sigmoid'))\n",
    "    \n",
    "    model.compile(loss='binary_crossentropy', optimizer='adam', metrics=['accuracy'])\n",
    "    model.fit(X_train, y_train, epochs=epochs, batch_size=batch_size, verbose=verbose)\n",
    "    \n",
    "    y_pred = model.predict(X_test, batch_size = batch_size)\n",
    "    y_pred = (y_pred > 0.5)\n",
    "    \n",
    "    y_hat = model.predict(x)\n",
    "    print(model.evaluate(x, y, verbose=0)[1])    \n",
    "    return y_pred, y_test\n",
    "\n",
    "def ANN_regresion_nlayer(X, y, input_dim, layers, neurons=2 , activation='relu', epochs=10, batch_size=100, verbose=2):\n",
    "    \n",
    "    X_train, X_test, y_train, y_test = train_test_split(X, y, test_size = 0.20, random_state = 0)\n",
    "    \n",
    "    scaler = MinMaxScaler((-1,1))\n",
    "    X_train_scaled = scaler.fit_transform(X_train)\n",
    "    X_test_scaled = scaler.transform(X_test)\n",
    "    \n",
    "    model = Sequential()\n",
    "    model.add(Dense(units=neurons, input_dim=input_dim, activation='relu'))\n",
    "    for i in range(layers-1):\n",
    "        model.add(Dense(units=neurons, activation='relu'))\n",
    "    model.add(Dense(units=1, activation='sigmoid'))\n",
    "    \n",
    "    model.compile(loss='binary_crossentropy', optimizer='adam', metrics=['accuracy'])\n",
    "    model.fit(X_train, y_train, epochs=epochs, batch_size=batch_size, verbose=verbose)\n",
    "    \n",
    "    y_pred = model.predict(X_test, batch_size = batch_size)\n",
    "    y_pred = (y_pred > 0.5)\n",
    "    \n",
    "    y_hat = model.predict(x)\n",
    "    print(model.evaluate(x, y, verbose=0)[1])\n",
    "    return y_pred, y_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "matrix size of train set (100000, 2)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "size_train = 100000\n",
    "\n",
    "# Create pair of numbers (a, b)\n",
    "a = np.random.randint(0,2,size_train)[:,np.newaxis]\n",
    "b = np.random.randint(0,2,size_train)[:,np.newaxis]\n",
    "# Label of xor, between a and b \n",
    "y = np.logical_xor(a, b).astype(int)\n",
    "x = np.concatenate([a,b], axis=1)\n",
    "print(f'matrix size of train set {x.shape}\\n')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1\n",
      "WARNING:tensorflow:From D:\\Anaconda3\\lib\\site-packages\\tensorflow\\python\\ops\\nn_impl.py:180: add_dispatch_support.<locals>.wrapper (from tensorflow.python.ops.array_ops) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Use tf.where in 2.0, which has the same broadcast rule as np.where\n",
      "WARNING:tensorflow:From D:\\Anaconda3\\lib\\site-packages\\keras\\backend\\tensorflow_backend.py:422: The name tf.global_variables is deprecated. Please use tf.compat.v1.global_variables instead.\n",
      "\n",
      "Epoch 1/10\n",
      "80000/80000 [==============================] - 3s 42us/step - loss: 0.7224 - accuracy: 0.5007\n",
      "Epoch 2/10\n",
      "80000/80000 [==============================] - 3s 36us/step - loss: 0.6936 - accuracy: 0.5005\n",
      "Epoch 3/10\n",
      "80000/80000 [==============================] - 3s 35us/step - loss: 0.6606 - accuracy: 0.6047\n",
      "Epoch 4/10\n",
      "80000/80000 [==============================] - 3s 35us/step - loss: 0.5567 - accuracy: 0.7492\n",
      "Epoch 5/10\n",
      "80000/80000 [==============================] - 3s 37us/step - loss: 0.5076 - accuracy: 0.7492\n",
      "Epoch 6/10\n",
      "80000/80000 [==============================] - 3s 37us/step - loss: 0.4913 - accuracy: 0.7492\n",
      "Epoch 7/10\n",
      "80000/80000 [==============================] - 3s 36us/step - loss: 0.4851 - accuracy: 0.7492\n",
      "Epoch 8/10\n",
      "80000/80000 [==============================] - ETA: 0s - loss: 0.4825 - accuracy: 0.74 - 3s 37us/step - loss: 0.4823 - accuracy: 0.7492\n",
      "Epoch 9/10\n",
      "80000/80000 [==============================] - 3s 36us/step - loss: 0.4808 - accuracy: 0.7492\n",
      "Epoch 10/10\n",
      "80000/80000 [==============================] - 3s 36us/step - loss: 0.4800 - accuracy: 0.7492\n",
      "0.749750018119812\n",
      "score: 75.32551436238943%\n",
      "2\n",
      "Epoch 1/10\n",
      "80000/80000 [==============================] - 3s 39us/step - loss: 0.7069 - accuracy: 0.5344\n",
      "Epoch 2/10\n",
      "80000/80000 [==============================] - 3s 36us/step - loss: 0.5902 - accuracy: 0.7492\n",
      "Epoch 3/10\n",
      "80000/80000 [==============================] - 3s 35us/step - loss: 0.5225 - accuracy: 0.7492\n",
      "Epoch 4/10\n",
      "80000/80000 [==============================] - 4s 44us/step - loss: 0.4970 - accuracy: 0.7492\n",
      "Epoch 5/10\n",
      "80000/80000 [==============================] - 3s 35us/step - loss: 0.4876 - accuracy: 0.7492\n",
      "Epoch 6/10\n",
      "80000/80000 [==============================] - 3s 34us/step - loss: 0.4835 - accuracy: 0.7492\n",
      "Epoch 7/10\n",
      "80000/80000 [==============================] - 3s 34us/step - loss: 0.4814 - accuracy: 0.7492\n",
      "Epoch 8/10\n",
      "80000/80000 [==============================] - 3s 34us/step - loss: 0.4803 - accuracy: 0.7492\n",
      "Epoch 9/10\n",
      "80000/80000 [==============================] - 3s 34us/step - loss: 0.4797 - accuracy: 0.7492\n",
      "Epoch 10/10\n",
      "80000/80000 [==============================] - 3s 34us/step - loss: 0.4793 - accuracy: 0.7492\n",
      "0.749750018119812\n",
      "score: 75.32551436238943%\n",
      "3\n",
      "Epoch 1/10\n",
      "80000/80000 [==============================] - 3s 37us/step - loss: 0.6285 - accuracy: 0.5358\n",
      "Epoch 2/10\n",
      "80000/80000 [==============================] - 3s 34us/step - loss: 0.4341 - accuracy: 0.7507\n",
      "Epoch 3/10\n",
      "80000/80000 [==============================] - 3s 34us/step - loss: 0.3743 - accuracy: 0.7512\n",
      "Epoch 4/10\n",
      "80000/80000 [==============================] - 3s 34us/step - loss: 0.3577 - accuracy: 0.7512\n",
      "Epoch 5/10\n",
      "80000/80000 [==============================] - 3s 34us/step - loss: 0.3518 - accuracy: 0.7512\n",
      "Epoch 6/10\n",
      "80000/80000 [==============================] - 3s 34us/step - loss: 0.3492 - accuracy: 0.7512\n",
      "Epoch 7/10\n",
      "80000/80000 [==============================] - 3s 35us/step - loss: 0.3480 - accuracy: 0.7502\n",
      "Epoch 8/10\n",
      "80000/80000 [==============================] - 3s 34us/step - loss: 0.3473 - accuracy: 0.7503\n",
      "Epoch 9/10\n",
      "80000/80000 [==============================] - 3s 34us/step - loss: 0.3469 - accuracy: 0.7502\n",
      "Epoch 10/10\n",
      "80000/80000 [==============================] - 3s 35us/step - loss: 0.3466 - accuracy: 0.7500\n",
      "0.7513800263404846\n",
      "score: 75.0427608411309%\n",
      "4\n",
      "Epoch 1/10\n",
      "80000/80000 [==============================] - 3s 38us/step - loss: 0.6274 - accuracy: 0.5406\n",
      "Epoch 2/10\n",
      "80000/80000 [==============================] - 3s 35us/step - loss: 0.4165 - accuracy: 0.9865\n",
      "Epoch 3/10\n",
      "80000/80000 [==============================] - 3s 35us/step - loss: 0.1951 - accuracy: 1.0000\n",
      "Epoch 4/10\n",
      "80000/80000 [==============================] - 3s 35us/step - loss: 0.0888 - accuracy: 1.0000\n",
      "Epoch 5/10\n",
      "80000/80000 [==============================] - 3s 35us/step - loss: 0.0474 - accuracy: 1.0000\n",
      "Epoch 6/10\n",
      "80000/80000 [==============================] - 3s 35us/step - loss: 0.0281 - accuracy: 1.0000\n",
      "Epoch 7/10\n",
      "80000/80000 [==============================] - 3s 35us/step - loss: 0.0177 - accuracy: 1.0000\n",
      "Epoch 8/10\n",
      "80000/80000 [==============================] - 3s 35us/step - loss: 0.0116 - accuracy: 1.0000\n",
      "Epoch 9/10\n",
      "80000/80000 [==============================] - 3s 34us/step - loss: 0.0079 - accuracy: 1.0000\n",
      "Epoch 10/10\n",
      "80000/80000 [==============================] - 3s 35us/step - loss: 0.0054 - accuracy: 1.0000\n",
      "1.0\n",
      "score: 100.0%\n",
      "5\n",
      "Epoch 1/10\n",
      "80000/80000 [==============================] - 3s 36us/step - loss: 0.5812 - accuracy: 0.6416\n",
      "Epoch 2/10\n",
      "80000/80000 [==============================] - 3s 35us/step - loss: 0.4133 - accuracy: 0.7502\n",
      "Epoch 3/10\n",
      "80000/80000 [==============================] - 3s 35us/step - loss: 0.3669 - accuracy: 0.7502\n",
      "Epoch 4/10\n",
      "80000/80000 [==============================] - 3s 35us/step - loss: 0.3549 - accuracy: 0.7512\n",
      "Epoch 5/10\n",
      "80000/80000 [==============================] - 3s 35us/step - loss: 0.3506 - accuracy: 0.7507\n",
      "Epoch 6/10\n",
      "80000/80000 [==============================] - 3s 35us/step - loss: 0.3486 - accuracy: 0.7498\n",
      "Epoch 7/10\n",
      "80000/80000 [==============================] - 3s 35us/step - loss: 0.3476 - accuracy: 0.7510\n",
      "Epoch 8/10\n",
      "80000/80000 [==============================] - 3s 35us/step - loss: 0.3471 - accuracy: 0.7496\n",
      "Epoch 9/10\n",
      "80000/80000 [==============================] - 3s 35us/step - loss: 0.3468 - accuracy: 0.7515\n",
      "Epoch 10/10\n",
      "80000/80000 [==============================] - 3s 34us/step - loss: 0.3466 - accuracy: 0.7504\n",
      "0.7513800263404846\n",
      "score: 75.0427608411309%\n",
      "6\n",
      "Epoch 1/10\n",
      "80000/80000 [==============================] - 3s 38us/step - loss: 0.5811 - accuracy: 0.8388\n",
      "Epoch 2/10\n",
      "80000/80000 [==============================] - 3s 36us/step - loss: 0.2843 - accuracy: 1.0000\n",
      "Epoch 3/10\n",
      "80000/80000 [==============================] - 3s 35us/step - loss: 0.1320 - accuracy: 1.0000\n",
      "Epoch 4/10\n",
      "80000/80000 [==============================] - 3s 35us/step - loss: 0.0694 - accuracy: 1.0000\n",
      "Epoch 5/10\n",
      "80000/80000 [==============================] - 3s 35us/step - loss: 0.0405 - accuracy: 1.0000\n",
      "Epoch 6/10\n",
      "80000/80000 [==============================] - 3s 35us/step - loss: 0.0252 - accuracy: 1.0000\n",
      "Epoch 7/10\n",
      "80000/80000 [==============================] - 3s 35us/step - loss: 0.0164 - accuracy: 1.0000\n",
      "Epoch 8/10\n",
      "80000/80000 [==============================] - 3s 35us/step - loss: 0.0109 - accuracy: 1.0000\n",
      "Epoch 9/10\n",
      "80000/80000 [==============================] - 3s 36us/step - loss: 0.0074 - accuracy: 1.0000\n",
      "Epoch 10/10\n",
      "80000/80000 [==============================] - 3s 35us/step - loss: 0.0051 - accuracy: 1.0000\n",
      "1.0\n",
      "score: 100.0%\n",
      "7\n",
      "Epoch 1/10\n",
      "80000/80000 [==============================] - 3s 39us/step - loss: 0.6867 - accuracy: 0.6125\n",
      "Epoch 2/10\n",
      "80000/80000 [==============================] - 3s 35us/step - loss: 0.5890 - accuracy: 0.7492\n",
      "Epoch 3/10\n",
      "80000/80000 [==============================] - 3s 35us/step - loss: 0.5243 - accuracy: 0.7492\n",
      "Epoch 4/10\n",
      "80000/80000 [==============================] - 3s 35us/step - loss: 0.4982 - accuracy: 0.7492\n",
      "Epoch 5/10\n",
      "80000/80000 [==============================] - 3s 35us/step - loss: 0.4882 - accuracy: 0.7492\n",
      "Epoch 6/10\n",
      "80000/80000 [==============================] - 3s 35us/step - loss: 0.4839 - accuracy: 0.7492\n",
      "Epoch 7/10\n",
      "80000/80000 [==============================] - 3s 35us/step - loss: 0.4817 - accuracy: 0.7492\n",
      "Epoch 8/10\n",
      "80000/80000 [==============================] - 3s 36us/step - loss: 0.4805 - accuracy: 0.7492\n",
      "Epoch 9/10\n",
      "80000/80000 [==============================] - 3s 35us/step - loss: 0.4798 - accuracy: 0.7492\n",
      "Epoch 10/10\n",
      "80000/80000 [==============================] - 3s 35us/step - loss: 0.4794 - accuracy: 0.7492\n",
      "0.749750018119812\n",
      "score: 75.32551436238943%\n",
      "8\n",
      "Epoch 1/10\n",
      "80000/80000 [==============================] - 3s 37us/step - loss: 0.5286 - accuracy: 0.9011\n",
      "Epoch 2/10\n",
      "80000/80000 [==============================] - 3s 35us/step - loss: 0.2317 - accuracy: 1.0000\n",
      "Epoch 3/10\n",
      "80000/80000 [==============================] - 3s 34us/step - loss: 0.0820 - accuracy: 1.0000\n",
      "Epoch 4/10\n",
      "80000/80000 [==============================] - 3s 35us/step - loss: 0.0247 - accuracy: 1.0000\n",
      "Epoch 5/10\n",
      "80000/80000 [==============================] - 3s 34us/step - loss: 0.0101 - accuracy: 1.0000\n",
      "Epoch 6/10\n",
      "80000/80000 [==============================] - 3s 35us/step - loss: 0.0052 - accuracy: 1.0000\n",
      "Epoch 7/10\n",
      "80000/80000 [==============================] - 3s 35us/step - loss: 0.0029 - accuracy: 1.0000\n",
      "Epoch 8/10\n",
      "80000/80000 [==============================] - 3s 35us/step - loss: 0.0017 - accuracy: 1.0000\n",
      "Epoch 9/10\n",
      "80000/80000 [==============================] - 3s 35us/step - loss: 0.0010 - accuracy: 1.0000\n",
      "Epoch 10/10\n",
      "80000/80000 [==============================] - 3s 34us/step - loss: 6.1140e-04 - accuracy: 1.0000\n",
      "1.0\n",
      "score: 100.0%\n",
      "9\n",
      "Epoch 1/10\n",
      "80000/80000 [==============================] - 3s 39us/step - loss: 0.5781 - accuracy: 0.9514\n",
      "Epoch 2/10\n",
      "80000/80000 [==============================] - 3s 39us/step - loss: 0.2998 - accuracy: 1.0000\n",
      "Epoch 3/10\n",
      "80000/80000 [==============================] - 3s 36us/step - loss: 0.1229 - accuracy: 1.0000\n",
      "Epoch 4/10\n",
      "80000/80000 [==============================] - 3s 35us/step - loss: 0.0524 - accuracy: 1.0000\n",
      "Epoch 5/10\n",
      "80000/80000 [==============================] - 3s 36us/step - loss: 0.0250 - accuracy: 1.0000\n",
      "Epoch 6/10\n",
      "80000/80000 [==============================] - 3s 36us/step - loss: 0.0131 - accuracy: 1.0000\n",
      "Epoch 7/10\n",
      "80000/80000 [==============================] - 3s 36us/step - loss: 0.0072 - accuracy: 1.0000\n",
      "Epoch 8/10\n",
      "80000/80000 [==============================] - 3s 36us/step - loss: 0.0042 - accuracy: 1.0000\n",
      "Epoch 9/10\n",
      "80000/80000 [==============================] - 3s 36us/step - loss: 0.0025 - accuracy: 1.0000\n",
      "Epoch 10/10\n",
      "80000/80000 [==============================] - 3s 36us/step - loss: 0.0015 - accuracy: 1.0000\n",
      "1.0\n",
      "score: 100.0%\n"
     ]
    }
   ],
   "source": [
    "y_pred_list_1layer = []\n",
    "for i in range(1,10):\n",
    "    print(i)\n",
    "    y_predict, y_test = ANN_regresion_nlayer(x, y, x.shape[1], layers=1, neurons=i , activation='relu', epochs=10, batch_size=100, verbose=1)\n",
    "    score = metrics.roc_auc_score(y_test, y_predict)\n",
    "    \n",
    "    print(f'score: {score*100}%')\n",
    "    y_pred_list_1layer.append(score)\n",
    " "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1\n",
      "Epoch 1/10\n",
      "80000/80000 [==============================] - 3s 37us/step - loss: 0.4010 - accuracy: 0.9281\n",
      "Epoch 2/10\n",
      "80000/80000 [==============================] - 3s 38us/step - loss: 0.0772 - accuracy: 1.0000\n",
      "Epoch 3/10\n",
      "80000/80000 [==============================] - 3s 36us/step - loss: 0.0201 - accuracy: 1.0000\n",
      "Epoch 4/10\n",
      "80000/80000 [==============================] - 3s 35us/step - loss: 0.0078 - accuracy: 1.0000\n",
      "Epoch 5/10\n",
      "80000/80000 [==============================] - 3s 35us/step - loss: 0.0037 - accuracy: 1.0000\n",
      "Epoch 6/10\n",
      "80000/80000 [==============================] - 3s 36us/step - loss: 0.0019 - accuracy: 1.0000\n",
      "Epoch 7/10\n",
      "80000/80000 [==============================] - 3s 35us/step - loss: 0.0011 - accuracy: 1.0000\n",
      "Epoch 8/10\n",
      "80000/80000 [==============================] - 3s 36us/step - loss: 6.3791e-04 - accuracy: 1.0000\n",
      "Epoch 9/10\n",
      "80000/80000 [==============================] - 3s 35us/step - loss: 3.8338e-04 - accuracy: 1.0000\n",
      "Epoch 10/10\n",
      "80000/80000 [==============================] - 3s 36us/step - loss: 2.3470e-04 - accuracy: 1.0000\n",
      "1.0\n",
      "score: 100.0%\n",
      "2\n",
      "Epoch 1/10\n",
      "80000/80000 [==============================] - 3s 43us/step - loss: 0.4383 - accuracy: 0.8402\n",
      "Epoch 2/10\n",
      "80000/80000 [==============================] - 3s 41us/step - loss: 0.0263 - accuracy: 1.0000\n",
      "Epoch 3/10\n",
      "80000/80000 [==============================] - 3s 41us/step - loss: 0.0045 - accuracy: 1.0000\n",
      "Epoch 4/10\n",
      "80000/80000 [==============================] - 3s 41us/step - loss: 0.0016 - accuracy: 1.0000\n",
      "Epoch 5/10\n",
      "80000/80000 [==============================] - 3s 41us/step - loss: 7.4085e-04 - accuracy: 1.0000\n",
      "Epoch 6/10\n",
      "80000/80000 [==============================] - 3s 41us/step - loss: 3.8469e-04 - accuracy: 1.0000\n",
      "Epoch 7/10\n",
      "80000/80000 [==============================] - 3s 41us/step - loss: 2.1362e-04 - accuracy: 1.0000\n",
      "Epoch 8/10\n",
      "80000/80000 [==============================] - 3s 41us/step - loss: 1.2393e-04 - accuracy: 1.0000\n",
      "Epoch 9/10\n",
      "80000/80000 [==============================] - 3s 40us/step - loss: 7.3966e-05 - accuracy: 1.0000\n",
      "Epoch 10/10\n",
      "80000/80000 [==============================] - 3s 41us/step - loss: 4.4944e-05 - accuracy: 1.0000\n",
      "1.0\n",
      "score: 100.0%\n",
      "3\n",
      "Epoch 1/10\n",
      "80000/80000 [==============================] - 4s 48us/step - loss: 0.3426 - accuracy: 0.8960\n",
      "Epoch 2/10\n",
      "80000/80000 [==============================] - 4s 44us/step - loss: 0.0267 - accuracy: 1.0000\n",
      "Epoch 3/10\n",
      "80000/80000 [==============================] - 4s 44us/step - loss: 0.0065 - accuracy: 1.0000\n",
      "Epoch 4/10\n",
      "80000/80000 [==============================] - 3s 44us/step - loss: 0.0027 - accuracy: 1.0000\n",
      "Epoch 5/10\n",
      "80000/80000 [==============================] - 4s 44us/step - loss: 0.0014 - accuracy: 1.0000\n",
      "Epoch 6/10\n",
      "80000/80000 [==============================] - 3s 44us/step - loss: 7.4248e-04 - accuracy: 1.0000\n",
      "Epoch 7/10\n",
      "80000/80000 [==============================] - 4s 44us/step - loss: 4.2923e-04 - accuracy: 1.0000\n",
      "Epoch 8/10\n",
      "80000/80000 [==============================] - 4s 44us/step - loss: 2.5605e-04 - accuracy: 1.0000\n",
      "Epoch 9/10\n",
      "80000/80000 [==============================] - 3s 44us/step - loss: 1.5591e-04 - accuracy: 1.0000\n",
      "Epoch 10/10\n",
      "80000/80000 [==============================] - 3s 44us/step - loss: 9.6321e-05 - accuracy: 1.0000\n",
      "1.0\n",
      "score: 100.0%\n",
      "4\n",
      "Epoch 1/10\n",
      "80000/80000 [==============================] - 4s 54us/step - loss: 0.3691 - accuracy: 0.9122\n",
      "Epoch 2/10\n",
      "80000/80000 [==============================] - 4s 48us/step - loss: 0.0374 - accuracy: 1.0000\n",
      "Epoch 3/10\n",
      "80000/80000 [==============================] - 4s 48us/step - loss: 0.0087 - accuracy: 1.0000\n",
      "Epoch 4/10\n",
      "80000/80000 [==============================] - 4s 48us/step - loss: 0.0034 - accuracy: 1.0000\n",
      "Epoch 5/10\n",
      "80000/80000 [==============================] - 4s 48us/step - loss: 0.0016 - accuracy: 1.0000\n",
      "Epoch 6/10\n",
      "80000/80000 [==============================] - 4s 48us/step - loss: 8.5785e-04 - accuracy: 1.0000\n",
      "Epoch 7/10\n",
      "80000/80000 [==============================] - 4s 48us/step - loss: 4.8404e-04 - accuracy: 1.0000\n",
      "Epoch 8/10\n",
      "80000/80000 [==============================] - 4s 48us/step - loss: 2.8378e-04 - accuracy: 1.0000\n",
      "Epoch 9/10\n",
      "80000/80000 [==============================] - 4s 48us/step - loss: 1.7063e-04 - accuracy: 1.0000\n",
      "Epoch 10/10\n",
      "80000/80000 [==============================] - 4s 51us/step - loss: 1.0440e-04 - accuracy: 1.0000\n",
      "1.0\n",
      "score: 100.0%\n",
      "5\n",
      "Epoch 1/10\n",
      "80000/80000 [==============================] - 4s 56us/step - loss: 0.3827 - accuracy: 0.9122\n",
      "Epoch 2/10\n",
      "80000/80000 [==============================] - 4s 53us/step - loss: 0.1302 - accuracy: 1.0000\n",
      "Epoch 3/10\n",
      "80000/80000 [==============================] - 4s 52us/step - loss: 0.0760 - accuracy: 1.0000\n",
      "Epoch 4/10\n",
      "80000/80000 [==============================] - 4s 53us/step - loss: 0.0480 - accuracy: 1.0000\n",
      "Epoch 5/10\n",
      "80000/80000 [==============================] - 4s 52us/step - loss: 0.0318 - accuracy: 1.0000\n",
      "Epoch 6/10\n",
      "80000/80000 [==============================] - 4s 53us/step - loss: 0.0216 - accuracy: 1.0000\n",
      "Epoch 7/10\n",
      "80000/80000 [==============================] - 4s 53us/step - loss: 0.0149 - accuracy: 1.0000\n",
      "Epoch 8/10\n",
      "80000/80000 [==============================] - 4s 53us/step - loss: 0.0105 - accuracy: 1.0000\n",
      "Epoch 9/10\n",
      "80000/80000 [==============================] - 4s 52us/step - loss: 0.0074 - accuracy: 1.0000\n",
      "Epoch 10/10\n",
      "80000/80000 [==============================] - 4s 52us/step - loss: 0.0052 - accuracy: 1.0000\n",
      "1.0\n",
      "score: 100.0%\n",
      "6\n",
      "Epoch 1/10\n",
      "80000/80000 [==============================] - 5s 60us/step - loss: 0.5823 - accuracy: 0.6887\n",
      "Epoch 2/10\n",
      "80000/80000 [==============================] - 5s 67us/step - loss: 0.4805 - accuracy: 0.7481\n",
      "Epoch 3/10\n",
      "80000/80000 [==============================] - 5s 65us/step - loss: 0.4793 - accuracy: 0.7481\n",
      "Epoch 4/10\n",
      "80000/80000 [==============================] - 5s 56us/step - loss: 0.4793 - accuracy: 0.7481\n",
      "Epoch 5/10\n",
      "80000/80000 [==============================] - 4s 56us/step - loss: 0.4792 - accuracy: 0.7481\n",
      "Epoch 6/10\n",
      "80000/80000 [==============================] - 4s 56us/step - loss: 0.4792 - accuracy: 0.7481\n",
      "Epoch 7/10\n",
      "80000/80000 [==============================] - 4s 56us/step - loss: 0.4792 - accuracy: 0.7481\n",
      "Epoch 8/10\n",
      "80000/80000 [==============================] - 5s 57us/step - loss: 0.4792 - accuracy: 0.7481\n",
      "Epoch 9/10\n",
      "80000/80000 [==============================] - 5s 57us/step - loss: 0.4792 - accuracy: 0.7481\n",
      "Epoch 10/10\n",
      "80000/80000 [==============================] - 5s 57us/step - loss: 0.4792 - accuracy: 0.7481\n",
      "0.7486799955368042\n",
      "score: 74.9572391588691%\n",
      "7\n",
      "Epoch 1/10\n",
      "80000/80000 [==============================] - 6s 69us/step - loss: 0.6932 - accuracy: 0.4993\n",
      "Epoch 2/10\n",
      "80000/80000 [==============================] - 5s 61us/step - loss: 0.6932 - accuracy: 0.4997\n",
      "Epoch 3/10\n",
      "80000/80000 [==============================] - 5s 61us/step - loss: 0.6932 - accuracy: 0.5007\n",
      "Epoch 4/10\n",
      "80000/80000 [==============================] - 5s 61us/step - loss: 0.6932 - accuracy: 0.4987\n",
      "Epoch 5/10\n",
      "80000/80000 [==============================] - 5s 63us/step - loss: 0.6932 - accuracy: 0.5009\n",
      "Epoch 6/10\n",
      "80000/80000 [==============================] - 5s 62us/step - loss: 0.6932 - accuracy: 0.5009\n",
      "Epoch 7/10\n",
      "80000/80000 [==============================] - 5s 62us/step - loss: 0.6932 - accuracy: 0.5004\n",
      "Epoch 8/10\n",
      "80000/80000 [==============================] - 5s 62us/step - loss: 0.6932 - accuracy: 0.4994\n",
      "Epoch 9/10\n",
      "80000/80000 [==============================] - 5s 62us/step - loss: 0.6932 - accuracy: 0.4995\n",
      "Epoch 10/10\n",
      "80000/80000 [==============================] - 5s 61us/step - loss: 0.6932 - accuracy: 0.4984\n",
      "0.49994000792503357\n",
      "score: 50.0%\n",
      "8\n",
      "Epoch 1/10\n",
      "80000/80000 [==============================] - 6s 77us/step - loss: 0.6932 - accuracy: 0.4958\n",
      "Epoch 2/10\n",
      "80000/80000 [==============================] - 5s 65us/step - loss: 0.6932 - accuracy: 0.5009\n",
      "Epoch 3/10\n",
      "80000/80000 [==============================] - 5s 65us/step - loss: 0.6932 - accuracy: 0.4975\n",
      "Epoch 4/10\n",
      "80000/80000 [==============================] - 5s 65us/step - loss: 0.6932 - accuracy: 0.4988\n",
      "Epoch 5/10\n",
      "80000/80000 [==============================] - 5s 65us/step - loss: 0.6932 - accuracy: 0.5019\n",
      "Epoch 6/10\n",
      "80000/80000 [==============================] - 5s 65us/step - loss: 0.6932 - accuracy: 0.4996\n",
      "Epoch 7/10\n",
      "80000/80000 [==============================] - 5s 65us/step - loss: 0.6932 - accuracy: 0.4975\n",
      "Epoch 8/10\n",
      "80000/80000 [==============================] - 5s 66us/step - loss: 0.6932 - accuracy: 0.5009\n",
      "Epoch 9/10\n",
      "80000/80000 [==============================] - 5s 65us/step - loss: 0.6932 - accuracy: 0.4990\n",
      "Epoch 10/10\n",
      "80000/80000 [==============================] - 5s 65us/step - loss: 0.6932 - accuracy: 0.5012\n",
      "0.49994000792503357\n",
      "score: 50.0%\n",
      "9\n",
      "Epoch 1/10\n",
      "80000/80000 [==============================] - 6s 78us/step - loss: 0.6932 - accuracy: 0.4980\n",
      "Epoch 2/10\n",
      "80000/80000 [==============================] - 6s 70us/step - loss: 0.6932 - accuracy: 0.5025\n",
      "Epoch 3/10\n",
      "80000/80000 [==============================] - 6s 70us/step - loss: 0.6932 - accuracy: 0.4961\n",
      "Epoch 4/10\n",
      "80000/80000 [==============================] - 6s 70us/step - loss: 0.6932 - accuracy: 0.4980\n",
      "Epoch 5/10\n",
      "80000/80000 [==============================] - 6s 69us/step - loss: 0.6932 - accuracy: 0.4995\n",
      "Epoch 6/10\n",
      "80000/80000 [==============================] - 6s 70us/step - loss: 0.6932 - accuracy: 0.4994\n",
      "Epoch 7/10\n",
      "80000/80000 [==============================] - 6s 70us/step - loss: 0.6932 - accuracy: 0.4966\n",
      "Epoch 8/10\n",
      "80000/80000 [==============================] - 6s 70us/step - loss: 0.6932 - accuracy: 0.5000\n",
      "Epoch 9/10\n",
      "80000/80000 [==============================] - 6s 70us/step - loss: 0.6932 - accuracy: 0.4997\n",
      "Epoch 10/10\n",
      "80000/80000 [==============================] - 6s 69us/step - loss: 0.6932 - accuracy: 0.4987\n",
      "0.49994000792503357\n",
      "score: 50.0%\n"
     ]
    }
   ],
   "source": [
    "y_pred_list_nNeuron = []\n",
    "for i in range(1,10):\n",
    "    print(i)\n",
    "    y_predict, y_test = ANN_regresion_nN(x, y, x.shape[1], layers=i, neurons=14 , activation='relu', epochs=10, batch_size=100, verbose=1)\n",
    "    score = metrics.roc_auc_score(y_test, y_predict)\n",
    "    \n",
    "    print(f'score: {score*100}%')\n",
    "    y_pred_list_nNeuron.append(score)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1\n",
      "Epoch 1/10\n",
      "80000/80000 [==============================] - 3s 44us/step - loss: 0.4099 - accuracy: 0.9527\n",
      "Epoch 2/10\n",
      "80000/80000 [==============================] - 3s 41us/step - loss: 0.1245 - accuracy: 1.0000\n",
      "Epoch 3/10\n",
      "80000/80000 [==============================] - 3s 42us/step - loss: 0.0574 - accuracy: 1.0000\n",
      "Epoch 4/10\n",
      "80000/80000 [==============================] - 3s 40us/step - loss: 0.0332 - accuracy: 1.0000\n",
      "Epoch 5/10\n",
      "80000/80000 [==============================] - 3s 40us/step - loss: 0.0210 - accuracy: 1.0000\n",
      "Epoch 6/10\n",
      "80000/80000 [==============================] - 3s 41us/step - loss: 0.0138 - accuracy: 1.0000\n",
      "Epoch 7/10\n",
      "80000/80000 [==============================] - 3s 42us/step - loss: 0.0094 - accuracy: 1.0000\n",
      "Epoch 8/10\n",
      "80000/80000 [==============================] - 3s 43us/step - loss: 0.0064 - accuracy: 1.0000\n",
      "Epoch 9/10\n",
      "80000/80000 [==============================] - 3s 41us/step - loss: 0.0045 - accuracy: 1.0000\n",
      "Epoch 10/10\n",
      "80000/80000 [==============================] - 3s 40us/step - loss: 0.0031 - accuracy: 1.0000\n",
      "1.0\n",
      "score: 100.0%\n",
      "2\n",
      "Epoch 1/10\n",
      "80000/80000 [==============================] - 4s 49us/step - loss: 0.2513 - accuracy: 0.9304\n",
      "Epoch 2/10\n",
      "80000/80000 [==============================] - 4s 48us/step - loss: 0.0056 - accuracy: 1.0000\n",
      "Epoch 3/10\n",
      "80000/80000 [==============================] - 4s 45us/step - loss: 0.0012 - accuracy: 1.0000\n",
      "Epoch 4/10\n",
      "80000/80000 [==============================] - ETA: 0s - loss: 4.6953e-04 - accuracy: 1.00 - 4s 45us/step - loss: 4.6829e-04 - accuracy: 1.0000\n",
      "Epoch 5/10\n",
      "80000/80000 [==============================] - 4s 45us/step - loss: 2.2337e-04 - accuracy: 1.0000\n",
      "Epoch 6/10\n",
      "80000/80000 [==============================] - 4s 45us/step - loss: 1.1839e-04 - accuracy: 1.0000\n",
      "Epoch 7/10\n",
      "80000/80000 [==============================] - 4s 46us/step - loss: 6.6669e-05 - accuracy: 1.0000\n",
      "Epoch 8/10\n",
      "80000/80000 [==============================] - 4s 45us/step - loss: 3.8975e-05 - accuracy: 1.0000\n",
      "Epoch 9/10\n",
      "80000/80000 [==============================] - 4s 45us/step - loss: 2.3354e-05 - accuracy: 1.0000\n",
      "Epoch 10/10\n",
      "80000/80000 [==============================] - 4s 45us/step - loss: 1.4236e-05 - accuracy: 1.0000\n",
      "1.0\n",
      "score: 100.0%\n",
      "3\n",
      "Epoch 1/10\n",
      "80000/80000 [==============================] - 4s 55us/step - loss: 0.1808 - accuracy: 0.9632\n",
      "Epoch 2/10\n",
      "80000/80000 [==============================] - 4s 49us/step - loss: 9.7516e-04 - accuracy: 1.0000\n",
      "Epoch 3/10\n",
      "80000/80000 [==============================] - 4s 49us/step - loss: 2.3957e-04 - accuracy: 1.0000\n",
      "Epoch 4/10\n",
      "80000/80000 [==============================] - 4s 49us/step - loss: 9.5348e-05 - accuracy: 1.0000\n",
      "Epoch 5/10\n",
      "80000/80000 [==============================] - 4s 50us/step - loss: 4.6267e-05 - accuracy: 1.0000\n",
      "Epoch 6/10\n",
      "80000/80000 [==============================] - 4s 50us/step - loss: 2.4872e-05 - accuracy: 1.0000\n",
      "Epoch 7/10\n",
      "80000/80000 [==============================] - 4s 50us/step - loss: 1.4162e-05 - accuracy: 1.0000\n",
      "Epoch 8/10\n",
      "80000/80000 [==============================] - 4s 49us/step - loss: 8.3551e-06 - accuracy: 1.0000\n",
      "Epoch 9/10\n",
      "80000/80000 [==============================] - 4s 50us/step - loss: 5.0443e-06 - accuracy: 1.0000\n",
      "Epoch 10/10\n",
      "80000/80000 [==============================] - 4s 49us/step - loss: 3.0934e-06 - accuracy: 1.0000\n",
      "1.0\n",
      "score: 100.0%\n",
      "4\n",
      "Epoch 1/10\n",
      "80000/80000 [==============================] - 5s 57us/step - loss: 0.1339 - accuracy: 0.9796\n",
      "Epoch 2/10\n",
      "80000/80000 [==============================] - 4s 53us/step - loss: 2.1245e-04 - accuracy: 1.0000\n",
      "Epoch 3/10\n",
      "80000/80000 [==============================] - 4s 54us/step - loss: 5.2882e-05 - accuracy: 1.0000\n",
      "Epoch 4/10\n",
      "80000/80000 [==============================] - 4s 53us/step - loss: 2.1288e-05 - accuracy: 1.0000\n",
      "Epoch 5/10\n",
      "80000/80000 [==============================] - 4s 54us/step - loss: 1.0356e-05 - accuracy: 1.0000\n",
      "Epoch 6/10\n",
      "80000/80000 [==============================] - 4s 54us/step - loss: 5.5392e-06 - accuracy: 1.0000\n",
      "Epoch 7/10\n",
      "80000/80000 [==============================] - 4s 53us/step - loss: 3.1311e-06 - accuracy: 1.0000\n",
      "Epoch 8/10\n",
      "80000/80000 [==============================] - 4s 53us/step - loss: 1.8326e-06 - accuracy: 1.0000\n",
      "Epoch 9/10\n",
      "80000/80000 [==============================] - 4s 53us/step - loss: 1.0979e-06 - accuracy: 1.0000\n",
      "Epoch 10/10\n",
      "80000/80000 [==============================] - 4s 53us/step - loss: 6.6873e-07 - accuracy: 1.0000\n",
      "1.0\n",
      "score: 100.0%\n",
      "5\n",
      "Epoch 1/10\n",
      "80000/80000 [==============================] - 5s 63us/step - loss: 0.1016 - accuracy: 0.9683\n",
      "Epoch 2/10\n",
      "80000/80000 [==============================] - 5s 57us/step - loss: 1.3892e-05 - accuracy: 1.0000\n",
      "Epoch 3/10\n",
      "80000/80000 [==============================] - 5s 56us/step - loss: 2.4143e-06 - accuracy: 1.0000\n",
      "Epoch 4/10\n",
      "80000/80000 [==============================] - 5s 57us/step - loss: 8.9978e-07 - accuracy: 1.0000\n",
      "Epoch 5/10\n",
      "80000/80000 [==============================] - 5s 56us/step - loss: 4.2956e-07 - accuracy: 1.0000\n",
      "Epoch 6/10\n",
      "80000/80000 [==============================] - 5s 57us/step - loss: 2.2343e-07 - accuracy: 1.0000\n",
      "Epoch 7/10\n",
      "80000/80000 [==============================] - 5s 60us/step - loss: 1.2620e-07 - accuracy: 1.0000\n",
      "Epoch 8/10\n",
      "80000/80000 [==============================] - 5s 57us/step - loss: 7.5225e-08 - accuracy: 1.0000\n",
      "Epoch 9/10\n",
      "80000/80000 [==============================] - 5s 57us/step - loss: 4.5178e-08 - accuracy: 1.0000\n",
      "Epoch 10/10\n",
      "80000/80000 [==============================] - 5s 57us/step - loss: 3.0009e-08 - accuracy: 1.0000\n",
      "1.0\n",
      "score: 100.0%\n",
      "6\n",
      "Epoch 1/10\n",
      "80000/80000 [==============================] - 5s 66us/step - loss: 0.0824 - accuracy: 0.9900\n",
      "Epoch 2/10\n",
      "80000/80000 [==============================] - 5s 61us/step - loss: 5.6327e-05 - accuracy: 1.0000\n",
      "Epoch 3/10\n",
      "80000/80000 [==============================] - 5s 62us/step - loss: 1.2490e-05 - accuracy: 1.0000\n",
      "Epoch 4/10\n",
      "80000/80000 [==============================] - 5s 61us/step - loss: 3.4193e-06 - accuracy: 1.0000\n",
      "Epoch 5/10\n",
      "80000/80000 [==============================] - 5s 62us/step - loss: 1.6777e-06 - accuracy: 1.0000\n",
      "Epoch 6/10\n",
      "80000/80000 [==============================] - 5s 62us/step - loss: 9.0762e-07 - accuracy: 1.0000\n",
      "Epoch 7/10\n",
      "80000/80000 [==============================] - 5s 62us/step - loss: 5.2258e-07 - accuracy: 1.0000\n",
      "Epoch 8/10\n",
      "80000/80000 [==============================] - 5s 65us/step - loss: 3.1348e-07 - accuracy: 1.0000\n",
      "Epoch 9/10\n",
      "80000/80000 [==============================] - 5s 62us/step - loss: 1.9412e-07 - accuracy: 1.0000\n",
      "Epoch 10/10\n",
      "80000/80000 [==============================] - 5s 62us/step - loss: 1.2370e-07 - accuracy: 1.0000\n",
      "1.0\n",
      "score: 100.0%\n",
      "7\n",
      "Epoch 1/10\n",
      "80000/80000 [==============================] - 6s 74us/step - loss: 0.0819 - accuracy: 0.9973\n",
      "Epoch 2/10\n",
      "80000/80000 [==============================] - 5s 67us/step - loss: 8.7666e-05 - accuracy: 1.0000\n",
      "Epoch 3/10\n",
      "80000/80000 [==============================] - 5s 66us/step - loss: 1.8200e-05 - accuracy: 1.0000\n",
      "Epoch 4/10\n",
      "80000/80000 [==============================] - 5s 67us/step - loss: 6.7859e-06 - accuracy: 1.0000\n",
      "Epoch 5/10\n",
      "80000/80000 [==============================] - 5s 67us/step - loss: 3.2291e-06 - accuracy: 1.0000\n",
      "Epoch 6/10\n",
      "80000/80000 [==============================] - 5s 67us/step - loss: 1.7182e-06 - accuracy: 1.0000\n",
      "Epoch 7/10\n",
      "80000/80000 [==============================] - 5s 67us/step - loss: 9.7188e-07 - accuracy: 1.0000\n",
      "Epoch 8/10\n",
      "80000/80000 [==============================] - 5s 67us/step - loss: 5.6762e-07 - accuracy: 1.0000\n",
      "Epoch 9/10\n",
      "80000/80000 [==============================] - 5s 67us/step - loss: 3.4296e-07 - accuracy: 1.0000\n",
      "Epoch 10/10\n",
      "80000/80000 [==============================] - 5s 67us/step - loss: 2.1367e-07 - accuracy: 1.0000\n",
      "1.0\n",
      "score: 100.0%\n",
      "8\n",
      "Epoch 1/10\n",
      "80000/80000 [==============================] - 6s 78us/step - loss: 0.0917 - accuracy: 0.9977\n",
      "Epoch 2/10\n",
      "80000/80000 [==============================] - 6s 71us/step - loss: 1.2688e-05 - accuracy: 1.0000\n",
      "Epoch 3/10\n",
      "80000/80000 [==============================] - 6s 71us/step - loss: 3.1335e-06 - accuracy: 1.0000\n",
      "Epoch 4/10\n",
      "80000/80000 [==============================] - 6s 71us/step - loss: 1.2958e-06 - accuracy: 1.0000\n",
      "Epoch 5/10\n",
      "80000/80000 [==============================] - 6s 74us/step - loss: 6.4884e-07 - accuracy: 1.0000\n",
      "Epoch 6/10\n",
      "80000/80000 [==============================] - 6s 73us/step - loss: 3.5840e-07 - accuracy: 1.0000\n",
      "Epoch 7/10\n",
      "80000/80000 [==============================] - 6s 71us/step - loss: 2.1033e-07 - accuracy: 1.0000\n",
      "Epoch 8/10\n",
      "80000/80000 [==============================] - 6s 70us/step - loss: 1.2622e-07 - accuracy: 1.0000\n",
      "Epoch 9/10\n",
      "80000/80000 [==============================] - 6s 71us/step - loss: 8.4115e-08 - accuracy: 1.0000\n",
      "Epoch 10/10\n",
      "80000/80000 [==============================] - 6s 71us/step - loss: 5.5296e-08 - accuracy: 1.0000\n",
      "1.0\n",
      "score: 100.0%\n",
      "9\n",
      "Epoch 1/10\n",
      "80000/80000 [==============================] - 7s 83us/step - loss: 0.0790 - accuracy: 0.9819\n",
      "Epoch 2/10\n",
      "80000/80000 [==============================] - 6s 76us/step - loss: 1.2717e-05 - accuracy: 1.0000\n",
      "Epoch 3/10\n",
      "80000/80000 [==============================] - 6s 76us/step - loss: 3.9416e-06 - accuracy: 1.0000\n",
      "Epoch 4/10\n",
      "80000/80000 [==============================] - 6s 76us/step - loss: 1.7695e-06 - accuracy: 1.0000\n",
      "Epoch 5/10\n",
      "80000/80000 [==============================] - 6s 76us/step - loss: 9.1409e-07 - accuracy: 1.0000\n",
      "Epoch 6/10\n",
      "80000/80000 [==============================] - 6s 76us/step - loss: 5.1004e-07 - accuracy: 1.0000\n",
      "Epoch 7/10\n",
      "80000/80000 [==============================] - 6s 75us/step - loss: 2.9808e-07 - accuracy: 1.0000\n",
      "Epoch 8/10\n",
      "80000/80000 [==============================] - 6s 75us/step - loss: 1.8000e-07 - accuracy: 1.0000\n",
      "Epoch 9/10\n",
      "80000/80000 [==============================] - 6s 75us/step - loss: 1.1076e-07 - accuracy: 1.0000\n",
      "Epoch 10/10\n",
      "80000/80000 [==============================] - 6s 75us/step - loss: 7.0218e-08 - accuracy: 1.0000\n",
      "1.0\n",
      "score: 100.0%\n"
     ]
    }
   ],
   "source": [
    "y_pred_list_nlayer = []\n",
    "for i in range(1,10):\n",
    "    print(i)\n",
    "    y_predict, y_test = ANN_regresion_nlayer(x, y, x.shape[1], layers=i, neurons=14 , activation='relu', epochs=10, batch_size=100, verbose=1)\n",
    "    score = metrics.roc_auc_score(y_test, y_predict)\n",
    "    \n",
    "    print(f'score: {score*100}%')\n",
    "    y_pred_list_nlayer.append(score)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAXQAAAD4CAYAAAD8Zh1EAAAABHNCSVQICAgIfAhkiAAAAAlwSFlzAAALEgAACxIB0t1+/AAAADh0RVh0U29mdHdhcmUAbWF0cGxvdGxpYiB2ZXJzaW9uMy4xLjMsIGh0dHA6Ly9tYXRwbG90bGliLm9yZy+AADFEAAAQVklEQVR4nO3df6zdd13H8efLtgvdAEvohWztoDMpDQshFm+GumRM52w3yTYgMavBBGKYMYwAas1qDOASgqZEIWFi5oYwhdU5yqxmoSAMUcOwtyujbKVYh7DbTnb5URBpXFvf/nFOx93tbe8522m/p58+H8nNPd/P99Pv97Wbe18793O+33tSVUiSznw/0XUASdJoWOiS1AgLXZIaYaFLUiMsdElqxOKuTrx8+fJatWpVV6eXpDPSzp07v11VE/Pt66zQV61axdTUVFenl6QzUpJvnGifSy6S1AgLXZIaYaFLUiMsdElqhIUuSY2w0CWpERa6JDXCQpekRljoktQIC12SGrHgrf9JPgS8Gni8ql42z/4A7weuBn4EvKGqHhh10GPu2bWfzdv3cuDgIS5YtpSN69Zw3doVp+p05jqLco1jJmkYg/wtlw8DHwDuOMH+q4DV/Y9XAh/sfx65e3btZ9PW3Rw6fBSA/QcPsWnrboBOf/DMdebnGsdM0rAWXHKpqs8D3z3JlGuBO6rnfmBZkvNHFXC2zdv3PvkDd8yhw0fZvH3vqTjdwMw1nHHMNY6ZpGGNYg19BfDorO3p/thxktyQZCrJ1MzMzNAnOnDw0FDjp4u5hjOOucYxkzSsURR65hmr+SZW1a1VNVlVkxMT8/4535O6YNnSocZPF3MNZxxzjWMmaVijKPRp4MJZ2yuBAyM47nE2rlvD0iWLnjK2dMkiNq5bcypONzBzDWccc41jJmlYo3iDi23AjUm20Hsx9PtV9dgIjnucYy9OjduVCOY683ONYyZpWKmad3XkxxOSO4HLgeXAt4B3AksAqurP+5ctfgBYT++yxTdW1YJvRTQ5OVm+Y5EkDSfJzqqanG/fgs/Qq2rDAvsLePPTzCZJGhHvFJWkRljoktQIC12SGmGhS1IjLHRJaoSFLkmNsNAlqREWuiQ1wkKXpEZY6JLUCAtdkhphoUtSIyx0SWqEhS5JjbDQJakRFrokNcJCl6RGWOiS1AgLXZIaYaFLUiMsdElqhIUuSY2w0CWpERa6JDXCQpekRljoktQIC12SGmGhS1IjLHRJasRAhZ5kfZK9SfYluWme/S9O8pkkX07yuSQrRx9VknQyCxZ6kkXALcBVwMXAhiQXz5n2XuCOqno5cDPwnlEHlSSd3CDP0C8B9lXVI1X1BLAFuHbOnIuBz/Qf3zfPfknSKTZIoa8AHp21Pd0fm+1B4HX9x68BnpPk+XMPlOSGJFNJpmZmZp5OXknSCQxS6JlnrOZs/y7wqiS7gFcB+4Ejx/2jqlurarKqJicmJoYOK0k6scUDzJkGLpy1vRI4MHtCVR0AXguQ5NnA66rq+6MKKUla2CDP0HcAq5NclOQc4Hpg2+wJSZYnOXasTcCHRhtTkrSQBQu9qo4ANwLbgT3AXVX1UJKbk1zTn3Y5sDfJ14AXAu8+RXklSSeQqrnL4afH5ORkTU1NdXJuSTpTJdlZVZPz7fNOUUlqhIUuSY2w0CWpERa6JDXCQpekRljoktQIC12SGmGhS1IjLHRJaoSFLkmNsNAlqREWuiQ1wkKXpEZY6JLUCAtdkhphoUtSIyx0SWqEhS5JjbDQJakRFrokNcJCl6RGWOiS1AgLXZIaYaFLUiMsdElqhIUuSY2w0CWpERa6JDVioEJPsj7J3iT7ktw0z/4XJbkvya4kX05y9eijSpJOZsFCT7IIuAW4CrgY2JDk4jnT/gC4q6rWAtcDfzbqoJKkkxvkGfolwL6qeqSqngC2ANfOmVPAc/uPfxI4MLqIkqRBDFLoK4BHZ21P98dmexfw+iTTwL3AW+Y7UJIbkkwlmZqZmXkacSVJJzJIoWeesZqzvQH4cFWtBK4G/irJcceuqlurarKqJicmJoZPK0k6oUEKfRq4cNb2So5fUvkN4C6AqvoC8Cxg+SgCSpIGM0ih7wBWJ7koyTn0XvTcNmfON4ErAJK8lF6hu6YiSafRgoVeVUeAG4HtwB56V7M8lOTmJNf0p/0O8KYkDwJ3Am+oqrnLMpKkU2jxIJOq6l56L3bOHnvHrMcPA5eONpokaRjeKSpJjbDQJakRFrokNcJCl6RGWOiS1AgLXZIaYaFLUiMsdElqhIUuSY2w0CWpEQPd+i+pO/fs2s/m7Xs5cPAQFyxbysZ1a7hu7dy3JJAsdGms3bNrP5u27ubQ4aMA7D94iE1bdwNY6jqOSy7SGNu8fe+TZX7MocNH2bx9b0eJNM4sdGmMHTh4aKhxnd0sdGmMXbBs6VDjOrtZ6NIY27huDUuXLHrK2NIli9i4bk1HiTTOfFFUGmPHXvj0KhcNwkKXxtx1a1dY4BqISy6S1AgLXZIaYaFLUiMsdElqhIUuSY2w0CWpERa6JDXCQpekRljoktQIC12SGmGhS1IjBir0JOuT7E2yL8lN8+z/0yRf6n98LcnB0UeVJJ3Mgn+cK8ki4BbgSmAa2JFkW1U9fGxOVb191vy3AGtPQVZJ0kkM8gz9EmBfVT1SVU8AW4BrTzJ/A3DnKMJJkgY3SKGvAB6dtT3dHztOkhcDFwGfPcH+G5JMJZmamZkZNqsk6SQGKfTMM1YnmHs9cHdVHZ1vZ1XdWlWTVTU5MTExaEZJ0gAGKfRp4MJZ2yuBAyeYez0ut0hSJwYp9B3A6iQXJTmHXmlvmzspyRrgecAXRhtRkjSIBQu9qo4ANwLbgT3AXVX1UJKbk1wza+oGYEtVnWg5RpJ0Cg30nqJVdS9w75yxd8zZftfoYkmShuWdopLUCAtdkhphoUtSIyx0SWqEhS5JjbDQJakRFrokNcJCl6RGWOiS1AgLXZIaYaFLUiMsdElqhIUuSY2w0CWpERa6JDXCQpekRljoktQIC12SGmGhS1IjLHRJaoSFLkmNsNAlqREWuiQ1wkKXpEZY6JLUCAtdkhphoUtSIyx0SWrEQIWeZH2SvUn2JbnpBHN+NcnDSR5K8rHRxpQkLWTxQhOSLAJuAa4EpoEdSbZV1cOz5qwGNgGXVtX3krzgVAWWJM1vkGfolwD7quqRqnoC2AJcO2fOm4Bbqup7AFX1+GhjSpIWMkihrwAenbU93R+b7SXAS5L8a5L7k6yf70BJbkgylWRqZmbm6SWWJM1rkELPPGM1Z3sxsBq4HNgA3JZk2XH/qOrWqpqsqsmJiYlhs0qSTmKQQp8GLpy1vRI4MM+cv6uqw1X1dWAvvYKXJJ0mgxT6DmB1kouSnANcD2ybM+ce4BcAkiyntwTzyCiDSpJObsFCr6ojwI3AdmAPcFdVPZTk5iTX9KdtB76T5GHgPmBjVX3nVIWWJB0vVXOXw0+PycnJmpqa6uTcknSmSrKzqibn2+edopLUCAtdkhphoUtSIyx0SWqEhS5JjbDQJakRFrokNcJCl6RGWOiS1AgLXZIaYaFLUiMsdElqhIUuSY2w0CWpERa6JDXCQpekRljoktQIC12SGmGhS1IjLHRJaoSFLkmNsNAlqREWuiQ1wkKXpEZY6JLUCAtdkhphoUtSIyx0SWqEhS5JjVg8yKQk64H3A4uA26rqj+bsfwOwGdjfH/pAVd02wpySxsw9u/azefteDhw8xAXLlrJx3RquW7ui61hnda4FCz3JIuAW4EpgGtiRZFtVPTxn6t9U1Y0jTSdpLN2zaz+btu7m0OGjAOw/eIhNW3cDdFqeZ3uuQZZcLgH2VdUjVfUEsAW4dmQJJJ1xNm/f+2Q5HXPo8FE2b9/bUaKesz3XIIW+Anh01vZ0f2yu1yX5cpK7k1w434GS3JBkKsnUzMzM04graRwcOHhoqPHT5WzPNUihZ56xmrP998Cqqno58I/AR+Y7UFXdWlWTVTU5MTExXFJJY+OCZUuHGj9dzvZcgxT6NDD7GfdK4MDsCVX1nar63/7mXwA/M5p4ksbRxnVrWLpk0VPGli5ZxMZ1azpK1HO25xrkKpcdwOokF9G7iuV64NdmT0hyflU91t+8Btgz0pSSxsqxF/LG7WqSsz1XquaunswzKbkaeB+9yxY/VFXvTnIzMFVV25K8h16RHwG+C/xWVX31ZMecnJysqampZ/wfIElnkyQ7q2py3n2DFPqpYKFL0vBOVujeKSpJjbDQJakRFrokNcJCl6RGWOiS1AgLXZIaYaFLUiMsdElqhIUuSY3o7E7RJDPAN57BIZYD3x5RnFEy13DGMdc4ZgJzDavVXC+uqnn/XG1nhf5MJZk60e2vXTLXcMYx1zhmAnMN62zM5ZKLJDXCQpekRpzJhX5r1wFOwFzDGcdc45gJzDWssy7XGbuGLkl6qjP5GbokaRYLXZIaccYVepIPJXk8yVe6znJMkguT3JdkT5KHkry160wASZ6V5N+SPNjP9YddZ5otyaIku5L8Q9dZjknyn0l2J/lSkrF5S60ky5LcneSr/e+znxuDTGv6X6djHz9I8raucwEkeXv/e/4rSe5M8qyuMwEkeWs/00On4mt1xq2hJ7kM+CFwR1W9rOs80HuTbOD8qnogyXOAncB1VfVwx7kCnFdVP0yyBPgX4K1VdX+XuY5J8tvAJPDcqnp113mgV+jAZFWN1Q0pST4C/HNV3ZbkHODcqjrYda5jkiyi9ybyr6yqZ3LD4CiyrKD3vX5xVR1Kchdwb1V9uONcLwO2AJcATwCfpPf+y/8+qnOccc/Qq+rz9N6IemxU1WNV9UD/8X8De4Bu32a8l6Wq6of9zSX9j7H4P3iSlcCvALd1nWXcJXkucBlwO0BVPTFOZd53BfAfXZf5LIuBpUkWA+cCBzrOA/BS4P6q+lFVHQH+CXjNKE9wxhX6uEuyClgLfLHbJD39ZY0vAY8Dn66qscgFvA/4PeD/ug4yRwGfSrIzyQ1dh+n7KWAG+Mv+EtVtSc7rOtQc1wN3dh0CoKr2A+8Fvgk8Bny/qj7VbSoAvgJcluT5Sc4FrgYuHOUJLPQRSvJs4OPA26rqB13nAaiqo1X108BK4JL+r32dSvJq4PGq2tl1lnlcWlWvAK4C3txf4uvaYuAVwAerai3wP8BN3Ub6sf4S0DXA33adBSDJ84BrgYuAC4Dzkry+21RQVXuAPwY+TW+55UHgyCjPYaGPSH+N+uPAR6tqa9d55ur/iv45YH3HUQAuBa7pr1dvAX4xyV93G6mnqg70Pz8OfILeemfXpoHpWb9d3U2v4MfFVcADVfWtroP0/RLw9aqaqarDwFbg5zvOBEBV3V5Vr6iqy+gtHY9s/Rws9JHov/h4O7Cnqv6k6zzHJJlIsqz/eCm9b/SvdpsKqmpTVa2sqlX0flX/bFV1/gwqyXn9F7XpL2n8Mr1fkztVVf8FPJpkTX/oCqDTF9zn2MCYLLf0fRP42STn9n82r6D3ulbnkryg//lFwGsZ8ddt8SgPdjokuRO4HFieZBp4Z1Xd3m0qLgV+HdjdX68G+P2qurfDTADnAx/pX4HwE8BdVTU2lwiOoRcCn+h1AIuBj1XVJ7uN9KS3AB/tL288Aryx4zwA9NeCrwR+s+ssx1TVF5PcDTxAb0ljF+PzZwA+nuT5wGHgzVX1vVEe/Iy7bFGSND+XXCSpERa6JDXCQpekRljoktQIC12SGmGhS1IjLHRJasT/AyEKg3yXrDoKAAAAAElFTkSuQmCC\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Plot functions y_pred_list_1layer\n",
    "plt.plot(range(1,10), y_pred_list_1layer, label=r\"$y=1-x$\")\n",
    "plt.show()\n",
    "# Plot functions y_pred_list_nNeuron\n",
    "plt.scatter(range(1,10), y_pred_list_nNeuron)\n",
    "plt.show()\n",
    "# Plot functions\n",
    "plt.scatter(range(1,10), y_pred_list_nlayer)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def ANN_regresion(X, y, input_dim,neurons=2, layers=1, activation='relu', epochs=25, batch_size=128,verbose=0):\n",
    "    model = Sequential()\n",
    "    model.add(Dense(units=neurons, input_dim=input_dim, activation='relu'))\n",
    "    for i in range(layers-1):\n",
    "        model.add(Dense(units=neurons, activation='relu'))\n",
    "    model.add(Dense(units=1))\n",
    "    model.compile(optimizer=SGD(lr=0.1), loss='mse')\n",
    "    model.fit(X, y, epochs=epochs, batch_size=batch_size, verbose=0)\n",
    "    return model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##  Continous Function Example"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAYIAAAD5CAYAAAAqaDI/AAAABHNCSVQICAgIfAhkiAAAAAlwSFlzAAALEgAACxIB0t1+/AAAADh0RVh0U29mdHdhcmUAbWF0cGxvdGxpYiB2ZXJzaW9uMy4xLjMsIGh0dHA6Ly9tYXRwbG90bGliLm9yZy+AADFEAAAeIElEQVR4nO3df/BddX3n8edrExNmrUpiviAGMBFTaxQb7HejLrsdl58BO4R2/QGtY6w/Mt0ts+sy2zEMHbAoI7azhf1BqyjU2GUEZatkSxQD4jpThfJFIz/FfIl0iaHw1aDooqGB9/5xP9HLzf31/Z5zz8/XY+bOvfecz7n3fT/3nM/78znnnnsUEZiZWXv9s7IDMDOzcjkRmJm1nBOBmVnLORGYmbWcE4GZWcs5EZiZtdziPF5E0jXAbwGPR8Rr+swX8F+BM4GngHdFxDfTvE3AH6eiH46IraPeb8WKFbFq1ao8Qjcza4277rrrBxEx1Ts9l0QAfAr4H8CnB8w/A1iTbq8H/hJ4vaTlwMXANBDAXZK2RcQTw95s1apVzMzM5BS6mVk7SPqHftNz2TUUEV8D9g0pshH4dHTcDhwu6SjgdGBHROxLjf8OYEMeMZmZ2XiKOkawEnik6/meNG3QdDMzK0hRiUB9psWQ6Ye+gLRZ0oykmbm5uVyDMzNrs6ISwR7gmK7nRwN7h0w/RERcFRHTETE9NXXIsQ4zM1ugohLBNuCd6ngD8OOIeBS4GThN0jJJy4DT0jQzMytIXj8f/QzwJmCFpD10fgn0PICI+Biwnc5PR2fp/Hz099O8fZI+BNyZXuqSiBh20NnMzHKWSyKIiHNHzA/gDwfMuwa4Jo84zMxs/vI6j8AaaNWWmwbOe/iyNxcYiZlNkv9iwvoalgTGmW9m9eFEYIcYt5F3MjBrBicCM7OWcyKw53Av36x9nAgsEycOs/pzIrBfcKNu1k5OBJaZE4hZvTkRGODG3KzNnAgsF04kZvXlRGBuxM1azonAcuOEYlZPTgQ2Fv+3kFlz+U/nWm6cXvx8ksCqLTc5aWQ06jtx/VrenAhsbA9f9mbv/pmwceq3t4wTg2XlXUM21EIaGSeLYrm+LatcEoGkDZIelDQraUuf+ZdL2plu35X0o655z3TN25ZHPDY57n1Wk5OBZZE5EUhaBFwJnAGsBc6VtLa7TET8p4hYFxHrgP8O/E3X7J8dnBcRZ2WNx6rBDVPxXOe2UHmMCNYDsxGxOyKeBq4DNg4pfy7wmRze1zJ67cVfGjp/UO/fo4LJWO2G3EqSRyJYCTzS9XxPmnYISS8DVgNf6Zp8mKQZSbdLOnvQm0janMrNzM3N5RC2Pbn/mYm+vnuo8xM5vIbr3BYij0SgPtMGrdPnADdERHcLdGxETAO/C1wh6bh+C0bEVRExHRHTU1NT2SK2zDwqMGuOPBLBHuCYrudHA3sHlD2Hnt1CEbE33e8GvgqckENMVhGvuMA91Lw4+dqk5JEI7gTWSFotaQmdxv6QX/9IeiWwDPhG17RlkpamxyuAE4H7c4jJCjBOw3Qgj/0d9gtOBjYJmU8oi4gDks4DbgYWAddExH2SLgFmIuJgUjgXuC4iupuGVwEfl/QsnaR0WUQ4EVSAG5xi5Xk2sc/unoxB31ET6jqX8wgiYntE/GpEHBcRl6ZpF3UlASLigxGxpWe5r0fE8RHx6+n+6jzisdHyOqg4zkbgA5j5akLDUzfD1uEmrN8+s9jMbIgmNPSjOBFYZh4VmNWbE4FZDY1Kvk68xfrCt75fdgiZOBGYlcx/O11d4ybU91+/c8KRTJYTgR1iIQ2Pdw+Z1ZcTQQu5QTazbk4ElhvvwrAmaVOHyYnArKZ8wLha6lzfTgRmJfKBYqsCJwLLlXupZvXjRNAyo/4N1D1Qs/Z1WJwIWsb/Bmo2OXVNIE4EZjXmXXGWBycCs5L4QHE1tTF5OhFY7kY1YL5qmVm15JIIJG2Q9KCkWUlb+sx/l6Q5STvT7b1d8zZJ2pVum/KIxxamqB6oj1NYk9VxRJE5EUhaBFwJnAGsBc6VtLZP0esjYl26fTItuxy4GHg9sB64WNKyrDFZf3VcQW20E49bPnS+v/fxjVNXTdxll8eIYD0wGxG7I+Jp4Dpg45jLng7siIh9EfEEsAPYkENMZq1x7fveWHYIVnN5JIKVwCNdz/ekab3+raS7Jd0g6Zh5LmvWKD5QXE9N/V7ySATqM613L/D/BlZFxGuBW4Ct81i2U1DaLGlG0szc3NyCg7VijNpgXnvxlwqKxGw8ee5Cq9vuuDwSwR7gmK7nRwN7uwtExA8jYn96+gngN8Zdtus1roqI6YiYnpqayiFsK9OT+58pOwSzBWvayCCPRHAnsEbSaklLgHOAbd0FJB3V9fQs4IH0+GbgNEnL0kHi09I0K1jTVuy28Yllk9fkbWRx1heIiAOSzqPTgC8CromI+yRdAsxExDbgP0g6CzgA7APelZbdJ+lDdJIJwCURsS9rTHYoNwTVMeo8iivevq6gSOygtm8fmRMBQERsB7b3TLuo6/EFwAUDlr0GuCaPOMzqYNR5FGef4N9LNMGqLTfVZhThM4ttYkZtBK+/dEdBkZhl029drksjPw4nAivNYz95uuwQzAwnArPG8AHjhXG9OBG0wq9duH3o/CYNcavOJ5LVT5bvpC5JxomgBX7+jP/lzWwSmpK4nQhsopqyoVgz1aXHPmlOBFYqb4j5OmxRv39t+SXX9/ysOeL5ZYdQCCcCswb5zqVnlh1Co+w4/02ZX6MOydeJoOW866Y4PlBcLXk10E343pwIGq4OvREzK5cTgU1cE3pM1j5tWm+dCKx0HrXkyyeWjVZ0HVS9zp0IzMwyqvvowYnArAA+UFwvbfs+nAharG0ruxlUfzdNGXJJBJI2SHpQ0qykLX3mny/p/nTx+lslvaxr3jOSdqbbtt5lbeGqtMKfeNzyskMwK1WVtsdemROBpEXAlcAZwFrgXElre4p9C5hOF6+/AfjTrnk/i4h16XZW1nismq593xuHzq/yRlJHPmC8cAsdKdd5hJ3HiGA9MBsRuyPiaeA6YGN3gYi4LSKeSk9vp3ORejMzq4A8EsFK4JGu53vStEHeA3yx6/lhkmYk3S7p7BziMasUHyiuDo+E+ssjEfT7l6u+/3ss6R3ANPBnXZOPjYhp4HeBKyQdN2DZzSlhzMzNzWWN2czsEJNOylVNRHkkgj3AMV3Pjwb29haSdApwIXBWROw/OD0i9qb73cBXgRP6vUlEXBUR0xExPTU1lUPYzVbFXqh7vtVS1Uapzuq6jueRCO4E1khaLWkJcA7wnF//SDoB+DidJPB41/RlkpamxyuAE4H7c4jJasgNU77q2ihNitevwRZnfYGIOCDpPOBmYBFwTUTcJ+kSYCYittHZFfQrwOckAfzf9AuhVwEfl/QsnaR0WUQ4EZhZ4dqcODMnAoCI2A5s75l2UdfjUwYs93Xg+DxiMKuiKu6is3L93ie+MfLn1EXzmcVm1nhF7hYaldz/7qF9BUUyPieCFiqzFzrqUoqWL59YZuNwImigKm/coy6lWOXYrbnavovOicDMGs2di9GcCMwmxAeK26tuu+ScCMys1ZyQnQisBIt9vLhQdeud5qnJny1PTgQtU4Xez+xH2tswmVWRE0HDuBGthtde/KWh89/xhmMLisSGmWTH6MgXLBk6v0rbai5nFtfBoEqvQg/ZmufJ/c8Mnf/hs31CfdPdceGplWrsh2nFiGDYl1GXL8pskpq4HTTxM01KKxLBKF5hrOk88j2U6+SXnAgSJ4NitfmXLGYHVWU9dyJokNU+gakSfCJZ+arSwNblu3YiaJC+1wc1s0Nc8fZ1ZYdQKa1IBONm5ar0IswmwbvjfunsE1aWHUKl5JIIJG2Q9KCkWUlb+sxfKun6NP8OSau65l2Qpj8o6fQ84umnLkM0M8umbgmtCvFmTgSSFgFXAmcAa4FzJa3tKfYe4ImIeAVwOfDRtOxaOtc4fjWwAfiL9HoT4WRQLe6hWhvUod3JY0SwHpiNiN0R8TRwHbCxp8xGYGt6fANwsjoXL94IXBcR+yPie8Bsej3LWR1WxibwgeLq83dwqDwSwUrgka7ne9K0vmUi4gDwY+DFYy5bqLr2Qusat1mevB0sTB6JoN9/Sfb+gGVQmXGW7byAtFnSjKSZubm5eYb4S+4NWJt5d1w1lV3veSSCPcAxXc+PBvYOKiNpMfAiYN+YywIQEVdFxHRETE9NTeUQtpm1TVkdwap3QPNIBHcCayStlrSEzsHfbT1ltgGb0uO3AF+JiEjTz0m/KloNrAH+PoeYMik7O7eJe6iWF68rC5c5EaR9/ucBNwMPAJ+NiPskXSLprFTsauDFkmaB84Etadn7gM8C9wNfAv4wIob/bWMOqp6drZ58oNjqKpfzCCJie0T8akQcFxGXpmkXRcS29PjnEfHWiHhFRKyPiN1dy16alntlRHwxj3jsudwA2Xx84VvfLzuEiaj6dlDmiKYVZxY3nYfENh+jGsT3X7+zoEjyc+qff7XsEEaqciJyIhjAjatZfex6/P+VHUKttTYRVDk7t40PGNukeXsfrrWJwCxPPlBsdeZEMEQTeqKL+52yZ63XpFFYnWKtar23OhGsOeL5ZYeQ2Wsv/tLQ+bMfcU/U2s2jsdFanQh2nP+mskPI7Mn9Ez/twswartWJwKqjqkNmqzavF/lwIhjBK5qN4gPFNh/veMOxQ+eX0ea0PhF4I7W2asMorIrb94fPPr7sEA7R+kTQZFXcCMzy0oREVRVOBGOo6gpX1bjMrF6cCKwy2rCrwopT5xFx0eu6EwH1XmGsXE0/UFzVfyKte6egauuFE4FZizXxn0ht/jIlAknLJe2QtCvdL+tTZp2kb0i6T9Ldkt7eNe9Tkr4naWe6rcsSzyTVvQdi1iZV63FXXdYRwRbg1ohYA9yanvd6CnhnRLwa2ABcIenwrvl/FBHr0q207kfTVpymfR6zg0b9rUpTFNn5zJoINgJb0+OtwNm9BSLiuxGxKz3eCzwO+OrzGTV1hFKnA8ajGqQjX7CkoEjapSl/q1KlzlrWRHBkRDwKkO6PGFZY0npgCfBQ1+RL0y6jyyUtzRjPRFWpEbLyjWqQ7rjw1IIiyaZOyXccVWpg62LxqAKSbgFe0mfWhfN5I0lHAX8NbIqIZ9PkC4B/pJMcrgI+AFwyYPnNwGaAY48dfoq2mZmNb+SIICJOiYjX9LndCDyWGviDDf3j/V5D0guBm4A/jojbu1770ejYD/wVsH5IHFdFxHRETE9NTWbPknsSZtVWt9FJVkV93qy7hrYBm9LjTcCNvQUkLQE+D3w6Ij7XM+9gEhGd4wv3ZozH8MVorL3q1pmrSrxZE8FlwKmSdgGnpudImpb0yVTmbcBvAu/q8zPRayXdA9wDrAA+nDGeiatCj2RUDHW/GE0d9lk3/UQya5dMiSAifhgRJ0fEmnS/L02fiYj3psf/MyKe1/UT0V/8TDQiToqI49OupndExE+zf6RsvAFbGzUh+drC+cxiM7MKKyIBOhEsgHsmZtVT19F8FeJ2IjCzynPna7KcCPqoQoZeqDrH3q3K+6x9oNiaxomgZtwzskmpcvIdpenJ9/c+8Y2Jvr4TwQJVeaMwa5I2bGujEtnfPbRvou/vRDBA03sYZmYHORGYWa2505adE0EGbRiylqmK+6ybfqC4anXelmsPlM2JoEHq3giZ9WrKtQfGUWYSdiIYomoNq0cgZs9VtW20rpwIzMxazokgI/fSzSbD21ZxnAhG8NCzXFU6eNn0A8UHVanOh2lKfXc7bNHwi4lMqu6dCBrCF0o3q7/vXHpmKe+bKRFIWi5ph6Rd6X7ZgHLPdF2UZlvX9NWS7kjLX5+uZlY7RfSQRr1HXS6UbjaOqow62iLriGALcGtErAFuTc/7+VnXRWnO6pr+UeDytPwTwHsyxmNmLeCrseYrayLYCGxNj7fSue7wWNJ1ik8CbljI8kVq4r5Iszr7Xou3yUmMlrImgiMj4lGAdH/EgHKHSZqRdLukg439i4EfRcSB9HwPsDJjPNZAVTh42ZYDxQeVWedt3y1Uxrq0eFQBSbcAL+kz68J5vM+xEbFX0suBr6QL1j/Zp1wMiWMzsBng2GOPncdbF2PVlpsa1xiYWTuMHBFExCnp4vK9txuBxyQdBZDuHx/wGnvT/W7gq8AJwA+AwyUdTEZHA3uHxHFVRExHxPTU1NQ8PmI+qtzIVzk2s7x5fc9f1l1D24BN6fEm4MbeApKWSVqaHq8ATgTuj4gAbgPeMmx581DZ2sPr+njyrqesieAy4FRJu4BT03MkTUv6ZCrzKmBG0rfpNPyXRcT9ad4HgPMlzdI5ZnB1xnjMLCeLR/w0x4325BQ96smUCCLihxFxckSsSff70vSZiHhvevz1iDg+In493V/dtfzuiFgfEa+IiLdGxP5sH6dc3jAmp8oHL5u6q2L2I9X7XE2t67L5zOJ58EpoNjmvv3RH2SG0lhOBmVXCYz95uuwQaiXPUbATQc6K3j3kUYq1RdvW9SI/rxPBPBW9Mvq4Q7lG1f8Vb19XUCTlqMLJfDZ5TgRWG1VslM4+wSfD58EJpVxOBGZWeW3bLVQ0J4IJcO/GzPJQVAJ0IliAqvROqhKHWRbuOJXPiaDCvIGUq60nkvUq+9iMrz0weU4EE+JGfDLKbpSseG2+9gAMXufz7IiM/Btq608M+c9sMxuLE/d4Jj369IhggdreSzGz5nAiMLPMXnHBZHr2bTkOUzYnggma5LDXG8hk+UDxc436vAcWsJ/Uu4Wqw4kgg0k2Bt5IBvMBY7N8ORGYWSW1bdRVpkyJQNJySTsk7Ur3y/qU+TeSdnbdfi7p7DTvU5K+1zWvcf/g5d6p2aFWe7uolKwjgi3ArRGxBrg1PX+OiLgtItZFxDrgJOAp4MtdRf7o4PyI2JkxnsL5ZJfm8fGB/vLcJeefXldL1kSwEdiaHm8Fzh5R/i3AFyPiqYzvWxn+GalZ/tqabMuSNREcGRGPAqT7I0aUPwf4TM+0SyXdLelySUszxtMI7pGO5gPGZvkZmQgk3SLp3j63jfN5I0lHAccDN3dNvgD4NeBfAMuBDwxZfrOkGUkzc3Nz83nr0rlRMvslbw/VMzIRRMQpEfGaPrcbgcdSA3+woX98yEu9Dfh8RPxT12s/Gh37gb8C1g+J46qImI6I6ampqXE/XyHcQ28ON1Ll8/ZUvKy7hrYBm9LjTcCNQ8qeS89uoa4kIjrHF+7NGI/ZRLW9kfIuuWbKmgguA06VtAs4NT1H0rSkTx4sJGkVcAzwf3qWv1bSPcA9wArgwxnjqSxvIGbeDqoqUyKIiB9GxMkRsSbd70vTZyLivV3lHo6IlRHxbM/yJ0XE8WlX0zsi4qdZ4mkCHygeX9690y986/tZwrEcvHDporJDaCWfWZwTN9D19/7ra3caS+Pc/Scbyg6hlZwIzMbkZD+eQSMx7xaqLieCAnlDsCZwQmweJ4IcZd1AnCjK47ovnxNMeZwIasQbyqGK+jmj6z4bJ9pqcyIomDeI6vF3Ym3nRGBm85b3SMwjrnI5EeRsoSu0e6XlcL1Pnuu4+pwIasI9pvK47q3pnAhK4B5Svha6m8LfQzU40ZbPiWACvGI3h79LawMnggpwz7R4rvPsxhmJuZ7rwYmgJPPZSNwrzZfrvTpcx9XgRFAy95jMrGxOBBPink6xxj1g7NGA2aEyJQJJb5V0n6RnJU0PKbdB0oOSZiVt6Zq+WtIdknZJul7SkizxmA3j0Ve1nHjc8rJDsCTriOBe4HeArw0qIGkRcCVwBrAWOFfS2jT7o8DlEbEGeAJ4T8Z4Gsc90+K5zseXpa6ufd8bc4zEssh6hbIHIuLBEcXWA7MRsTsingauAzam6xSfBNyQym2lc93ixnCDUj/+zqyNijhGsBJ4pOv5njTtxcCPIuJAz/RGccNiZlU3MhFIukXSvX1uG8d8D/WZFkOmD4pjs6QZSTNzc3NjvnU1PHzZmxeUEJxE5idrfbm+i+O6rpaRiSAiTkkXl++93Tjme+wBjul6fjSwF/gBcLikxT3TB8VxVURMR8T01NTUmG9dLV75q8vfzcK57uqviF1DdwJr0i+ElgDnANsiIoDbgLekcpuAcZNLbY07OvDGVRzXtbVd1p+P/rakPcAbgZsk3Zymv1TSdoB0DOA84GbgAeCzEXFfeokPAOdLmqVzzODqLPHUybDGxw3Tws237lzXxXOdV486HfN6mZ6ejpmZmbLDsIobdt6AG6N8zeccDdd9eSTdFRGHnPO1uF9hsyZwg2M2Hv/FhJllNm7SdXKuJicCM7OWcyIwM2s5JwIzK4R3C1WXE4GZTdwLly4qOwQbwonAzHIxqMf/wqWLuPtPNhQcjc2Hfz5qZrnx7p968ojAzKzlnAjMzFrOicDMrOWcCMzMWs6JwMys5ZwIzMxarpZ/Qy1pDviHBS6+gs7V0arGcc2P45ofxzU/TY3rZRFxyCUea5kIspA00+//uMvmuObHcc2P45qftsXlXUNmZi3nRGBm1nJtTARXlR3AAI5rfhzX/Diu+WlVXK07RmBmZs/VxhGBmZl1aWQikPRWSfdJelbSdM+8CyTNSnpQ0ukDll8t6Q5JuyRdL2nJBGK8XtLOdHtY0s4B5R6WdE8qN5N3HH3e74OSvt8V25kDym1IdTgraUsBcf2ZpO9IulvS5yUdPqBcIfU16vNLWpq+49m0Lq2aVCxd73mMpNskPZDW///Yp8ybJP246/u9aNJxpfcd+r2o47+l+rpb0usKiOmVXfWwU9KTkt7fU6aQ+pJ0jaTHJd3bNW25pB2pHdohadmAZTelMrskbVpQABHRuBvwKuCVwFeB6a7pa4FvA0uB1cBDwKI+y38WOCc9/hjw7yYc738BLhow72FgRYF190HgP48osyjV3cuBJalO1044rtOAxenxR4GPllVf43x+4N8DH0uPzwGuL+C7Owp4XXr8AuC7feJ6E/C3Ra1P434vwJnAFwEBbwDuKDi+RcA/0vmdfeH1Bfwm8Drg3q5pfwpsSY+39FvngeXA7nS/LD1eNt/3b+SIICIeiIgH+8zaCFwXEfsj4nvALLC+u4AkAScBN6RJW4GzJxVrer+3AZ+Z1HtMwHpgNiJ2R8TTwHV06nZiIuLLEXEgPb0dOHqS7zfCOJ9/I511Bzrr0snpu56YiHg0Ir6ZHv8EeABYOcn3zNFG4NPRcTtwuKSjCnz/k4GHImKhJ6pmEhFfA/b1TO5ehwa1Q6cDOyJiX0Q8AewA5n0VoEYmgiFWAo90Pd/DoRvKi4EfdTU6/crk6V8Dj0XErgHzA/iypLskbZ5gHN3OS8PzawYMR8epx0l6N53eYz9F1Nc4n/8XZdK69GM661Yh0q6oE4A7+sx+o6RvS/qipFcXFNKo76XsdeocBnfGyqgvgCMj4lHoJHngiD5lcqm32l6hTNItwEv6zLowIm4ctFifab0/mxqnzFjGjPFcho8GToyIvZKOAHZI+k7qPSzYsLiAvwQ+ROczf4jObqt3975En2Uz//xsnPqSdCFwALh2wMvkXl/9Qu0zbWLr0XxJ+hXgfwHvj4gne2Z/k87uj5+m4z9fANYUENao76XM+loCnAVc0Gd2WfU1rlzqrbaJICJOWcBie4Bjup4fDeztKfMDOsPSxakn169MLjFKWgz8DvAbQ15jb7p/XNLn6eyWyNSwjVt3kj4B/G2fWePUY+5xpQNhvwWcHGkHaZ/XyL2++hjn8x8ssyd9zy/i0KF/7iQ9j04SuDYi/qZ3fndiiIjtkv5C0oqImOj/6ozxvUxknRrTGcA3I+Kx3hll1VfymKSjIuLRtJvs8T5l9tA5jnHQ0XSOjc5L23YNbQPOSb/oWE0ns/99d4HUwNwGvCVN2gQMGmFkdQrwnYjY02+mpOdLesHBx3QOmN7br2xeevbL/vaA97sTWKPOr6uW0BlWb5twXBuADwBnRcRTA8oUVV/jfP5tdNYd6KxLXxmUvPKSjkFcDTwQEX8+oMxLDh6rkLSeThvwwwnHNc73sg14Z/r10BuAHx/cLVKAgaPyMuqrS/c6NKgduhk4TdKytBv3tDRtfiZ9NLyMG50GbA+wH3gMuLlr3oV0fvHxIHBG1/TtwEvT45fTSRCzwOeApROK81PAH/RMeymwvSuOb6fbfXR2kUy67v4auAe4O62IR/XGlZ6fSedXKQ8VFNcsnX2hO9PtY71xFVlf/T4/cAmdRAVwWFp3ZtO69PIC6uhf0dktcHdXPZ0J/MHB9Qw4L9XNt+kcdP+XBcTV93vpiUvAlak+76Hr134Tju2f02nYX9Q1rfD6opOIHgX+KbVd76FzTOlWYFe6X57KTgOf7Fr23Wk9mwV+fyHv7zOLzcxarm27hszMrIcTgZlZyzkRmJm1nBOBmVnLORGYmbWcE4GZWcs5EZiZtZwTgZlZy/1/ZalzcH8AyyYAAAAASUVORK5CYII=\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mean Squared Error: 0.04313436214304017\n"
     ]
    }
   ],
   "source": [
    "# Continuous function\n",
    "f_c = lambda x: np.sin(x)\n",
    "f_c = np.vectorize(f_c)\n",
    "\n",
    "x_c = np.random.uniform(low=-10, high=10, size=(100000,))[:,np.newaxis]\n",
    "y_c = f_c(x_c)\n",
    "\n",
    "# transform to [0~1] scale\n",
    "scale_x = MinMaxScaler()\n",
    "x_c = scale_x.fit_transform(x_c)\n",
    "scale_y = MinMaxScaler()\n",
    "y_c = scale_y.fit_transform(y_c)\n",
    "\n",
    "neurons = 100\n",
    "layers = 2\n",
    "act_function = 'relu'\n",
    "\n",
    "model = ANN_regresion(x_c, y_c, 1,\n",
    "                      neurons=neurons,\n",
    "                      layers=layers,\n",
    "                      activation=act_function,\n",
    "                      epochs=25,\n",
    "                      batch_size=128,\n",
    "                      verbose=0)\n",
    "#  Predict Train Data\n",
    "y_c_hat = model.predict(x_c)\n",
    "\n",
    "# Transform to real scale\n",
    "x_c = scale_x.inverse_transform(x_c)\n",
    "y_c = scale_y.inverse_transform(y_c)\n",
    "y_c_hat = scale_y.inverse_transform(y_c_hat)\n",
    "\n",
    "# Plot functions\n",
    "plt.scatter(x_c, y_c)\n",
    "plt.show()\n",
    "plt.scatter(x_c, y_c_hat)\n",
    "plt.show()\n",
    "\n",
    "print(f'Mean Squared Error: {mean_squared_error(y_c, y_c_hat)}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Discontinuous Function Example"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(200000, 1)\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mean Squared Error3556.9679090600216\n"
     ]
    }
   ],
   "source": [
    "# Discontinuous function\n",
    "# f_d = lambda x: x**2 if x <0 else 40 + 10*x\n",
    "f_d = lambda x: 1 /(x)\n",
    "f_d = np.vectorize(f_d)\n",
    "x_d_1 = np.random.uniform(low=-5, high=-1e-17, size=(100000,))[:,np.newaxis]\n",
    "x_d_2 = np.random.uniform(low=1e-17, high=5, size=(100000,))[:,np.newaxis]\n",
    "x_d = np.concatenate((x_d_1, x_d_2), axis = 0)\n",
    "print(x_d.shape)\n",
    "y_d = f_d(x_d)\n",
    "\n",
    "# transform to [0~1] scale\n",
    "scale_x = MinMaxScaler()\n",
    "x_d = scale_x.fit_transform(x_d)\n",
    "scale_y = MinMaxScaler()\n",
    "y_d = scale_y.fit_transform(y_d)\n",
    "\n",
    "neurons = 10\n",
    "layers = 100\n",
    "act_function='relu'\n",
    "\n",
    "model = ANN_regresion(x_d, y_d, 1,\n",
    "                      neurons=neurons,\n",
    "                      layers=layers,\n",
    "                      activation=act_function,\n",
    "                      epochs=25,\n",
    "                      batch_size=128,\n",
    "                      verbose=0)\n",
    "# Predict Train Data\n",
    "y_d_hat = model.predict(x_d)\n",
    "\n",
    "# Transform to real scale\n",
    "x_d = scale_x.inverse_transform(x_d)\n",
    "y_d = scale_y.inverse_transform(y_d)\n",
    "y_d_hat = scale_y.inverse_transform(y_d_hat)\n",
    "\n",
    "# Plot functions\n",
    "plt.scatter(x_d, y_d)\n",
    "plt.ylim(-100,100)\n",
    "plt.show()\n",
    "plt.scatter(x_d, y_d_hat)\n",
    "plt.show()\n",
    "print(f'Mean Squared Error{mean_squared_error(y_d, y_d_hat)}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "import math\n",
    "\n",
    "math.ceil(0.1)\n",
    "f_ceil = lambda x: math.ceil(x)\n",
    "f_ceil = np.vectorize(f_ceil)\n",
    "x = np.random.uniform(low=0, high=10, size=(100000,))[:,np.newaxis]\n",
    "y = f_ceil(x)\n",
    "\n",
    "scale_x = MinMaxScaler()\n",
    "x = scale_x.fit_transform(x)\n",
    "scale_y = MinMaxScaler()\n",
    "y = scale_y.fit_transform(y)\n",
    "\n",
    "neurons = 10\n",
    "layers = 10\n",
    "act_function='relu'\n",
    "\n",
    "model = ANN_regresion(x, y, 1,\n",
    "                      neurons=neurons,\n",
    "                      layers=layers,\n",
    "                      activation=act_function,\n",
    "                      epochs=25,\n",
    "                      batch_size=128,\n",
    "                      verbose=0)\n",
    "# Predict Train Data\n",
    "y_hat = model.predict(x)\n",
    "\n",
    "# Transform to real scale\n",
    "x = scale_x.inverse_transform(x)\n",
    "y = scale_y.inverse_transform(y)\n",
    "y_hat = scale_y.inverse_transform(y_hat)\n",
    "\n",
    "\n",
    "plt.scatter(x,y)\n",
    "plt.show()\n",
    "plt.scatter(x,y_hat)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Primer Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn import preprocessing\n",
    "from sklearn.model_selection import train_test_split\n",
    "from keras.optimizers import Adam\n",
    "from keras.callbacks import EarlyStopping\n",
    "from keras.backend import clear_session"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "df = pd.read_csv('high_diamond_ranked_10min.csv')\n",
    "df = df.drop(['gameId','blueWardsDestroyed','blueFirstBlood','blueDragons','blueHeralds','blueTotalExperience','blueCSPerMin','redWardsPlaced','redWardsDestroyed','redFirstBlood','redDragons','redHeralds','redTotalExperience','redCSPerMin'],axis= 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>blueWardsPlaced</th>\n",
       "      <th>blueKills</th>\n",
       "      <th>blueDeaths</th>\n",
       "      <th>blueAssists</th>\n",
       "      <th>blueEliteMonsters</th>\n",
       "      <th>blueTowersDestroyed</th>\n",
       "      <th>blueTotalGold</th>\n",
       "      <th>blueAvgLevel</th>\n",
       "      <th>blueTotalMinionsKilled</th>\n",
       "      <th>blueTotalJungleMinionsKilled</th>\n",
       "      <th>...</th>\n",
       "      <th>redAssists</th>\n",
       "      <th>redEliteMonsters</th>\n",
       "      <th>redTowersDestroyed</th>\n",
       "      <th>redTotalGold</th>\n",
       "      <th>redAvgLevel</th>\n",
       "      <th>redTotalMinionsKilled</th>\n",
       "      <th>redTotalJungleMinionsKilled</th>\n",
       "      <th>redGoldDiff</th>\n",
       "      <th>redExperienceDiff</th>\n",
       "      <th>redGoldPerMin</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>28</td>\n",
       "      <td>9</td>\n",
       "      <td>6</td>\n",
       "      <td>11</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>17210</td>\n",
       "      <td>6.6</td>\n",
       "      <td>195</td>\n",
       "      <td>36</td>\n",
       "      <td>...</td>\n",
       "      <td>8</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>16567</td>\n",
       "      <td>6.8</td>\n",
       "      <td>197</td>\n",
       "      <td>55</td>\n",
       "      <td>-643</td>\n",
       "      <td>8</td>\n",
       "      <td>1656.7</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>12</td>\n",
       "      <td>5</td>\n",
       "      <td>5</td>\n",
       "      <td>5</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>14712</td>\n",
       "      <td>6.6</td>\n",
       "      <td>174</td>\n",
       "      <td>43</td>\n",
       "      <td>...</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>17620</td>\n",
       "      <td>6.8</td>\n",
       "      <td>240</td>\n",
       "      <td>52</td>\n",
       "      <td>2908</td>\n",
       "      <td>1173</td>\n",
       "      <td>1762.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>15</td>\n",
       "      <td>7</td>\n",
       "      <td>11</td>\n",
       "      <td>4</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>16113</td>\n",
       "      <td>6.4</td>\n",
       "      <td>186</td>\n",
       "      <td>46</td>\n",
       "      <td>...</td>\n",
       "      <td>14</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>17285</td>\n",
       "      <td>6.8</td>\n",
       "      <td>203</td>\n",
       "      <td>28</td>\n",
       "      <td>1172</td>\n",
       "      <td>1033</td>\n",
       "      <td>1728.5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>43</td>\n",
       "      <td>4</td>\n",
       "      <td>5</td>\n",
       "      <td>5</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>15157</td>\n",
       "      <td>7.0</td>\n",
       "      <td>201</td>\n",
       "      <td>55</td>\n",
       "      <td>...</td>\n",
       "      <td>10</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>16478</td>\n",
       "      <td>7.0</td>\n",
       "      <td>235</td>\n",
       "      <td>47</td>\n",
       "      <td>1321</td>\n",
       "      <td>7</td>\n",
       "      <td>1647.8</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>75</td>\n",
       "      <td>6</td>\n",
       "      <td>6</td>\n",
       "      <td>6</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>16400</td>\n",
       "      <td>7.0</td>\n",
       "      <td>210</td>\n",
       "      <td>57</td>\n",
       "      <td>...</td>\n",
       "      <td>7</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>17404</td>\n",
       "      <td>7.0</td>\n",
       "      <td>225</td>\n",
       "      <td>67</td>\n",
       "      <td>1004</td>\n",
       "      <td>-230</td>\n",
       "      <td>1740.4</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 25 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   blueWardsPlaced  blueKills  blueDeaths  blueAssists  blueEliteMonsters  \\\n",
       "0               28          9           6           11                  0   \n",
       "1               12          5           5            5                  0   \n",
       "2               15          7          11            4                  1   \n",
       "3               43          4           5            5                  1   \n",
       "4               75          6           6            6                  0   \n",
       "\n",
       "   blueTowersDestroyed  blueTotalGold  blueAvgLevel  blueTotalMinionsKilled  \\\n",
       "0                    0          17210           6.6                     195   \n",
       "1                    0          14712           6.6                     174   \n",
       "2                    0          16113           6.4                     186   \n",
       "3                    0          15157           7.0                     201   \n",
       "4                    0          16400           7.0                     210   \n",
       "\n",
       "   blueTotalJungleMinionsKilled  ...  redAssists  redEliteMonsters  \\\n",
       "0                            36  ...           8                 0   \n",
       "1                            43  ...           2                 2   \n",
       "2                            46  ...          14                 0   \n",
       "3                            55  ...          10                 0   \n",
       "4                            57  ...           7                 1   \n",
       "\n",
       "   redTowersDestroyed  redTotalGold  redAvgLevel  redTotalMinionsKilled  \\\n",
       "0                   0         16567          6.8                    197   \n",
       "1                   1         17620          6.8                    240   \n",
       "2                   0         17285          6.8                    203   \n",
       "3                   0         16478          7.0                    235   \n",
       "4                   0         17404          7.0                    225   \n",
       "\n",
       "   redTotalJungleMinionsKilled  redGoldDiff  redExperienceDiff  redGoldPerMin  \n",
       "0                           55         -643                  8         1656.7  \n",
       "1                           52         2908               1173         1762.0  \n",
       "2                           28         1172               1033         1728.5  \n",
       "3                           47         1321                  7         1647.8  \n",
       "4                           67         1004               -230         1740.4  \n",
       "\n",
       "[5 rows x 25 columns]"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df1 = df.loc[:, df.columns != 'blueWins']\n",
    "df2 = df['blueWins']\n",
    "\n",
    "df1.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "df1 = preprocessing.scale(df1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(df1, df2, test_size=0.2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = Sequential()\n",
    "model.add(Dense(22,input_shape=(25,), activation = 'relu'))\n",
    "model.add(Dense(1,activation='sigmoid'))\n",
    "model.compile(loss='binary_crossentropy', optimizer=Adam(lr=0.001), metrics = ['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 00029: early stopping\n"
     ]
    }
   ],
   "source": [
    "earlystopper = EarlyStopping(monitor='val_loss', min_delta=0, patience=15, verbose=1, mode='auto')\n",
    "history = model.fit(X_train, y_train, epochs = 2000, validation_split = 0.15, verbose = 0, \n",
    "                    callbacks = [earlystopper])\n",
    "history_dict=history.history"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1976/1976 [==============================] - 0s 114us/step\n",
      "Test loss:  0.5405108354352264\n",
      "Test accuracy:  0.7231781482696533\n"
     ]
    }
   ],
   "source": [
    "loss, acc = model.evaluate(X_test, y_test)\n",
    "print(\"Test loss: \", loss)\n",
    "print(\"Test accuracy: \", acc)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Primer dataset variando el numero de capas "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 00025: early stopping\n",
      "1976/1976 [==============================] - 0s 109us/step\n",
      "Epoch 00021: early stopping\n",
      "1976/1976 [==============================] - 0s 59us/step\n",
      "Epoch 00020: early stopping\n",
      "1976/1976 [==============================] - 0s 69us/step\n"
     ]
    }
   ],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(df1, df2, test_size=0.2)\n",
    "#model = Sequential()\n",
    "#model.add(Dense(22,input_shape=(25,), activation = 'relu'))\n",
    "capas = [4,8,12]\n",
    "resultados = []\n",
    "for j in range(0,len(capas)):\n",
    "    model = Sequential()\n",
    "    model.add(Dense(22,input_shape=(25,), activation = 'relu'))\n",
    "    for i in range(0,capas[j]):\n",
    "        model.add(Dense(14,activation = 'relu'))\n",
    "    model.add(Dense(1,activation='sigmoid'))\n",
    "    model.compile(loss='binary_crossentropy', optimizer=Adam(lr=0.001), metrics = ['accuracy'])\n",
    "    earlystopper = EarlyStopping(monitor='val_loss', min_delta=0, patience=15, verbose=1, mode='auto')\n",
    "    history = model.fit(X_train, y_train, epochs = 2000, validation_split = 0.15, verbose = 0, \n",
    "                    callbacks = [earlystopper])\n",
    "    loss, acc = model.evaluate(X_test, y_test)\n",
    "    resultados.append((loss,acc))\n",
    "    clear_session()\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>loss</th>\n",
       "      <th>acc</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>4 capas</th>\n",
       "      <td>0.582303</td>\n",
       "      <td>0.703441</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8 capas</th>\n",
       "      <td>0.583482</td>\n",
       "      <td>0.709008</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12 capas</th>\n",
       "      <td>0.580275</td>\n",
       "      <td>0.709008</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "              loss       acc\n",
       "4 capas   0.582303  0.703441\n",
       "8 capas   0.583482  0.709008\n",
       "12 capas  0.580275  0.709008"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tabla = pd.DataFrame(resultados, index =['4 capas', '8 capas', '12 capas'], columns = ['loss', 'acc'])\n",
    "tabla"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "seg_resultados = [l[1] for l in resultados]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[]"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "capas = [4,8,12]\n",
    "plt.scatter(capas,seg_resultados,c = 'b')\n",
    "plt.plot()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Primer dataset variando el numero de Neuronas"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 00020: early stopping\n",
      "1976/1976 [==============================] - 0s 57us/step\n",
      "Epoch 00018: early stopping\n",
      "1976/1976 [==============================] - 0s 50us/step\n",
      "Epoch 00017: early stopping\n",
      "1976/1976 [==============================] - 0s 50us/step\n"
     ]
    }
   ],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(df1, df2, test_size=0.2)\n",
    "#model = Sequential()\n",
    "#model.add(Dense(22,input_shape=(25,), activation = 'relu'))\n",
    "neuronas = [13,18,40]\n",
    "resultados_neuronas = []\n",
    "for j in range(0,len(neuronas)):\n",
    "    model = Sequential()\n",
    "    model.add(Dense(22,input_shape=(25,), activation = 'relu'))\n",
    "    model.add(Dense(neuronas[j],activation = 'relu'))\n",
    "    model.add(Dense(1,activation='sigmoid'))\n",
    "    model.compile(loss='binary_crossentropy', optimizer=Adam(lr=0.001), metrics = ['accuracy'])\n",
    "    earlystopper = EarlyStopping(monitor='val_loss', min_delta=0, patience=15, verbose=1, mode='auto')\n",
    "    history = model.fit(X_train, y_train, epochs = 2000, validation_split = 0.15, verbose = 0, \n",
    "                    callbacks = [earlystopper])\n",
    "    loss, acc = model.evaluate(X_test, y_test)\n",
    "    resultados_neuronas.append((loss,acc))\n",
    "    clear_session()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>loss</th>\n",
       "      <th>acc</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>13 neuronas</th>\n",
       "      <td>0.536277</td>\n",
       "      <td>0.721660</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18 neuronas</th>\n",
       "      <td>0.531959</td>\n",
       "      <td>0.727227</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>40 neuronas</th>\n",
       "      <td>0.532938</td>\n",
       "      <td>0.717611</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                 loss       acc\n",
       "13 neuronas  0.536277  0.721660\n",
       "18 neuronas  0.531959  0.727227\n",
       "40 neuronas  0.532938  0.717611"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tabla2 = pd.DataFrame(resultados_neuronas, index =['13 neuronas', '18 neuronas', '40 neuronas'], columns = ['loss', 'acc'])\n",
    "tabla2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[]"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "neuronas = [13,18,40]\n",
    "seg_resultados = [l[1] for l in resultados_neuronas]\n",
    "plt.scatter(neuronas,seg_resultados,c = 'b')\n",
    "plt.plot()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Primer dataset distribuyendo neuronas a traves de las capas"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 00020: early stopping\n",
      "1976/1976 [==============================] - 0s 52us/step\n",
      "Epoch 00036: early stopping\n",
      "1976/1976 [==============================] - 0s 50us/step\n",
      "Epoch 00070: early stopping\n",
      "1976/1976 [==============================] - 0s 54us/step\n",
      "Epoch 00016: early stopping\n",
      "1976/1976 [==============================] - 0s 58us/step\n",
      "Epoch 00016: early stopping\n",
      "1976/1976 [==============================] - 0s 59us/step\n",
      "Epoch 00075: early stopping\n",
      "1976/1976 [==============================] - 0s 60us/step\n",
      "Epoch 00089: early stopping\n",
      "1976/1976 [==============================] - 0s 61us/step\n",
      "Epoch 00016: early stopping\n",
      "1976/1976 [==============================] - 0s 55us/step\n",
      "Epoch 00017: early stopping\n",
      "1976/1976 [==============================] - 0s 66us/step\n",
      "Epoch 00016: early stopping\n",
      "1976/1976 [==============================] - 0s 71us/step\n"
     ]
    }
   ],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(df1, df2, test_size=0.2)\n",
    "#model = Sequential()\n",
    "#model.add(Dense(22,input_shape=(25,), activation = 'relu'))\n",
    "capas = [1,2,3,4,5,6,7,8,9,10]\n",
    "resultados_nc = []\n",
    "neuronas = 14\n",
    "for j in range(0,len(capas)):\n",
    "    model = Sequential()\n",
    "    neuro = neuronas//capas[j]\n",
    "    model.add(Dense(neuro,input_shape=(25,), activation = 'relu'))\n",
    "    for i in range(0,capas[j]):\n",
    "        model.add(Dense(neuro,activation = 'relu'))\n",
    "    model.add(Dense(1,activation='sigmoid'))\n",
    "    model.compile(loss='binary_crossentropy', optimizer=Adam(lr=0.001), metrics = ['accuracy'])\n",
    "    earlystopper = EarlyStopping(monitor='val_loss', min_delta=0, patience=15, verbose=1, mode='auto')\n",
    "    history = model.fit(X_train, y_train, epochs = 2000, validation_split = 0.15, verbose = 0, \n",
    "                    callbacks = [earlystopper])\n",
    "    loss, acc = model.evaluate(X_test, y_test)\n",
    "    resultados_nc.append((loss,acc))\n",
    "    clear_session()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "resultados_nc = [l[1] for l in resultados_nc]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[]"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.scatter(capas,resultados_nc,c = 'b')\n",
    "plt.plot()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "Mro0DvciPO8t"
   },
   "source": [
    "## Dataset real 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {
    "colab_type": "text",
    "id": "Mro0DvciPO8t"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>backers</th>\n",
       "      <th>usd_pledged_real</th>\n",
       "      <th>usd_goal_real</th>\n",
       "      <th>days</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>backers</th>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.752539</td>\n",
       "      <td>0.004517</td>\n",
       "      <td>-0.000792</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>usd_pledged_real</th>\n",
       "      <td>0.752539</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.005596</td>\n",
       "      <td>0.000946</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>usd_goal_real</th>\n",
       "      <td>0.004517</td>\n",
       "      <td>0.005596</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.004184</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>days</th>\n",
       "      <td>-0.000792</td>\n",
       "      <td>0.000946</td>\n",
       "      <td>0.004184</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                   backers  usd_pledged_real  usd_goal_real      days\n",
       "backers           1.000000          0.752539       0.004517 -0.000792\n",
       "usd_pledged_real  0.752539          1.000000       0.005596  0.000946\n",
       "usd_goal_real     0.004517          0.005596       1.000000  0.004184\n",
       "days             -0.000792          0.000946       0.004184  1.000000"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data = pd.read_csv('ks.csv',\n",
    "                 parse_dates=['deadline', 'launched'])\n",
    "\n",
    "data.drop('ID', axis = 1, inplace = True)\n",
    "data.drop('goal', axis = 1, inplace = True)\n",
    "data.drop('pledged', axis = 1, inplace = True)\n",
    "data.drop('usd pledged', axis = 1, inplace = True)\n",
    "\n",
    "data['deadline']=pd.to_datetime(data['deadline'], format=\"%Y/%m/%d\").dt.date\n",
    "data['launched']=pd.to_datetime(data['launched'], format=\"%Y/%m/%d\").dt.date\n",
    "\n",
    "data['days'] = (data['deadline'] - data['launched']).dt.days\n",
    "data['launch_year']=pd.to_datetime(data['launched'], format=\"%Y/%m/%d\").dt.year\n",
    "\n",
    "data[\"launch_year\"]=data['launch_year'].apply(str)\n",
    "\n",
    "data.corr()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {
    "colab_type": "text",
    "id": "Mro0DvciPO8t"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>backers</th>\n",
       "      <th>usd_pledged_real</th>\n",
       "      <th>usd_goal_real</th>\n",
       "      <th>days</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>backers</th>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.752539</td>\n",
       "      <td>0.004517</td>\n",
       "      <td>-0.000792</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>usd_pledged_real</th>\n",
       "      <td>0.752539</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.005596</td>\n",
       "      <td>0.000946</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>usd_goal_real</th>\n",
       "      <td>0.004517</td>\n",
       "      <td>0.005596</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.004184</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>days</th>\n",
       "      <td>-0.000792</td>\n",
       "      <td>0.000946</td>\n",
       "      <td>0.004184</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                   backers  usd_pledged_real  usd_goal_real      days\n",
       "backers           1.000000          0.752539       0.004517 -0.000792\n",
       "usd_pledged_real  0.752539          1.000000       0.005596  0.000946\n",
       "usd_goal_real     0.004517          0.005596       1.000000  0.004184\n",
       "days             -0.000792          0.000946       0.004184  1.000000"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data_for_model = pd.read_csv('ks.csv')\n",
    "\n",
    "#Datetime Processing\n",
    "data_for_model['deadline']=pd.to_datetime(data_for_model['deadline'], format=\"%Y/%m/%d\")\n",
    "data_for_model['launched']=pd.to_datetime(data_for_model['launched'], format=\"%Y/%m/%d\")\n",
    "\n",
    "data_for_model['days'] = (data_for_model['deadline'] - data_for_model['launched']).dt.days\n",
    "data_for_model['launch_year']=pd.to_datetime(data_for_model['launched'], format=\"%Y/%m/%d\").dt.year\n",
    "data_for_model.drop(['ID',\"name\",\"category\",\"launched\",\"currency\",\"deadline\",\"usd pledged\",\"goal\",\"pledged\"], axis = 1, inplace = True)\n",
    "\n",
    "data_for_model[\"launch_year\"]=data_for_model['launch_year'].apply(str) #it has to be string.\n",
    "\n",
    "data_for_model.corr()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {
    "colab_type": "text",
    "id": "Mro0DvciPO8t"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Unbalanced Data shape 378661\n",
      "Balanced data shape: 378661\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "successful    133956\n",
       "failed        133956\n",
       "Name: state, dtype: int64"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "print(\"Unbalanced Data shape\", len(data))\n",
    "datafail = data_for_model[data_for_model.state == \"failed\"]\n",
    "datasuccess = data_for_model[data_for_model.state == \"successful\"]\n",
    "data_for_model = pd.concat([datafail.sample(len(datasuccess), random_state=5), datasuccess])\n",
    "print(\"Balanced data shape:\", len(data))\n",
    "data_for_model.state.value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {
    "colab_type": "text",
    "id": "Mro0DvciPO8t"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>main_category</th>\n",
       "      <th>state</th>\n",
       "      <th>backers</th>\n",
       "      <th>country</th>\n",
       "      <th>usd_pledged_real</th>\n",
       "      <th>usd_goal_real</th>\n",
       "      <th>days</th>\n",
       "      <th>launch_year</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>284067</th>\n",
       "      <td>Publishing</td>\n",
       "      <td>0</td>\n",
       "      <td>13</td>\n",
       "      <td>SE</td>\n",
       "      <td>312.18</td>\n",
       "      <td>860.15</td>\n",
       "      <td>39</td>\n",
       "      <td>2017</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>281299</th>\n",
       "      <td>Film &amp; Video</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>US</td>\n",
       "      <td>10.00</td>\n",
       "      <td>100000.00</td>\n",
       "      <td>29</td>\n",
       "      <td>2015</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6785</th>\n",
       "      <td>Music</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>US</td>\n",
       "      <td>550.00</td>\n",
       "      <td>4000.00</td>\n",
       "      <td>29</td>\n",
       "      <td>2012</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>220548</th>\n",
       "      <td>Design</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>US</td>\n",
       "      <td>200.00</td>\n",
       "      <td>2750.00</td>\n",
       "      <td>29</td>\n",
       "      <td>2013</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>301405</th>\n",
       "      <td>Games</td>\n",
       "      <td>0</td>\n",
       "      <td>5</td>\n",
       "      <td>MX</td>\n",
       "      <td>47.69</td>\n",
       "      <td>4841.44</td>\n",
       "      <td>44</td>\n",
       "      <td>2016</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       main_category  state  backers country  usd_pledged_real  usd_goal_real  \\\n",
       "284067    Publishing      0       13      SE            312.18         860.15   \n",
       "281299  Film & Video      0        1      US             10.00      100000.00   \n",
       "6785           Music      0        2      US            550.00        4000.00   \n",
       "220548        Design      0        1      US            200.00        2750.00   \n",
       "301405         Games      0        5      MX             47.69        4841.44   \n",
       "\n",
       "        days launch_year  \n",
       "284067    39        2017  \n",
       "281299    29        2015  \n",
       "6785      29        2012  \n",
       "220548    29        2013  \n",
       "301405    44        2016  "
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def state_process(cell_value):\n",
    "    if cell_value == 'successful':\n",
    "        return 1\n",
    "    else:\n",
    "        return 0    \n",
    "data_for_model.state = data_for_model.state.apply(state_process)\n",
    "data_for_model.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {
    "colab_type": "text",
    "id": "Mro0DvciPO8t"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Original Features:\n",
      " ['name', 'category', 'main_category', 'currency', 'deadline', 'launched', 'state', 'backers', 'country', 'usd_pledged_real', 'usd_goal_real', 'days', 'launch_year'] \n",
      "\n",
      "Features after One-Hot Encoding:\n",
      " ['state', 'backers', 'usd_pledged_real', 'usd_goal_real', 'days', 'main_category_Art', 'main_category_Comics', 'main_category_Crafts', 'main_category_Dance', 'main_category_Design', 'main_category_Fashion', 'main_category_Film & Video', 'main_category_Food', 'main_category_Games', 'main_category_Journalism', 'main_category_Music', 'main_category_Photography', 'main_category_Publishing', 'main_category_Technology', 'main_category_Theater', 'country_AT', 'country_AU', 'country_BE', 'country_CA', 'country_CH', 'country_DE', 'country_DK', 'country_ES', 'country_FR', 'country_GB', 'country_HK', 'country_IE', 'country_IT', 'country_JP', 'country_LU', 'country_MX', 'country_N,0\"', 'country_NL', 'country_NO', 'country_NZ', 'country_SE', 'country_SG', 'country_US', 'launch_year_2009', 'launch_year_2010', 'launch_year_2011', 'launch_year_2012', 'launch_year_2013', 'launch_year_2014', 'launch_year_2015', 'launch_year_2016', 'launch_year_2017']\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(267912, 52)"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "print('Original Features:\\n', list(data.columns), '\\n')\n",
    "data_for_model= pd.get_dummies(data_for_model)\n",
    "print('Features after One-Hot Encoding:\\n', list(data_for_model.columns))\n",
    "data_for_model.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {
    "colab_type": "text",
    "id": "Mro0DvciPO8t"
   },
   "outputs": [],
   "source": [
    "def ANN_regresion_nN(X, y, input_dim, neurons=2, layers=1, activation='relu', epochs=10, batch_size=100, verbose=2):\n",
    "    \n",
    "    X_train, X_test, y_train, y_test = train_test_split(X, y, test_size = 0.20, random_state = 0)\n",
    "    \n",
    "    scaler = MinMaxScaler((-1,1))\n",
    "    X_train_scaled = scaler.fit_transform(X_train)\n",
    "    X_test_scaled = scaler.transform(X_test)\n",
    "    \n",
    "    model = Sequential()\n",
    "    neurons = int(np.round(neurons/layers)) if neurons > 1 else 1\n",
    "    model.add(Dense(units=neurons, input_dim=input_dim, activation='relu'))\n",
    "    for i in range(layers-1):\n",
    "        model.add(Dense(units=neurons, activation='relu'))\n",
    "    model.add(Dense(units=1, activation='sigmoid'))\n",
    "    \n",
    "    model.compile(loss='binary_crossentropy', optimizer='adam', metrics=['accuracy'])\n",
    "    model.fit(X_train, y_train, epochs=epochs, batch_size=batch_size, verbose=verbose)\n",
    "    \n",
    "    y_pred = model.predict(X_test, batch_size = batch_size)\n",
    "    y_pred = (y_pred > 0.5)\n",
    "    \n",
    "    return y_pred, y_test\n",
    "\n",
    "def ANN_regresion_nlayer(X, y, input_dim, layers, neurons=2 , activation='relu', epochs=10, batch_size=100, verbose=2):\n",
    "    \n",
    "    X_train, X_test, y_train, y_test = train_test_split(X, y, test_size = 0.20, random_state = 0)\n",
    "    \n",
    "    scaler = MinMaxScaler((-1,1))\n",
    "    X_train_scaled = scaler.fit_transform(X_train)\n",
    "    X_test_scaled = scaler.transform(X_test)\n",
    "    \n",
    "    model = Sequential()\n",
    "    model.add(Dense(units=neurons, input_dim=input_dim, activation='relu'))\n",
    "    for i in range(layers-1):\n",
    "        model.add(Dense(units=neurons, activation='relu'))\n",
    "    model.add(Dense(units=1, activation='sigmoid'))\n",
    "    \n",
    "    model.compile(loss='binary_crossentropy', optimizer='adam', metrics=['accuracy'])\n",
    "    model.fit(X_train, y_train, epochs=epochs, batch_size=batch_size, verbose=verbose)\n",
    "    \n",
    "    y_pred = model.predict(X_test, batch_size = batch_size)\n",
    "    y_pred = (y_pred > 0.5)\n",
    "    \n",
    "    return y_pred, y_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {
    "colab_type": "text",
    "id": "Mro0DvciPO8t"
   },
   "outputs": [],
   "source": [
    "from sklearn import metrics\n",
    "\n",
    "X = data_for_model.iloc[:,data_for_model.columns != 'state']\n",
    "y = data_for_model.state"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {
    "colab_type": "text",
    "id": "Mro0DvciPO8t"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1\n",
      "Epoch 1/10\n",
      "214329/214329 [==============================] - 8s 37us/step - loss: 0.2586 - accuracy: 0.9624\n",
      "Epoch 2/10\n",
      "214329/214329 [==============================] - 8s 36us/step - loss: 0.1020 - accuracy: 0.9868\n",
      "Epoch 3/10\n",
      "214329/214329 [==============================] - 8s 36us/step - loss: 0.0452 - accuracy: 0.9956\n",
      "Epoch 4/10\n",
      "214329/214329 [==============================] - 8s 36us/step - loss: 0.0458 - accuracy: 0.9940\n",
      "Epoch 5/10\n",
      "214329/214329 [==============================] - 8s 36us/step - loss: 0.0419 - accuracy: 0.9929\n",
      "Epoch 6/10\n",
      "214329/214329 [==============================] - 8s 36us/step - loss: 0.0326 - accuracy: 0.9943\n",
      "Epoch 7/10\n",
      "214329/214329 [==============================] - 8s 36us/step - loss: 0.0168 - accuracy: 0.9975\n",
      "Epoch 8/10\n",
      "214329/214329 [==============================] - 8s 36us/step - loss: 0.0196 - accuracy: 0.9972\n",
      "Epoch 9/10\n",
      "214329/214329 [==============================] - 8s 36us/step - loss: 0.0239 - accuracy: 0.9963\n",
      "Epoch 10/10\n",
      "214329/214329 [==============================] - 8s 36us/step - loss: 0.0213 - accuracy: 0.9973\n",
      "score: 99.84510663160904%\n",
      "2\n",
      "Epoch 1/10\n",
      "214329/214329 [==============================] - 8s 37us/step - loss: 25.1803 - accuracy: 0.4859\n",
      "Epoch 2/10\n",
      "214329/214329 [==============================] - 8s 37us/step - loss: 0.6961 - accuracy: 0.4988\n",
      "Epoch 3/10\n",
      "214329/214329 [==============================] - 8s 36us/step - loss: 0.6940 - accuracy: 0.5006\n",
      "Epoch 4/10\n",
      "214329/214329 [==============================] - 8s 36us/step - loss: 0.6932 - accuracy: 0.5015\n",
      "Epoch 5/10\n",
      "214329/214329 [==============================] - 8s 36us/step - loss: 0.6932 - accuracy: 0.5001\n",
      "Epoch 6/10\n",
      "214329/214329 [==============================] - 8s 36us/step - loss: 0.6932 - accuracy: 0.4988\n",
      "Epoch 7/10\n",
      "214329/214329 [==============================] - 8s 37us/step - loss: 0.6932 - accuracy: 0.5001\n",
      "Epoch 8/10\n",
      "214329/214329 [==============================] - 8s 36us/step - loss: 0.6932 - accuracy: 0.5002\n",
      "Epoch 9/10\n",
      "214329/214329 [==============================] - 8s 36us/step - loss: 0.6932 - accuracy: 0.4993\n",
      "Epoch 10/10\n",
      "214329/214329 [==============================] - 8s 36us/step - loss: 0.6932 - accuracy: 0.4989\n",
      "score: 50.0%\n",
      "3\n",
      "Epoch 1/10\n",
      "214329/214329 [==============================] - 8s 37us/step - loss: 61.3214 - accuracy: 0.6646\n",
      "Epoch 2/10\n",
      "214329/214329 [==============================] - 8s 37us/step - loss: 0.1011 - accuracy: 0.9927\n",
      "Epoch 3/10\n",
      "214329/214329 [==============================] - 8s 37us/step - loss: 0.0508 - accuracy: 0.9943\n",
      "Epoch 4/10\n",
      "214329/214329 [==============================] - 8s 37us/step - loss: 0.0285 - accuracy: 0.9975\n",
      "Epoch 5/10\n",
      "214329/214329 [==============================] - 8s 37us/step - loss: 0.0456 - accuracy: 0.9920\n",
      "Epoch 6/10\n",
      "214329/214329 [==============================] - 8s 37us/step - loss: 0.0213 - accuracy: 0.9971\n",
      "Epoch 7/10\n",
      "214329/214329 [==============================] - 8s 37us/step - loss: 0.0353 - accuracy: 0.9942\n",
      "Epoch 8/10\n",
      "214329/214329 [==============================] - 8s 37us/step - loss: 0.0182 - accuracy: 0.9973\n",
      "Epoch 9/10\n",
      "214329/214329 [==============================] - 8s 37us/step - loss: 0.0185 - accuracy: 0.9971\n",
      "Epoch 10/10\n",
      "214329/214329 [==============================] - 8s 37us/step - loss: 0.0213 - accuracy: 0.9968\n",
      "score: 99.84323691986626%\n",
      "4\n",
      "Epoch 1/10\n",
      "214329/214329 [==============================] - 8s 38us/step - loss: 292.6991 - accuracy: 0.4919\n",
      "Epoch 2/10\n",
      "214329/214329 [==============================] - 8s 37us/step - loss: 0.2975 - accuracy: 0.9128\n",
      "Epoch 3/10\n",
      "214329/214329 [==============================] - 8s 37us/step - loss: 0.2072 - accuracy: 0.9293\n",
      "Epoch 4/10\n",
      "214329/214329 [==============================] - 8s 37us/step - loss: 0.1126 - accuracy: 0.9643\n",
      "Epoch 5/10\n",
      "214329/214329 [==============================] - 8s 37us/step - loss: 0.0303 - accuracy: 0.9949\n",
      "Epoch 6/10\n",
      "214329/214329 [==============================] - 8s 37us/step - loss: 0.0108 - accuracy: 0.9981\n",
      "Epoch 7/10\n",
      "214329/214329 [==============================] - 8s 37us/step - loss: 0.0101 - accuracy: 0.9981\n",
      "Epoch 8/10\n",
      "214329/214329 [==============================] - 8s 37us/step - loss: 0.0083 - accuracy: 0.9987\n",
      "Epoch 9/10\n",
      "214329/214329 [==============================] - 8s 37us/step - loss: 0.0087 - accuracy: 0.9984\n",
      "Epoch 10/10\n",
      "214329/214329 [==============================] - 8s 38us/step - loss: 0.0054 - accuracy: 0.9988\n",
      "score: 99.9402849274908%\n",
      "5\n",
      "Epoch 1/10\n",
      "214329/214329 [==============================] - 8s 38us/step - loss: 130.2752 - accuracy: 0.9542\n",
      "Epoch 2/10\n",
      "214329/214329 [==============================] - 8s 37us/step - loss: 0.0136 - accuracy: 0.9979\n",
      "Epoch 3/10\n",
      "214329/214329 [==============================] - 8s 37us/step - loss: 0.0267 - accuracy: 0.9978\n",
      "Epoch 4/10\n",
      "214329/214329 [==============================] - 8s 37us/step - loss: 0.0466 - accuracy: 0.9976\n",
      "Epoch 5/10\n",
      "214329/214329 [==============================] - 8s 37us/step - loss: 0.0209 - accuracy: 0.9986\n",
      "Epoch 6/10\n",
      "214329/214329 [==============================] - 8s 37us/step - loss: 0.1370 - accuracy: 0.9972\n",
      "Epoch 7/10\n",
      "214329/214329 [==============================] - 8s 38us/step - loss: 0.1480 - accuracy: 0.9985\n",
      "Epoch 8/10\n",
      "214329/214329 [==============================] - 8s 37us/step - loss: 0.0587 - accuracy: 0.9985\n",
      "Epoch 9/10\n",
      "214329/214329 [==============================] - 8s 37us/step - loss: 0.1151 - accuracy: 0.9981\n",
      "Epoch 10/10\n",
      "214329/214329 [==============================] - 8s 37us/step - loss: 0.0360 - accuracy: 0.9991\n",
      "score: 99.94028262875054%\n",
      "6\n",
      "Epoch 1/10\n",
      "214329/214329 [==============================] - 8s 38us/step - loss: 4.2184 - accuracy: 0.9853\n",
      "Epoch 2/10\n",
      "214329/214329 [==============================] - 8s 37us/step - loss: 0.0649 - accuracy: 0.9976\n",
      "Epoch 3/10\n",
      "214329/214329 [==============================] - 8s 37us/step - loss: 0.0554 - accuracy: 0.9985\n",
      "Epoch 4/10\n",
      "214329/214329 [==============================] - 8s 37us/step - loss: 0.0329 - accuracy: 0.9986\n",
      "Epoch 5/10\n",
      "214329/214329 [==============================] - 8s 37us/step - loss: 0.0920 - accuracy: 0.9980\n",
      "Epoch 6/10\n",
      "214329/214329 [==============================] - 8s 37us/step - loss: 0.0417 - accuracy: 0.9990\n",
      "Epoch 7/10\n",
      "214329/214329 [==============================] - 8s 37us/step - loss: 0.1115 - accuracy: 0.9985\n",
      "Epoch 8/10\n",
      "214329/214329 [==============================] - 8s 37us/step - loss: 0.1054 - accuracy: 0.9986\n",
      "Epoch 9/10\n",
      "214329/214329 [==============================] - 8s 37us/step - loss: 0.1313 - accuracy: 0.9986\n",
      "Epoch 10/10\n",
      "214329/214329 [==============================] - 8s 37us/step - loss: 0.0452 - accuracy: 0.9992\n",
      "score: 99.94028416124404%\n",
      "7\n",
      "Epoch 1/10\n",
      "214329/214329 [==============================] - 8s 39us/step - loss: 46.7987 - accuracy: 0.9688\n",
      "Epoch 2/10\n",
      "214329/214329 [==============================] - 8s 38us/step - loss: 0.0266 - accuracy: 0.9981\n",
      "Epoch 3/10\n",
      "214329/214329 [==============================] - 8s 38us/step - loss: 0.0641 - accuracy: 0.9988\n",
      "Epoch 4/10\n",
      "214329/214329 [==============================] - 8s 38us/step - loss: 0.0520 - accuracy: 0.9988\n",
      "Epoch 5/10\n",
      "214329/214329 [==============================] - 8s 37us/step - loss: 0.0734 - accuracy: 0.9990\n",
      "Epoch 6/10\n",
      "214329/214329 [==============================] - 8s 38us/step - loss: 0.0419 - accuracy: 0.9991\n",
      "Epoch 7/10\n",
      "214329/214329 [==============================] - 8s 38us/step - loss: 0.0309 - accuracy: 0.9993\n",
      "Epoch 8/10\n",
      "214329/214329 [==============================] - 8s 37us/step - loss: 0.0644 - accuracy: 0.9988\n",
      "Epoch 9/10\n",
      "214329/214329 [==============================] - 8s 39us/step - loss: 0.0590 - accuracy: 0.9988\n",
      "Epoch 10/10\n",
      "214329/214329 [==============================] - 8s 37us/step - loss: 0.0355 - accuracy: 0.9993\n",
      "score: 99.93467885724947%\n",
      "8\n",
      "Epoch 1/10\n",
      "214329/214329 [==============================] - 8s 38us/step - loss: 0.0778 - accuracy: 0.9971\n",
      "Epoch 2/10\n",
      "214329/214329 [==============================] - 8s 38us/step - loss: 0.0312 - accuracy: 0.9994\n",
      "Epoch 3/10\n",
      "214329/214329 [==============================] - 8s 38us/step - loss: 0.0503 - accuracy: 0.9992\n",
      "Epoch 4/10\n",
      "214329/214329 [==============================] - 8s 38us/step - loss: 0.0197 - accuracy: 0.9995\n",
      "Epoch 5/10\n",
      "214329/214329 [==============================] - 8s 38us/step - loss: 0.0444 - accuracy: 0.9991\n",
      "Epoch 6/10\n",
      "214329/214329 [==============================] - 8s 37us/step - loss: 0.0266 - accuracy: 0.9992\n",
      "Epoch 7/10\n",
      "214329/214329 [==============================] - 8s 37us/step - loss: 0.0507 - accuracy: 0.9991\n",
      "Epoch 8/10\n",
      "214329/214329 [==============================] - 8s 38us/step - loss: 0.0247 - accuracy: 0.9994\n",
      "Epoch 9/10\n",
      "214329/214329 [==============================] - 8s 37us/step - loss: 0.0300 - accuracy: 0.9994\n",
      "Epoch 10/10\n",
      "214329/214329 [==============================] - 8s 37us/step - loss: 0.0328 - accuracy: 0.9994\n",
      "score: 99.96640955335725%\n",
      "9\n",
      "Epoch 1/10\n",
      "214329/214329 [==============================] - 8s 39us/step - loss: 350.8640 - accuracy: 0.9343\n",
      "Epoch 2/10\n",
      "214329/214329 [==============================] - 8s 38us/step - loss: 0.0618 - accuracy: 0.9982\n",
      "Epoch 3/10\n",
      "214329/214329 [==============================] - 8s 38us/step - loss: 0.0353 - accuracy: 0.9990\n",
      "Epoch 4/10\n",
      "214329/214329 [==============================] - 8s 38us/step - loss: 0.0655 - accuracy: 0.9991\n",
      "Epoch 5/10\n",
      "214329/214329 [==============================] - 8s 38us/step - loss: 0.0274 - accuracy: 0.9992\n",
      "Epoch 6/10\n",
      "214329/214329 [==============================] - 8s 38us/step - loss: 0.0926 - accuracy: 0.9991\n",
      "Epoch 7/10\n",
      "214329/214329 [==============================] - 8s 38us/step - loss: 0.0637 - accuracy: 0.9992\n",
      "Epoch 8/10\n",
      "214329/214329 [==============================] - 8s 38us/step - loss: 0.0422 - accuracy: 0.9995\n",
      "Epoch 9/10\n",
      "214329/214329 [==============================] - 8s 38us/step - loss: 0.0729 - accuracy: 0.9991\n",
      "Epoch 10/10\n",
      "214329/214329 [==============================] - 8s 38us/step - loss: 0.0681 - accuracy: 0.9994\n",
      "score: 99.89177893047729%\n"
     ]
    }
   ],
   "source": [
    "y_pred_list_1layer = []\n",
    "for i in range(1,10):\n",
    "    print(i)\n",
    "    y_predict, y_test = ANN_regresion_nlayer(X, y, X.shape[1], layers=1, neurons=i , activation='relu', epochs=10, batch_size=100, verbose=1)\n",
    "    score = metrics.roc_auc_score(y_test, y_predict)\n",
    "    \n",
    "    print(f'score: {score*100}%')\n",
    "    y_pred_list_1layer.append(score)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {
    "colab_type": "text",
    "id": "Mro0DvciPO8t"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1\n",
      "Epoch 1/10\n",
      "214329/214329 [==============================] - 9s 40us/step - loss: 30.5858 - accuracy: 0.9797\n",
      "Epoch 2/10\n",
      "214329/214329 [==============================] - 8s 38us/step - loss: 0.0594 - accuracy: 0.9982\n",
      "Epoch 3/10\n",
      "214329/214329 [==============================] - 8s 38us/step - loss: 0.0400 - accuracy: 0.9986\n",
      "Epoch 4/10\n",
      "214329/214329 [==============================] - 8s 38us/step - loss: 0.0833 - accuracy: 0.9987\n",
      "Epoch 5/10\n",
      "214329/214329 [==============================] - 8s 38us/step - loss: 0.0531 - accuracy: 0.9992\n",
      "Epoch 6/10\n",
      "214329/214329 [==============================] - 8s 38us/step - loss: 0.0429 - accuracy: 0.9995\n",
      "Epoch 7/10\n",
      "214329/214329 [==============================] - 8s 38us/step - loss: 0.0619 - accuracy: 0.9994\n",
      "Epoch 8/10\n",
      "214329/214329 [==============================] - 8s 39us/step - loss: 0.0649 - accuracy: 0.9993\n",
      "Epoch 9/10\n",
      "214329/214329 [==============================] - 8s 38us/step - loss: 0.1263 - accuracy: 0.9993\n",
      "Epoch 10/10\n",
      "214329/214329 [==============================] - 8s 38us/step - loss: 0.0873 - accuracy: 0.9992\n",
      "score: 99.9552066078356%\n",
      "2\n",
      "Epoch 1/10\n",
      "214329/214329 [==============================] - 9s 43us/step - loss: 14.0033 - accuracy: 0.9902\n",
      "Epoch 2/10\n",
      "214329/214329 [==============================] - 9s 43us/step - loss: 0.0137 - accuracy: 0.9979\n",
      "Epoch 3/10\n",
      "214329/214329 [==============================] - 9s 42us/step - loss: 0.0149 - accuracy: 0.9984\n",
      "Epoch 4/10\n",
      "214329/214329 [==============================] - 9s 43us/step - loss: 0.0161 - accuracy: 0.9986\n",
      "Epoch 5/10\n",
      "214329/214329 [==============================] - 9s 43us/step - loss: 0.0303 - accuracy: 0.9985\n",
      "Epoch 6/10\n",
      "214329/214329 [==============================] - 9s 42us/step - loss: 0.0155 - accuracy: 0.9988\n",
      "Epoch 7/10\n",
      "214329/214329 [==============================] - 9s 43us/step - loss: 0.0124 - accuracy: 0.9988\n",
      "Epoch 8/10\n",
      "214329/214329 [==============================] - 11s 53us/step - loss: 0.0197 - accuracy: 0.9988\n",
      "Epoch 9/10\n",
      "214329/214329 [==============================] - 12s 56us/step - loss: 0.0110 - accuracy: 0.9992\n",
      "Epoch 10/10\n",
      "214329/214329 [==============================] - 13s 59us/step - loss: 0.0172 - accuracy: 0.9990\n",
      "score: 99.91230284982966%\n",
      "3\n",
      "Epoch 1/10\n",
      "214329/214329 [==============================] - 11s 51us/step - loss: 5.9288 - accuracy: 0.9657\n",
      "Epoch 2/10\n",
      "214329/214329 [==============================] - 10s 46us/step - loss: 0.0745 - accuracy: 0.9961\n",
      "Epoch 3/10\n",
      "214329/214329 [==============================] - 10s 45us/step - loss: 0.0323 - accuracy: 0.9969\n",
      "Epoch 4/10\n",
      "214329/214329 [==============================] - 12s 58us/step - loss: 0.0163 - accuracy: 0.9981\n",
      "Epoch 5/10\n",
      "214329/214329 [==============================] - 10s 46us/step - loss: 0.0223 - accuracy: 0.9964\n",
      "Epoch 6/10\n",
      "214329/214329 [==============================] - 10s 46us/step - loss: 0.0235 - accuracy: 0.9963\n",
      "Epoch 7/10\n",
      "214329/214329 [==============================] - 10s 46us/step - loss: 0.0188 - accuracy: 0.9971\n",
      "Epoch 8/10\n",
      "214329/214329 [==============================] - 10s 46us/step - loss: 0.0108 - accuracy: 0.9986\n",
      "Epoch 9/10\n",
      "214329/214329 [==============================] - 10s 46us/step - loss: 0.0157 - accuracy: 0.9976\n",
      "Epoch 10/10\n",
      "214329/214329 [==============================] - 10s 46us/step - loss: 0.0092 - accuracy: 0.9985\n",
      "score: 99.95147867805136%\n",
      "4\n",
      "Epoch 1/10\n",
      "214329/214329 [==============================] - 11s 52us/step - loss: 0.0737 - accuracy: 0.9975\n",
      "Epoch 2/10\n",
      "214329/214329 [==============================] - 11s 51us/step - loss: 0.0060 - accuracy: 0.9990\n",
      "Epoch 3/10\n",
      "214329/214329 [==============================] - 11s 50us/step - loss: 0.0041 - accuracy: 0.9995\n",
      "Epoch 4/10\n",
      "214329/214329 [==============================] - 11s 50us/step - loss: 0.0048 - accuracy: 0.9996\n",
      "Epoch 5/10\n",
      "214329/214329 [==============================] - 11s 50us/step - loss: 0.0045 - accuracy: 0.9995\n",
      "Epoch 6/10\n",
      "214329/214329 [==============================] - 11s 50us/step - loss: 0.0043 - accuracy: 0.9996\n",
      "Epoch 7/10\n",
      "214329/214329 [==============================] - 11s 50us/step - loss: 0.0035 - accuracy: 0.9997\n",
      "Epoch 8/10\n",
      "214329/214329 [==============================] - 11s 50us/step - loss: 0.0046 - accuracy: 0.9995\n",
      "Epoch 9/10\n",
      "214329/214329 [==============================] - 11s 50us/step - loss: 0.0070 - accuracy: 0.9990\n",
      "Epoch 10/10\n",
      "214329/214329 [==============================] - 11s 50us/step - loss: 0.0093 - accuracy: 0.9994\n",
      "score: 99.96640648837023%\n",
      "5\n",
      "Epoch 1/10\n",
      "214329/214329 [==============================] - 12s 56us/step - loss: 0.6932 - accuracy: 0.4999\n",
      "Epoch 2/10\n",
      "214329/214329 [==============================] - 13s 62us/step - loss: 0.6932 - accuracy: 0.4999\n",
      "Epoch 3/10\n",
      "214329/214329 [==============================] - 12s 54us/step - loss: 0.6932 - accuracy: 0.4987\n",
      "Epoch 4/10\n",
      "214329/214329 [==============================] - 12s 54us/step - loss: 0.6932 - accuracy: 0.4997\n",
      "Epoch 5/10\n",
      "214329/214329 [==============================] - 12s 54us/step - loss: 0.6932 - accuracy: 0.4994\n",
      "Epoch 6/10\n",
      "214329/214329 [==============================] - 12s 54us/step - loss: 0.6932 - accuracy: 0.4996\n",
      "Epoch 7/10\n",
      "214329/214329 [==============================] - 12s 54us/step - loss: 0.6932 - accuracy: 0.5002\n",
      "Epoch 8/10\n",
      "214329/214329 [==============================] - 12s 55us/step - loss: 0.6932 - accuracy: 0.5013\n",
      "Epoch 9/10\n",
      "214329/214329 [==============================] - 12s 54us/step - loss: 0.6932 - accuracy: 0.4977\n",
      "Epoch 10/10\n",
      "214329/214329 [==============================] - 12s 54us/step - loss: 0.6932 - accuracy: 0.4993\n",
      "score: 50.0%\n",
      "6\n",
      "Epoch 1/10\n",
      "214329/214329 [==============================] - 13s 60us/step - loss: 0.6932 - accuracy: 0.4998\n",
      "Epoch 2/10\n",
      "214329/214329 [==============================] - 13s 61us/step - loss: 0.6932 - accuracy: 0.4988\n",
      "Epoch 3/10\n",
      "214329/214329 [==============================] - 13s 59us/step - loss: 0.6932 - accuracy: 0.4994\n",
      "Epoch 4/10\n",
      "214329/214329 [==============================] - 12s 58us/step - loss: 0.6932 - accuracy: 0.4984\n",
      "Epoch 5/10\n",
      "214329/214329 [==============================] - 13s 58us/step - loss: 0.6932 - accuracy: 0.4989\n",
      "Epoch 6/10\n",
      "214329/214329 [==============================] - 12s 58us/step - loss: 0.6932 - accuracy: 0.5015\n",
      "Epoch 7/10\n",
      "214329/214329 [==============================] - 12s 58us/step - loss: 0.6932 - accuracy: 0.4986\n",
      "Epoch 8/10\n",
      "214329/214329 [==============================] - 12s 58us/step - loss: 0.6932 - accuracy: 0.4990\n",
      "Epoch 9/10\n",
      "214329/214329 [==============================] - 13s 58us/step - loss: 0.6932 - accuracy: 0.4996\n",
      "Epoch 10/10\n",
      "214329/214329 [==============================] - 12s 58us/step - loss: 0.6932 - accuracy: 0.4993\n",
      "score: 50.0%\n",
      "7\n",
      "Epoch 1/10\n",
      "214329/214329 [==============================] - 14s 63us/step - loss: 0.6932 - accuracy: 0.5004\n",
      "Epoch 2/10\n",
      "214329/214329 [==============================] - 14s 63us/step - loss: 0.6932 - accuracy: 0.4993\n",
      "Epoch 3/10\n",
      "214329/214329 [==============================] - 13s 62us/step - loss: 0.6932 - accuracy: 0.5002\n",
      "Epoch 4/10\n",
      "214329/214329 [==============================] - 13s 62us/step - loss: 0.6932 - accuracy: 0.4983\n",
      "Epoch 5/10\n",
      "214329/214329 [==============================] - 13s 62us/step - loss: 0.6932 - accuracy: 0.5003\n",
      "Epoch 6/10\n",
      "214329/214329 [==============================] - 13s 62us/step - loss: 0.6932 - accuracy: 0.5005\n",
      "Epoch 7/10\n",
      "214329/214329 [==============================] - 13s 61us/step - loss: 0.6932 - accuracy: 0.4973\n",
      "Epoch 8/10\n",
      "214329/214329 [==============================] - 13s 61us/step - loss: 0.6932 - accuracy: 0.4993\n",
      "Epoch 9/10\n",
      "214329/214329 [==============================] - 13s 62us/step - loss: 0.6932 - accuracy: 0.5015\n",
      "Epoch 10/10\n",
      "214329/214329 [==============================] - 13s 63us/step - loss: 0.6932 - accuracy: 0.5001\n",
      "score: 50.0%\n",
      "8\n",
      "Epoch 1/10\n",
      "214329/214329 [==============================] - 15s 69us/step - loss: 0.6932 - accuracy: 0.5008\n",
      "Epoch 2/10\n",
      "214329/214329 [==============================] - 14s 66us/step - loss: 0.6932 - accuracy: 0.4992\n",
      "Epoch 3/10\n",
      "214329/214329 [==============================] - 14s 67us/step - loss: 0.6932 - accuracy: 0.4985\n",
      "Epoch 4/10\n",
      "214329/214329 [==============================] - 14s 66us/step - loss: 0.6932 - accuracy: 0.4981\n",
      "Epoch 5/10\n",
      "214329/214329 [==============================] - 14s 66us/step - loss: 0.6932 - accuracy: 0.5005\n",
      "Epoch 6/10\n",
      "214329/214329 [==============================] - 14s 66us/step - loss: 0.6932 - accuracy: 0.4997\n",
      "Epoch 7/10\n",
      "214329/214329 [==============================] - 14s 66us/step - loss: 0.6932 - accuracy: 0.4999\n",
      "Epoch 8/10\n",
      "214329/214329 [==============================] - 14s 66us/step - loss: 0.6932 - accuracy: 0.5000\n",
      "Epoch 9/10\n",
      "214329/214329 [==============================] - 14s 66us/step - loss: 0.6932 - accuracy: 0.5008\n",
      "Epoch 10/10\n",
      "214329/214329 [==============================] - 14s 66us/step - loss: 0.6932 - accuracy: 0.4996\n",
      "score: 50.0%\n",
      "9\n",
      "Epoch 1/10\n",
      "214329/214329 [==============================] - 16s 73us/step - loss: 0.6932 - accuracy: 0.5013\n",
      "Epoch 2/10\n",
      "214329/214329 [==============================] - 15s 70us/step - loss: 0.6932 - accuracy: 0.5000\n",
      "Epoch 3/10\n",
      "214329/214329 [==============================] - 15s 71us/step - loss: 0.6932 - accuracy: 0.5006\n",
      "Epoch 4/10\n",
      "214329/214329 [==============================] - 15s 71us/step - loss: 0.6932 - accuracy: 0.4995\n",
      "Epoch 5/10\n",
      "214329/214329 [==============================] - 15s 71us/step - loss: 0.6932 - accuracy: 0.5010\n",
      "Epoch 6/10\n",
      "214329/214329 [==============================] - 15s 71us/step - loss: 0.6932 - accuracy: 0.4994\n",
      "Epoch 7/10\n",
      "214329/214329 [==============================] - 15s 72us/step - loss: 0.6932 - accuracy: 0.4997\n",
      "Epoch 8/10\n",
      "214329/214329 [==============================] - 18s 84us/step - loss: 0.6932 - accuracy: 0.5013\n",
      "Epoch 9/10\n",
      "214329/214329 [==============================] - 17s 79us/step - loss: 0.6932 - accuracy: 0.4998\n",
      "Epoch 10/10\n",
      "214329/214329 [==============================] - 17s 80us/step - loss: 0.6932 - accuracy: 0.4996\n",
      "score: 50.0%\n"
     ]
    }
   ],
   "source": [
    "y_pred_list_nNeuron = []\n",
    "for i in range(1,10):\n",
    "    print(i)\n",
    "    y_predict, y_test = ANN_regresion_nN(X, y, X.shape[1], layers=i, neurons=10 , activation='relu', epochs=10, batch_size=100, verbose=1)\n",
    "    score = metrics.roc_auc_score(y_test, y_predict)\n",
    "    \n",
    "    print(f'score: {score*100}%')\n",
    "    y_pred_list_nNeuron.append(score)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {
    "colab_type": "text",
    "id": "Mro0DvciPO8t"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1\n",
      "Epoch 1/10\n",
      "214329/214329 [==============================] - 10s 46us/step - loss: 13.5362 - accuracy: 0.9877 1s - loss: 15\n",
      "Epoch 2/10\n",
      "214329/214329 [==============================] - 10s 46us/step - loss: 0.1092 - accuracy: 0.9981\n",
      "Epoch 3/10\n",
      "214329/214329 [==============================] - 10s 48us/step - loss: 0.0497 - accuracy: 0.9989\n",
      "Epoch 4/10\n",
      "214329/214329 [==============================] - 10s 48us/step - loss: 0.1823 - accuracy: 0.9980\n",
      "Epoch 5/10\n",
      "214329/214329 [==============================] - 11s 54us/step - loss: 0.0577 - accuracy: 0.9992\n",
      "Epoch 6/10\n",
      "214329/214329 [==============================] - 9s 43us/step - loss: 0.1768 - accuracy: 0.9989\n",
      "Epoch 7/10\n",
      "214329/214329 [==============================] - 9s 43us/step - loss: 0.0940 - accuracy: 0.9992\n",
      "Epoch 8/10\n",
      "214329/214329 [==============================] - 9s 44us/step - loss: 0.0707 - accuracy: 0.9994\n",
      "Epoch 9/10\n",
      "214329/214329 [==============================] - 9s 43us/step - loss: 0.1568 - accuracy: 0.9990\n",
      "Epoch 10/10\n",
      "214329/214329 [==============================] - 9s 43us/step - loss: 0.1271 - accuracy: 0.9989\n",
      "score: 99.95708474829271%\n",
      "2\n",
      "Epoch 1/10\n",
      "214329/214329 [==============================] - 10s 49us/step - loss: 191.6848 - accuracy: 0.9603\n",
      "Epoch 2/10\n",
      "214329/214329 [==============================] - 10s 47us/step - loss: 0.0134 - accuracy: 0.9993\n",
      "Epoch 3/10\n",
      "214329/214329 [==============================] - 10s 47us/step - loss: 0.0431 - accuracy: 0.9990\n",
      "Epoch 4/10\n",
      "214329/214329 [==============================] - 10s 47us/step - loss: 0.0292 - accuracy: 0.9993\n",
      "Epoch 5/10\n",
      "214329/214329 [==============================] - 10s 47us/step - loss: 0.0256 - accuracy: 0.9994\n",
      "Epoch 6/10\n",
      "214329/214329 [==============================] - 10s 48us/step - loss: 0.0419 - accuracy: 0.9994\n",
      "Epoch 7/10\n",
      "214329/214329 [==============================] - 10s 47us/step - loss: 0.0325 - accuracy: 0.9994\n",
      "Epoch 8/10\n",
      "214329/214329 [==============================] - 10s 48us/step - loss: 0.0353 - accuracy: 0.9994\n",
      "Epoch 9/10\n",
      "214329/214329 [==============================] - 10s 47us/step - loss: 0.0177 - accuracy: 0.9994\n",
      "Epoch 10/10\n",
      "214329/214329 [==============================] - 10s 49us/step - loss: 0.0251 - accuracy: 0.9992\n",
      "score: 99.97200489614401%\n",
      "3\n",
      "Epoch 1/10\n",
      "214329/214329 [==============================] - 11s 52us/step - loss: 7.5899 - accuracy: 0.9893\n",
      "Epoch 2/10\n",
      "214329/214329 [==============================] - 11s 50us/step - loss: 0.0050 - accuracy: 0.9997\n",
      "Epoch 3/10\n",
      "214329/214329 [==============================] - 11s 50us/step - loss: 0.0104 - accuracy: 0.9995\n",
      "Epoch 4/10\n",
      "214329/214329 [==============================] - 11s 51us/step - loss: 0.0151 - accuracy: 0.9994\n",
      "Epoch 5/10\n",
      "214329/214329 [==============================] - 11s 51us/step - loss: 0.0221 - accuracy: 0.9996\n",
      "Epoch 6/10\n",
      "214329/214329 [==============================] - 11s 50us/step - loss: 0.0084 - accuracy: 0.9996\n",
      "Epoch 7/10\n",
      "214329/214329 [==============================] - 11s 51us/step - loss: 0.0092 - accuracy: 0.9995\n",
      "Epoch 8/10\n",
      "214329/214329 [==============================] - 11s 51us/step - loss: 0.0045 - accuracy: 0.9993\n",
      "Epoch 9/10\n",
      "214329/214329 [==============================] - 11s 50us/step - loss: 0.0053 - accuracy: 0.9995\n",
      "Epoch 10/10\n",
      "214329/214329 [==============================] - 11s 50us/step - loss: 0.0074 - accuracy: 0.9995\n",
      "score: 99.94587030906975%\n",
      "4\n",
      "Epoch 1/10\n",
      "214329/214329 [==============================] - 12s 56us/step - loss: 19.3519 - accuracy: 0.9413\n",
      "Epoch 2/10\n",
      "214329/214329 [==============================] - 12s 55us/step - loss: 0.0184 - accuracy: 0.9985\n",
      "Epoch 3/10\n",
      "214329/214329 [==============================] - 12s 55us/step - loss: 0.0085 - accuracy: 0.9985\n",
      "Epoch 4/10\n",
      "214329/214329 [==============================] - 12s 56us/step - loss: 0.0196 - accuracy: 0.9984\n",
      "Epoch 5/10\n",
      "214329/214329 [==============================] - 12s 54us/step - loss: 0.0525 - accuracy: 0.9984\n",
      "Epoch 6/10\n",
      "214329/214329 [==============================] - 12s 56us/step - loss: 0.0372 - accuracy: 0.9973\n",
      "Epoch 7/10\n",
      "214329/214329 [==============================] - 12s 54us/step - loss: 0.0162 - accuracy: 0.9981\n",
      "Epoch 8/10\n",
      "214329/214329 [==============================] - 12s 54us/step - loss: 0.0255 - accuracy: 0.9976\n",
      "Epoch 9/10\n",
      "214329/214329 [==============================] - 12s 54us/step - loss: 0.0402 - accuracy: 0.9973\n",
      "Epoch 10/10\n",
      "214329/214329 [==============================] - 12s 54us/step - loss: 0.0116 - accuracy: 0.9975\n",
      "score: 99.91790049135672%\n",
      "5\n",
      "Epoch 1/10\n",
      "214329/214329 [==============================] - 13s 62us/step - loss: 1.9313 - accuracy: 0.9719\n",
      "Epoch 2/10\n",
      "214329/214329 [==============================] - 13s 59us/step - loss: 0.0223 - accuracy: 0.9994\n",
      "Epoch 3/10\n",
      "214329/214329 [==============================] - 13s 59us/step - loss: 0.0256 - accuracy: 0.9990\n",
      "Epoch 4/10\n",
      "214329/214329 [==============================] - 13s 60us/step - loss: 0.0134 - accuracy: 0.9992\n",
      "Epoch 5/10\n",
      "214329/214329 [==============================] - 13s 59us/step - loss: 0.0145 - accuracy: 0.9992\n",
      "Epoch 6/10\n",
      "214329/214329 [==============================] - 13s 59us/step - loss: 0.0110 - accuracy: 0.9993\n",
      "Epoch 7/10\n",
      "214329/214329 [==============================] - 13s 60us/step - loss: 0.0060 - accuracy: 0.9995\n",
      "Epoch 8/10\n",
      "214329/214329 [==============================] - 13s 59us/step - loss: 0.0377 - accuracy: 0.9990\n",
      "Epoch 9/10\n",
      "214329/214329 [==============================] - 13s 59us/step - loss: 0.0272 - accuracy: 0.9994\n",
      "Epoch 10/10\n",
      "214329/214329 [==============================] - 13s 60us/step - loss: 0.0257 - accuracy: 0.9996\n",
      "score: 99.98507065718763%\n",
      "6\n",
      "Epoch 1/10\n",
      "214329/214329 [==============================] - 14s 67us/step - loss: 1.7123 - accuracy: 0.9847\n",
      "Epoch 2/10\n",
      "214329/214329 [==============================] - 14s 65us/step - loss: 0.0215 - accuracy: 0.9988\n",
      "Epoch 3/10\n",
      "214329/214329 [==============================] - 14s 63us/step - loss: 0.0220 - accuracy: 0.9988\n",
      "Epoch 4/10\n",
      "214329/214329 [==============================] - 14s 65us/step - loss: 0.0789 - accuracy: 0.9987\n",
      "Epoch 5/10\n",
      "214329/214329 [==============================] - 14s 65us/step - loss: 0.0205 - accuracy: 0.9989\n",
      "Epoch 6/10\n",
      "214329/214329 [==============================] - 14s 63us/step - loss: 0.0332 - accuracy: 0.9989\n",
      "Epoch 7/10\n",
      "214329/214329 [==============================] - 14s 63us/step - loss: 0.0377 - accuracy: 0.9992\n",
      "Epoch 8/10\n",
      "214329/214329 [==============================] - 14s 64us/step - loss: 0.0072 - accuracy: 0.9996\n",
      "Epoch 9/10\n",
      "214329/214329 [==============================] - 14s 63us/step - loss: 0.0091 - accuracy: 0.9994\n",
      "Epoch 10/10\n",
      "214329/214329 [==============================] - 14s 63us/step - loss: 0.0089 - accuracy: 0.9992\n",
      "score: 99.94402358472963%\n",
      "7\n",
      "Epoch 1/10\n",
      "214329/214329 [==============================] - 15s 71us/step - loss: 0.9780 - accuracy: 0.9914\n",
      "Epoch 2/10\n",
      "214329/214329 [==============================] - 15s 68us/step - loss: 0.0684 - accuracy: 0.9980\n",
      "Epoch 3/10\n",
      "214329/214329 [==============================] - 14s 68us/step - loss: 0.0360 - accuracy: 0.9986\n",
      "Epoch 4/10\n",
      "214329/214329 [==============================] - 14s 68us/step - loss: 0.0190 - accuracy: 0.9991\n",
      "Epoch 5/10\n",
      "214329/214329 [==============================] - 15s 69us/step - loss: 0.0095 - accuracy: 0.9991\n",
      "Epoch 6/10\n",
      "214329/214329 [==============================] - 15s 68us/step - loss: 0.0115 - accuracy: 0.9990\n",
      "Epoch 7/10\n",
      "214329/214329 [==============================] - 15s 68us/step - loss: 0.0190 - accuracy: 0.9980\n",
      "Epoch 8/10\n",
      "214329/214329 [==============================] - 15s 68us/step - loss: 0.0174 - accuracy: 0.9971\n",
      "Epoch 9/10\n",
      "214329/214329 [==============================] - 15s 68us/step - loss: 0.0079 - accuracy: 0.9993\n",
      "Epoch 10/10\n",
      "214329/214329 [==============================] - 15s 68us/step - loss: 0.0110 - accuracy: 0.9981\n",
      "score: 99.96267242861194%\n",
      "8\n",
      "Epoch 1/10\n",
      "214329/214329 [==============================] - 16s 76us/step - loss: 0.3237 - accuracy: 0.9937\n",
      "Epoch 2/10\n",
      "214329/214329 [==============================] - 16s 74us/step - loss: 0.0380 - accuracy: 0.9978\n",
      "Epoch 3/10\n",
      "214329/214329 [==============================] - 15s 72us/step - loss: 0.0136 - accuracy: 0.9987\n",
      "Epoch 4/10\n",
      "214329/214329 [==============================] - 15s 72us/step - loss: 0.0073 - accuracy: 0.9990\n",
      "Epoch 5/10\n",
      "214329/214329 [==============================] - 15s 72us/step - loss: 0.0042 - accuracy: 0.9995\n",
      "Epoch 6/10\n",
      "214329/214329 [==============================] - 15s 72us/step - loss: 0.0107 - accuracy: 0.9987\n",
      "Epoch 7/10\n",
      "214329/214329 [==============================] - 15s 72us/step - loss: 0.0090 - accuracy: 0.9988\n",
      "Epoch 8/10\n",
      "214329/214329 [==============================] - 15s 72us/step - loss: 0.0051 - accuracy: 0.9991\n",
      "Epoch 9/10\n",
      "214329/214329 [==============================] - 16s 72us/step - loss: 0.0061 - accuracy: 0.9991\n",
      "Epoch 10/10\n",
      "214329/214329 [==============================] - 16s 74us/step - loss: 0.0071 - accuracy: 0.9990\n",
      "score: 99.95894833006147%\n",
      "9\n",
      "Epoch 1/10\n",
      "214329/214329 [==============================] - 17s 80us/step - loss: 0.0223 - accuracy: 0.9979\n",
      "Epoch 2/10\n",
      "214329/214329 [==============================] - 16s 76us/step - loss: 0.0145 - accuracy: 0.9991\n",
      "Epoch 3/10\n",
      "214329/214329 [==============================] - 16s 76us/step - loss: 0.0133 - accuracy: 0.9990\n",
      "Epoch 4/10\n",
      "214329/214329 [==============================] - 16s 76us/step - loss: 0.0084 - accuracy: 0.9990\n",
      "Epoch 5/10\n",
      "214329/214329 [==============================] - 16s 76us/step - loss: 0.0045 - accuracy: 0.9994\n",
      "Epoch 6/10\n",
      "214329/214329 [==============================] - 16s 77us/step - loss: 0.0032 - accuracy: 0.9995\n",
      "Epoch 7/10\n",
      "214329/214329 [==============================] - 17s 77us/step - loss: 0.0021 - accuracy: 0.9997\n",
      "Epoch 8/10\n",
      "214329/214329 [==============================] - 16s 76us/step - loss: 0.0041 - accuracy: 0.9993\n",
      "Epoch 9/10\n",
      "214329/214329 [==============================] - 16s 77us/step - loss: 0.0033 - accuracy: 0.9993\n",
      "Epoch 10/10\n",
      "214329/214329 [==============================] - 17s 82us/step - loss: 0.0016 - accuracy: 0.9997\n",
      "score: 99.94774461829307%\n"
     ]
    }
   ],
   "source": [
    "y_pred_list_nlayer = []\n",
    "for i in range(1,10):\n",
    "    print(i)\n",
    "    y_predict, y_test = ANN_regresion_nlayer(X, y, X.shape[1], layers=i, neurons=10 , activation='relu', epochs=10, batch_size=100, verbose=1)\n",
    "    score = metrics.roc_auc_score(y_test, y_predict)\n",
    "    \n",
    "    print(f'score: {score*100}%')\n",
    "    y_pred_list_nlayer.append(score)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {
    "colab_type": "text",
    "id": "Mro0DvciPO8t"
   },
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "\n",
    "# Plot functions y_pred_list_1layer\n",
    "plt.plot(range(1,10), y_pred_list_1layer, label=r\"$y=1-x$\")\n",
    "plt.show()\n",
    "# Plot functions y_pred_list_nNeuron\n",
    "plt.scatter(range(1,10), y_pred_list_nNeuron)\n",
    "plt.show()\n",
    "# Plot functions\n",
    "plt.scatter(range(1,10), y_pred_list_nlayer)\n",
    "plt.show()\n",
    "# print(f'Mean Squared Error{mean_squared_error(y_d, y_d_hat)}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {
    "colab_type": "text",
    "id": "Mro0DvciPO8t"
   },
   "outputs": [],
   "source": [
    "data = pd.read_csv('ks.csv',\n",
    "                 parse_dates=['deadline', 'launched'])\n",
    "\n",
    "data.drop('ID', axis = 1, inplace = True)\n",
    "data.drop('goal', axis = 1, inplace = True)\n",
    "data.drop('pledged', axis = 1, inplace = True)\n",
    "data.drop('usd pledged', axis = 1, inplace = True)\n",
    "\n",
    "data['deadline']=pd.to_datetime(data['deadline'], format=\"%Y/%m/%d\").dt.date\n",
    "data['launched']=pd.to_datetime(data['launched'], format=\"%Y/%m/%d\").dt.date\n",
    "\n",
    "data['days'] = (data['deadline'] - data['launched']).dt.days\n",
    "data['launch_year']=pd.to_datetime(data['launched'], format=\"%Y/%m/%d\").dt.year\n",
    "\n",
    "data[\"launch_year\"]=data['launch_year'].apply(str)\n",
    "\n",
    "data_for_model = pd.read_csv('ks.csv')\n",
    "\n",
    "#Datetime Processing\n",
    "data_for_model['deadline']=pd.to_datetime(data_for_model['deadline'], format=\"%Y/%m/%d\")\n",
    "data_for_model['launched']=pd.to_datetime(data_for_model['launched'], format=\"%Y/%m/%d\")\n",
    "\n",
    "data_for_model['days'] = (data_for_model['deadline'] - data_for_model['launched']).dt.days\n",
    "data_for_model['launch_year']=pd.to_datetime(data_for_model['launched'], format=\"%Y/%m/%d\").dt.year\n",
    "data_for_model.drop(['ID',\"name\",\"category\",\"launched\",\"currency\",\"deadline\",\"usd pledged\",\"pledged\", \"country\", \"main_category\"], axis = 1, inplace = True)\n",
    "\n",
    "data_for_model[\"launch_year\"]=data_for_model['launch_year'].apply(str) #it has to be string."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {
    "colab_type": "text",
    "id": "Mro0DvciPO8t"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>goal</th>\n",
       "      <th>state</th>\n",
       "      <th>backers</th>\n",
       "      <th>usd_pledged_real</th>\n",
       "      <th>usd_goal_real</th>\n",
       "      <th>days</th>\n",
       "      <th>launch_year</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1000.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1533.95</td>\n",
       "      <td>58</td>\n",
       "      <td>2015</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>30000.0</td>\n",
       "      <td>0</td>\n",
       "      <td>15</td>\n",
       "      <td>2421.0</td>\n",
       "      <td>30000.00</td>\n",
       "      <td>59</td>\n",
       "      <td>2017</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>45000.0</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>220.0</td>\n",
       "      <td>45000.00</td>\n",
       "      <td>44</td>\n",
       "      <td>2013</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>5000.0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1.0</td>\n",
       "      <td>5000.00</td>\n",
       "      <td>29</td>\n",
       "      <td>2012</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>19500.0</td>\n",
       "      <td>0</td>\n",
       "      <td>14</td>\n",
       "      <td>1283.0</td>\n",
       "      <td>19500.00</td>\n",
       "      <td>55</td>\n",
       "      <td>2015</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "      goal  state  backers  usd_pledged_real  usd_goal_real  days launch_year\n",
       "0   1000.0      0        0               0.0        1533.95    58        2015\n",
       "1  30000.0      0       15            2421.0       30000.00    59        2017\n",
       "2  45000.0      0        3             220.0       45000.00    44        2013\n",
       "3   5000.0      0        1               1.0        5000.00    29        2012\n",
       "4  19500.0      0       14            1283.0       19500.00    55        2015"
      ]
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# print(\"Unbalanced Data shape\", len(data))\n",
    "# datafail = data_for_model[data_for_model.state == \"failed\"]\n",
    "# datasuccess = data_for_model[data_for_model.state == \"successful\"]\n",
    "# data_for_model = pd.concat([datafail.sample(len(datasuccess), random_state=5), datasuccess])\n",
    "# print(\"Balanced data shape:\", len(data))\n",
    "# data_for_model.state.value_counts()\n",
    "\n",
    "def state_process(cell_value):\n",
    "    if cell_value == 'successful':\n",
    "        return 1\n",
    "    else:\n",
    "        return 0    \n",
    "data_for_model.state = data_for_model.state.apply(state_process)\n",
    "\n",
    "data_for_model.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {
    "colab_type": "text",
    "id": "Mro0DvciPO8t"
   },
   "outputs": [],
   "source": [
    "from sklearn import metrics\n",
    "\n",
    "X = data_for_model.iloc[:,data_for_model.columns != 'state']\n",
    "y = data_for_model.state"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {
    "colab_type": "text",
    "id": "Mro0DvciPO8t"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1\n",
      "Epoch 1/10\n",
      "302928/302928 [==============================] - 15s 49us/step - loss: 0.7762 - accuracy: 0.6459\n",
      "Epoch 2/10\n",
      "302928/302928 [==============================] - 15s 48us/step - loss: 0.7239 - accuracy: 0.6461\n",
      "Epoch 3/10\n",
      "302928/302928 [==============================] - 15s 48us/step - loss: 0.6782 - accuracy: 0.6461\n",
      "Epoch 4/10\n",
      "302928/302928 [==============================] - 15s 48us/step - loss: 0.6601 - accuracy: 0.6461\n",
      "Epoch 5/10\n",
      "302928/302928 [==============================] - 15s 48us/step - loss: 0.6529 - accuracy: 0.6461\n",
      "Epoch 6/10\n",
      "302928/302928 [==============================] - 15s 48us/step - loss: 0.6506 - accuracy: 0.6461\n",
      "Epoch 7/10\n",
      "302928/302928 [==============================] - 15s 48us/step - loss: 0.6498 - accuracy: 0.6461\n",
      "Epoch 8/10\n",
      "302928/302928 [==============================] - 15s 48us/step - loss: 0.6498 - accuracy: 0.6461\n",
      "Epoch 9/10\n",
      "302928/302928 [==============================] - 15s 48us/step - loss: 0.6498 - accuracy: 0.6461\n",
      "Epoch 10/10\n",
      "302928/302928 [==============================] - 15s 48us/step - loss: 0.6498 - accuracy: 0.6461\n",
      "score: 50.0%\n",
      "2\n",
      "Epoch 1/10\n",
      "302928/302928 [==============================] - 15s 50us/step - loss: 22.2209 - accuracy: 0.8706\n",
      "Epoch 2/10\n",
      "302928/302928 [==============================] - 15s 49us/step - loss: 0.2158 - accuracy: 0.9807\n",
      "Epoch 3/10\n",
      "302928/302928 [==============================] - 15s 49us/step - loss: 0.0791 - accuracy: 0.9820\n",
      "Epoch 4/10\n",
      "302928/302928 [==============================] - 15s 49us/step - loss: 0.0572 - accuracy: 0.9883\n",
      "Epoch 5/10\n",
      "302928/302928 [==============================] - 15s 48us/step - loss: 0.0492 - accuracy: 0.9889\n",
      "Epoch 6/10\n",
      "302928/302928 [==============================] - 15s 49us/step - loss: 0.0456 - accuracy: 0.9903\n",
      "Epoch 7/10\n",
      "302928/302928 [==============================] - 15s 49us/step - loss: 0.0458 - accuracy: 0.9904\n",
      "Epoch 8/10\n",
      "302928/302928 [==============================] - 15s 49us/step - loss: 0.0450 - accuracy: 0.9904\n",
      "Epoch 9/10\n",
      "302928/302928 [==============================] - 15s 49us/step - loss: 0.0438 - accuracy: 0.9907\n",
      "Epoch 10/10\n",
      "302928/302928 [==============================] - 15s 48us/step - loss: 0.0432 - accuracy: 0.9906\n",
      "score: 99.2553203035685%\n",
      "3\n",
      "Epoch 1/10\n",
      "302928/302928 [==============================] - 15s 50us/step - loss: 448.0518 - accuracy: 0.8932\n",
      "Epoch 2/10\n",
      "302928/302928 [==============================] - 15s 49us/step - loss: 2.7160 - accuracy: 0.9578\n",
      "Epoch 3/10\n",
      "302928/302928 [==============================] - 15s 49us/step - loss: 3.7307 - accuracy: 0.9516\n",
      "Epoch 4/10\n",
      "302928/302928 [==============================] - 15s 49us/step - loss: 3.9966 - accuracy: 0.9488\n",
      "Epoch 5/10\n",
      "302928/302928 [==============================] - 15s 49us/step - loss: 5.9410 - accuracy: 0.9529\n",
      "Epoch 6/10\n",
      "302928/302928 [==============================] - 15s 49us/step - loss: 8.5363 - accuracy: 0.9568\n",
      "Epoch 7/10\n",
      "302928/302928 [==============================] - 15s 49us/step - loss: 2.9072 - accuracy: 0.9499\n",
      "Epoch 8/10\n",
      "302928/302928 [==============================] - 15s 50us/step - loss: 3.3653 - accuracy: 0.9515\n",
      "Epoch 9/10\n",
      "302928/302928 [==============================] - 15s 49us/step - loss: 3.6968 - accuracy: 0.9521\n",
      "Epoch 10/10\n",
      "302928/302928 [==============================] - 15s 49us/step - loss: 3.3618 - accuracy: 0.9538\n",
      "score: 93.63698707417707%\n",
      "4\n",
      "Epoch 1/10\n",
      "302928/302928 [==============================] - 15s 51us/step - loss: 24.3566 - accuracy: 0.9694\n",
      "Epoch 2/10\n",
      "302928/302928 [==============================] - 15s 50us/step - loss: 3.2133 - accuracy: 0.9797\n",
      "Epoch 3/10\n",
      "302928/302928 [==============================] - 15s 50us/step - loss: 5.6058 - accuracy: 0.9728\n",
      "Epoch 4/10\n",
      "302928/302928 [==============================] - 15s 49us/step - loss: 1.6189 - accuracy: 0.9767\n",
      "Epoch 5/10\n",
      "302928/302928 [==============================] - 15s 50us/step - loss: 3.3923 - accuracy: 0.9774\n",
      "Epoch 6/10\n",
      "302928/302928 [==============================] - 15s 49us/step - loss: 1.7195 - accuracy: 0.9779\n",
      "Epoch 7/10\n",
      "302928/302928 [==============================] - 15s 49us/step - loss: 3.7736 - accuracy: 0.9790\n",
      "Epoch 8/10\n",
      "302928/302928 [==============================] - 15s 49us/step - loss: 1.7291 - accuracy: 0.9772\n",
      "Epoch 9/10\n",
      "302928/302928 [==============================] - 15s 49us/step - loss: 1.1443 - accuracy: 0.9804\n",
      "Epoch 10/10\n",
      "302928/302928 [==============================] - 15s 50us/step - loss: 0.5568 - accuracy: 0.9829\n",
      "score: 98.68498339995337%\n",
      "5\n",
      "Epoch 1/10\n",
      "302928/302928 [==============================] - 15s 51us/step - loss: 766.1949 - accuracy: 0.8672\n",
      "Epoch 2/10\n",
      "302928/302928 [==============================] - 15s 50us/step - loss: 10.4901 - accuracy: 0.9800\n",
      "Epoch 3/10\n",
      "302928/302928 [==============================] - 15s 50us/step - loss: 3.3073 - accuracy: 0.9801\n",
      "Epoch 4/10\n",
      "302928/302928 [==============================] - 15s 49us/step - loss: 5.7933 - accuracy: 0.9791\n",
      "Epoch 5/10\n",
      "302928/302928 [==============================] - 15s 50us/step - loss: 4.8245 - accuracy: 0.9790\n",
      "Epoch 6/10\n",
      "302928/302928 [==============================] - 15s 50us/step - loss: 4.5546 - accuracy: 0.9791\n",
      "Epoch 7/10\n",
      "302928/302928 [==============================] - 15s 50us/step - loss: 3.8023 - accuracy: 0.9800\n",
      "Epoch 8/10\n",
      "302928/302928 [==============================] - 15s 50us/step - loss: 4.5920 - accuracy: 0.9792\n",
      "Epoch 9/10\n",
      "302928/302928 [==============================] - 15s 50us/step - loss: 3.2997 - accuracy: 0.9804\n",
      "Epoch 10/10\n",
      "302928/302928 [==============================] - 15s 50us/step - loss: 4.6195 - accuracy: 0.9801\n",
      "score: 98.97885538441213%\n",
      "6\n",
      "Epoch 1/10\n",
      "302928/302928 [==============================] - 15s 51us/step - loss: 398.5475 - accuracy: 0.9124\n",
      "Epoch 2/10\n",
      "302928/302928 [==============================] - 15s 50us/step - loss: 5.8659 - accuracy: 0.9775\n",
      "Epoch 3/10\n",
      "302928/302928 [==============================] - 15s 50us/step - loss: 4.9369 - accuracy: 0.9756\n",
      "Epoch 4/10\n",
      "302928/302928 [==============================] - 15s 50us/step - loss: 4.1504 - accuracy: 0.9789\n",
      "Epoch 5/10\n",
      "302928/302928 [==============================] - 15s 50us/step - loss: 4.5803 - accuracy: 0.9778\n",
      "Epoch 6/10\n",
      "302928/302928 [==============================] - 15s 49us/step - loss: 3.3378 - accuracy: 0.9770\n",
      "Epoch 7/10\n",
      "302928/302928 [==============================] - 15s 49us/step - loss: 2.4138 - accuracy: 0.9775\n",
      "Epoch 8/10\n",
      "302928/302928 [==============================] - 15s 50us/step - loss: 3.6545 - accuracy: 0.9765\n",
      "Epoch 9/10\n",
      "302928/302928 [==============================] - 15s 50us/step - loss: 3.6983 - accuracy: 0.9783\n",
      "Epoch 10/10\n",
      "302928/302928 [==============================] - 15s 49us/step - loss: 2.0415 - accuracy: 0.9784\n",
      "score: 98.26753324309082%\n",
      "7\n",
      "Epoch 1/10\n",
      "302928/302928 [==============================] - 15s 51us/step - loss: 2015.9824 - accuracy: 0.9019\n",
      "Epoch 2/10\n",
      "302928/302928 [==============================] - 15s 50us/step - loss: 21.3894 - accuracy: 0.9738\n",
      "Epoch 3/10\n",
      "302928/302928 [==============================] - 15s 50us/step - loss: 12.2022 - accuracy: 0.9661\n",
      "Epoch 4/10\n",
      "302928/302928 [==============================] - 16s 53us/step - loss: 4.6764 - accuracy: 0.9681\n",
      "Epoch 5/10\n",
      "302928/302928 [==============================] - 16s 52us/step - loss: 3.4980 - accuracy: 0.9708\n",
      "Epoch 6/10\n",
      "302928/302928 [==============================] - 16s 51us/step - loss: 2.9678 - accuracy: 0.9744\n",
      "Epoch 7/10\n",
      "302928/302928 [==============================] - 16s 52us/step - loss: 2.2419 - accuracy: 0.9755\n",
      "Epoch 8/10\n",
      "302928/302928 [==============================] - 16s 52us/step - loss: 2.3599 - accuracy: 0.9768\n",
      "Epoch 9/10\n",
      "302928/302928 [==============================] - 16s 52us/step - loss: 2.6952 - accuracy: 0.9769\n",
      "Epoch 10/10\n",
      "302928/302928 [==============================] - 16s 52us/step - loss: 2.9869 - accuracy: 0.9773\n",
      "score: 99.01888877700623%\n",
      "8\n",
      "Epoch 1/10\n",
      "302928/302928 [==============================] - 16s 53us/step - loss: 22.1627 - accuracy: 0.9537\n",
      "Epoch 2/10\n",
      "302928/302928 [==============================] - 16s 52us/step - loss: 4.6461 - accuracy: 0.9740\n",
      "Epoch 3/10\n",
      "302928/302928 [==============================] - 16s 52us/step - loss: 3.6052 - accuracy: 0.9757\n",
      "Epoch 4/10\n",
      "302928/302928 [==============================] - 16s 52us/step - loss: 2.5318 - accuracy: 0.9796\n",
      "Epoch 5/10\n",
      "302928/302928 [==============================] - 16s 52us/step - loss: 2.5164 - accuracy: 0.9807\n",
      "Epoch 6/10\n",
      "302928/302928 [==============================] - 16s 53us/step - loss: 2.7700 - accuracy: 0.9807\n",
      "Epoch 7/10\n",
      "302928/302928 [==============================] - 16s 52us/step - loss: 2.8845 - accuracy: 0.9816\n",
      "Epoch 8/10\n",
      "302928/302928 [==============================] - 16s 52us/step - loss: 2.9035 - accuracy: 0.9808\n",
      "Epoch 9/10\n",
      "302928/302928 [==============================] - 16s 52us/step - loss: 3.2694 - accuracy: 0.9808\n",
      "Epoch 10/10\n",
      "302928/302928 [==============================] - 16s 52us/step - loss: 3.1202 - accuracy: 0.9808\n",
      "score: 98.57331661802121%\n",
      "9\n",
      "Epoch 1/10\n",
      "302928/302928 [==============================] - 16s 53us/step - loss: 289.0258 - accuracy: 0.8852\n",
      "Epoch 2/10\n",
      "302928/302928 [==============================] - 16s 52us/step - loss: 3.2516 - accuracy: 0.9648\n",
      "Epoch 3/10\n",
      "302928/302928 [==============================] - 16s 52us/step - loss: 2.6838 - accuracy: 0.9666\n",
      "Epoch 4/10\n",
      "302928/302928 [==============================] - 16s 52us/step - loss: 2.2759 - accuracy: 0.9729\n",
      "Epoch 5/10\n",
      "302928/302928 [==============================] - 16s 52us/step - loss: 3.3824 - accuracy: 0.9719\n",
      "Epoch 6/10\n",
      "302928/302928 [==============================] - 16s 53us/step - loss: 1.9198 - accuracy: 0.9782\n",
      "Epoch 7/10\n",
      "302928/302928 [==============================] - 16s 52us/step - loss: 1.7243 - accuracy: 0.9776\n",
      "Epoch 8/10\n",
      "302928/302928 [==============================] - 16s 52us/step - loss: 1.4188 - accuracy: 0.9810\n",
      "Epoch 9/10\n",
      "302928/302928 [==============================] - 16s 52us/step - loss: 1.1570 - accuracy: 0.9803\n",
      "Epoch 10/10\n",
      "302928/302928 [==============================] - 16s 52us/step - loss: 1.7887 - accuracy: 0.9820\n",
      "score: 99.31089237089662%\n"
     ]
    }
   ],
   "source": [
    "y_pred_list_1layer = []\n",
    "for i in range(1,10):\n",
    "    print(i)\n",
    "    y_predict, y_test = ANN_regresion_nlayer(X, y, X.shape[1], layers=1, neurons=i , activation='relu', epochs=10, batch_size=100, verbose=1)\n",
    "    score = metrics.roc_auc_score(y_test, y_predict)\n",
    "    \n",
    "    print(f'score: {score*100}%')\n",
    "    y_pred_list_1layer.append(score)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {
    "colab_type": "text",
    "id": "Mro0DvciPO8t"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1\n",
      "Epoch 1/10\n",
      "302928/302928 [==============================] - 16s 53us/step - loss: 2083.2179 - accuracy: 0.8568\n",
      "Epoch 2/10\n",
      "302928/302928 [==============================] - 16s 53us/step - loss: 3.5445 - accuracy: 0.9729\n",
      "Epoch 3/10\n",
      "302928/302928 [==============================] - 16s 53us/step - loss: 2.7462 - accuracy: 0.9769\n",
      "Epoch 4/10\n",
      "302928/302928 [==============================] - 16s 52us/step - loss: 2.8792 - accuracy: 0.9777\n",
      "Epoch 5/10\n",
      "302928/302928 [==============================] - 16s 53us/step - loss: 3.3629 - accuracy: 0.9781\n",
      "Epoch 6/10\n",
      "302928/302928 [==============================] - 16s 52us/step - loss: 3.2796 - accuracy: 0.9788\n",
      "Epoch 7/10\n",
      "302928/302928 [==============================] - 16s 52us/step - loss: 2.2731 - accuracy: 0.9794\n",
      "Epoch 8/10\n",
      "302928/302928 [==============================] - 16s 52us/step - loss: 2.6684 - accuracy: 0.9802\n",
      "Epoch 9/10\n",
      "302928/302928 [==============================] - 16s 52us/step - loss: 1.9117 - accuracy: 0.9808\n",
      "Epoch 10/10\n",
      "302928/302928 [==============================] - 16s 52us/step - loss: 3.4716 - accuracy: 0.9786\n",
      "score: 95.48173326138374%\n",
      "2\n",
      "Epoch 1/10\n",
      "302928/302928 [==============================] - 18s 58us/step - loss: 56.9683 - accuracy: 0.9219\n",
      "Epoch 2/10\n",
      "302928/302928 [==============================] - 17s 57us/step - loss: 2.1362 - accuracy: 0.9649\n",
      "Epoch 3/10\n",
      "302928/302928 [==============================] - 17s 57us/step - loss: 2.5999 - accuracy: 0.9757\n",
      "Epoch 4/10\n",
      "302928/302928 [==============================] - 17s 57us/step - loss: 1.5071 - accuracy: 0.9785\n",
      "Epoch 5/10\n",
      "302928/302928 [==============================] - 17s 57us/step - loss: 1.2888 - accuracy: 0.9839\n",
      "Epoch 6/10\n",
      "302928/302928 [==============================] - 17s 57us/step - loss: 0.6560 - accuracy: 0.9846\n",
      "Epoch 7/10\n",
      "302928/302928 [==============================] - 17s 57us/step - loss: 0.4498 - accuracy: 0.9888\n",
      "Epoch 8/10\n",
      "302928/302928 [==============================] - 18s 58us/step - loss: 0.6587 - accuracy: 0.9887\n",
      "Epoch 9/10\n",
      "302928/302928 [==============================] - 18s 59us/step - loss: 0.4011 - accuracy: 0.9836\n",
      "Epoch 10/10\n",
      "302928/302928 [==============================] - 17s 56us/step - loss: 0.1010 - accuracy: 0.9829\n",
      "score: 99.09166707634522%\n",
      "3\n",
      "Epoch 1/10\n",
      "302928/302928 [==============================] - 19s 62us/step - loss: 11.1062 - accuracy: 0.9318\n",
      "Epoch 2/10\n",
      "302928/302928 [==============================] - 18s 60us/step - loss: 0.5061 - accuracy: 0.9861\n",
      "Epoch 3/10\n",
      "302928/302928 [==============================] - 18s 60us/step - loss: 0.2128 - accuracy: 0.9883\n",
      "Epoch 4/10\n",
      "302928/302928 [==============================] - 18s 60us/step - loss: 0.0477 - accuracy: 0.9894\n",
      "Epoch 5/10\n",
      "302928/302928 [==============================] - 18s 60us/step - loss: 0.0450 - accuracy: 0.9898\n",
      "Epoch 6/10\n",
      "302928/302928 [==============================] - 18s 60us/step - loss: 0.0525 - accuracy: 0.9902\n",
      "Epoch 7/10\n",
      "302928/302928 [==============================] - 18s 61us/step - loss: 0.0453 - accuracy: 0.9899\n",
      "Epoch 8/10\n",
      "302928/302928 [==============================] - 18s 60us/step - loss: 0.0445 - accuracy: 0.9900\n",
      "Epoch 9/10\n",
      "302928/302928 [==============================] - 18s 60us/step - loss: 0.0460 - accuracy: 0.9897\n",
      "Epoch 10/10\n",
      "302928/302928 [==============================] - 18s 60us/step - loss: 0.0477 - accuracy: 0.9893\n",
      "score: 99.2947095340627%\n",
      "4\n",
      "Epoch 1/10\n",
      "302928/302928 [==============================] - 20s 66us/step - loss: 27.1406 - accuracy: 0.8888\n",
      "Epoch 2/10\n",
      "302928/302928 [==============================] - 19s 64us/step - loss: 0.4141 - accuracy: 0.9635\n",
      "Epoch 3/10\n",
      "302928/302928 [==============================] - 20s 65us/step - loss: 0.2239 - accuracy: 0.9755\n",
      "Epoch 4/10\n",
      "302928/302928 [==============================] - 19s 64us/step - loss: 0.2232 - accuracy: 0.9809\n",
      "Epoch 5/10\n",
      "302928/302928 [==============================] - 19s 64us/step - loss: 0.3087 - accuracy: 0.9856\n",
      "Epoch 6/10\n",
      "302928/302928 [==============================] - 20s 65us/step - loss: 0.0507 - accuracy: 0.9897\n",
      "Epoch 7/10\n",
      "302928/302928 [==============================] - 20s 65us/step - loss: 0.0458 - accuracy: 0.9899\n",
      "Epoch 8/10\n",
      "302928/302928 [==============================] - 20s 65us/step - loss: 0.0470 - accuracy: 0.9894\n",
      "Epoch 9/10\n",
      "302928/302928 [==============================] - 20s 65us/step - loss: 0.0452 - accuracy: 0.9900\n",
      "Epoch 10/10\n",
      "302928/302928 [==============================] - 20s 65us/step - loss: 0.0458 - accuracy: 0.9895\n",
      "score: 99.30337768052888%\n",
      "5\n",
      "Epoch 1/10\n",
      "302928/302928 [==============================] - 21s 70us/step - loss: 0.1893 - accuracy: 0.9578\n",
      "Epoch 2/10\n",
      "302928/302928 [==============================] - 21s 69us/step - loss: 0.1003 - accuracy: 0.9758\n",
      "Epoch 3/10\n",
      "302928/302928 [==============================] - 21s 69us/step - loss: 0.0887 - accuracy: 0.9788\n",
      "Epoch 4/10\n",
      "302928/302928 [==============================] - 21s 69us/step - loss: 0.0829 - accuracy: 0.9815\n",
      "Epoch 5/10\n",
      "302928/302928 [==============================] - 21s 69us/step - loss: 0.0784 - accuracy: 0.9831\n",
      "Epoch 6/10\n",
      "302928/302928 [==============================] - 21s 69us/step - loss: 0.0815 - accuracy: 0.9816\n",
      "Epoch 7/10\n",
      "302928/302928 [==============================] - 21s 69us/step - loss: 0.0741 - accuracy: 0.9842\n",
      "Epoch 8/10\n",
      "302928/302928 [==============================] - 21s 69us/step - loss: 0.0754 - accuracy: 0.9834\n",
      "Epoch 9/10\n",
      "302928/302928 [==============================] - 21s 69us/step - loss: 0.0729 - accuracy: 0.9843\n",
      "Epoch 10/10\n",
      "302928/302928 [==============================] - 21s 69us/step - loss: 0.0694 - accuracy: 0.9855\n",
      "score: 98.63732154706841%\n",
      "6\n",
      "Epoch 1/10\n",
      "302928/302928 [==============================] - 23s 75us/step - loss: 8.7237 - accuracy: 0.6374\n",
      "Epoch 2/10\n",
      "302928/302928 [==============================] - 22s 74us/step - loss: 0.6498 - accuracy: 0.6461\n",
      "Epoch 3/10\n",
      "302928/302928 [==============================] - 22s 74us/step - loss: 0.6498 - accuracy: 0.6461\n",
      "Epoch 4/10\n",
      "302928/302928 [==============================] - 22s 74us/step - loss: 0.6498 - accuracy: 0.6461\n",
      "Epoch 5/10\n",
      "302928/302928 [==============================] - 23s 75us/step - loss: 0.6498 - accuracy: 0.6461\n",
      "Epoch 6/10\n",
      "302928/302928 [==============================] - 22s 74us/step - loss: 0.6498 - accuracy: 0.6461\n",
      "Epoch 7/10\n",
      "302928/302928 [==============================] - 23s 74us/step - loss: 0.6498 - accuracy: 0.6461\n",
      "Epoch 8/10\n",
      "302928/302928 [==============================] - 23s 74us/step - loss: 0.6498 - accuracy: 0.6461\n",
      "Epoch 9/10\n",
      "302928/302928 [==============================] - 22s 74us/step - loss: 0.6498 - accuracy: 0.6461\n",
      "Epoch 10/10\n",
      "302928/302928 [==============================] - 22s 74us/step - loss: 0.6498 - accuracy: 0.6461\n",
      "score: 50.0%\n",
      "7\n",
      "Epoch 1/10\n",
      "302928/302928 [==============================] - 25s 81us/step - loss: 0.6534 - accuracy: 0.6461\n",
      "Epoch 2/10\n",
      "302928/302928 [==============================] - 24s 80us/step - loss: 0.6498 - accuracy: 0.6461\n",
      "Epoch 3/10\n",
      "302928/302928 [==============================] - 24s 79us/step - loss: 0.6498 - accuracy: 0.6461\n",
      "Epoch 4/10\n",
      "302928/302928 [==============================] - 24s 79us/step - loss: 0.6498 - accuracy: 0.6461\n",
      "Epoch 5/10\n",
      "302928/302928 [==============================] - 24s 80us/step - loss: 0.6498 - accuracy: 0.6461\n",
      "Epoch 6/10\n",
      "302928/302928 [==============================] - 24s 80us/step - loss: 0.6498 - accuracy: 0.6461\n",
      "Epoch 7/10\n",
      "302928/302928 [==============================] - 24s 79us/step - loss: 0.6498 - accuracy: 0.6461\n",
      "Epoch 8/10\n",
      "302928/302928 [==============================] - 24s 79us/step - loss: 0.6498 - accuracy: 0.6461\n",
      "Epoch 9/10\n",
      "302928/302928 [==============================] - 24s 79us/step - loss: 0.6498 - accuracy: 0.6461\n",
      "Epoch 10/10\n",
      "302928/302928 [==============================] - 24s 79us/step - loss: 0.6498 - accuracy: 0.6461\n",
      "score: 50.0%\n",
      "8\n",
      "Epoch 1/10\n",
      "302928/302928 [==============================] - 26s 86us/step - loss: 0.6608 - accuracy: 0.6439\n",
      "Epoch 2/10\n",
      "302928/302928 [==============================] - 26s 85us/step - loss: 0.6498 - accuracy: 0.6461\n",
      "Epoch 3/10\n",
      "302928/302928 [==============================] - 26s 84us/step - loss: 0.6498 - accuracy: 0.6461\n",
      "Epoch 4/10\n",
      "302928/302928 [==============================] - 26s 85us/step - loss: 0.6498 - accuracy: 0.6461\n",
      "Epoch 5/10\n",
      "302928/302928 [==============================] - 26s 84us/step - loss: 0.6498 - accuracy: 0.6461\n",
      "Epoch 6/10\n",
      "302928/302928 [==============================] - 26s 85us/step - loss: 0.6498 - accuracy: 0.6461\n",
      "Epoch 7/10\n",
      "302928/302928 [==============================] - 26s 85us/step - loss: 0.6498 - accuracy: 0.6461\n",
      "Epoch 8/10\n",
      "302928/302928 [==============================] - 25s 84us/step - loss: 0.6498 - accuracy: 0.6461\n",
      "Epoch 9/10\n",
      "302928/302928 [==============================] - 26s 84us/step - loss: 0.6498 - accuracy: 0.6461\n",
      "Epoch 10/10\n",
      "302928/302928 [==============================] - 26s 84us/step - loss: 0.6498 - accuracy: 0.6461\n",
      "score: 50.0%\n",
      "9\n",
      "Epoch 1/10\n",
      "302928/302928 [==============================] - 28s 91us/step - loss: 0.6536 - accuracy: 0.6461\n",
      "Epoch 2/10\n",
      "302928/302928 [==============================] - 27s 88us/step - loss: 0.6498 - accuracy: 0.6461\n",
      "Epoch 3/10\n",
      "302928/302928 [==============================] - 27s 88us/step - loss: 0.6498 - accuracy: 0.6461\n",
      "Epoch 4/10\n",
      "302928/302928 [==============================] - 27s 89us/step - loss: 0.6498 - accuracy: 0.6461\n",
      "Epoch 5/10\n",
      "302928/302928 [==============================] - 27s 88us/step - loss: 0.6498 - accuracy: 0.6461\n",
      "Epoch 6/10\n",
      "302928/302928 [==============================] - 27s 88us/step - loss: 0.6498 - accuracy: 0.6461\n",
      "Epoch 7/10\n",
      "302928/302928 [==============================] - 27s 88us/step - loss: 0.6498 - accuracy: 0.6461\n",
      "Epoch 8/10\n",
      "302928/302928 [==============================] - 27s 89us/step - loss: 0.6498 - accuracy: 0.6461\n",
      "Epoch 9/10\n",
      "302928/302928 [==============================] - 29s 96us/step - loss: 0.6498 - accuracy: 0.6461\n",
      "Epoch 10/10\n",
      "302928/302928 [==============================] - 27s 89us/step - loss: 0.6498 - accuracy: 0.6461\n",
      "score: 50.0%\n"
     ]
    }
   ],
   "source": [
    "y_pred_list_nNeuron = []\n",
    "for i in range(1,10):\n",
    "    print(i)\n",
    "    y_predict, y_test = ANN_regresion_nN(X, y, X.shape[1], layers=i, neurons=14 , activation='relu', epochs=10, batch_size=100, verbose=1)\n",
    "    score = metrics.roc_auc_score(y_test, y_predict)\n",
    "    \n",
    "    print(f'score: {score*100}%')\n",
    "    y_pred_list_nNeuron.append(score)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {
    "colab_type": "text",
    "id": "Mro0DvciPO8t"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1\n",
      "Epoch 1/10\n",
      "302928/302928 [==============================] - 18s 59us/step - loss: 27.9267 - accuracy: 0.9503\n",
      "Epoch 2/10\n",
      "302928/302928 [==============================] - 17s 57us/step - loss: 3.9456 - accuracy: 0.9748\n",
      "Epoch 3/10\n",
      "302928/302928 [==============================] - 17s 57us/step - loss: 3.1889 - accuracy: 0.9789\n",
      "Epoch 4/10\n",
      "302928/302928 [==============================] - 17s 57us/step - loss: 2.9806 - accuracy: 0.9792\n",
      "Epoch 5/10\n",
      "302928/302928 [==============================] - 17s 57us/step - loss: 2.8445 - accuracy: 0.9804\n",
      "Epoch 6/10\n",
      "302928/302928 [==============================] - 17s 57us/step - loss: 3.4686 - accuracy: 0.9802\n",
      "Epoch 7/10\n",
      "302928/302928 [==============================] - 17s 57us/step - loss: 2.4249 - accuracy: 0.9811\n",
      "Epoch 8/10\n",
      "302928/302928 [==============================] - 17s 58us/step - loss: 3.0717 - accuracy: 0.9809\n",
      "Epoch 9/10\n",
      "302928/302928 [==============================] - 17s 57us/step - loss: 3.0375 - accuracy: 0.9807\n",
      "Epoch 10/10\n",
      "302928/302928 [==============================] - 17s 57us/step - loss: 2.3775 - accuracy: 0.9813\n",
      "score: 98.94090991026619%\n",
      "2\n",
      "Epoch 1/10\n",
      "302928/302928 [==============================] - 19s 63us/step - loss: 9.6451 - accuracy: 0.9580\n",
      "Epoch 2/10\n",
      "302928/302928 [==============================] - 19s 61us/step - loss: 3.5863 - accuracy: 0.9802\n",
      "Epoch 3/10\n",
      "302928/302928 [==============================] - 19s 62us/step - loss: 2.1954 - accuracy: 0.9804\n",
      "Epoch 4/10\n",
      "302928/302928 [==============================] - 19s 61us/step - loss: 1.5052 - accuracy: 0.9794\n",
      "Epoch 5/10\n",
      "302928/302928 [==============================] - 19s 62us/step - loss: 1.3373 - accuracy: 0.9826\n",
      "Epoch 6/10\n",
      "302928/302928 [==============================] - 19s 62us/step - loss: 0.6886 - accuracy: 0.9839\n",
      "Epoch 7/10\n",
      "302928/302928 [==============================] - 19s 62us/step - loss: 0.4734 - accuracy: 0.9848\n",
      "Epoch 8/10\n",
      "302928/302928 [==============================] - 19s 61us/step - loss: 0.5598 - accuracy: 0.9798\n",
      "Epoch 9/10\n",
      "302928/302928 [==============================] - 18s 61us/step - loss: 0.4386 - accuracy: 0.9828\n",
      "Epoch 10/10\n",
      "302928/302928 [==============================] - 18s 61us/step - loss: 0.4713 - accuracy: 0.9843\n",
      "score: 98.51371746930656%\n",
      "3\n",
      "Epoch 1/10\n",
      "302928/302928 [==============================] - 20s 68us/step - loss: 72.4462 - accuracy: 0.9558\n",
      "Epoch 2/10\n",
      "302928/302928 [==============================] - 20s 66us/step - loss: 0.9698 - accuracy: 0.9768\n",
      "Epoch 3/10\n",
      "302928/302928 [==============================] - 20s 66us/step - loss: 2.8016 - accuracy: 0.9805\n",
      "Epoch 4/10\n",
      "302928/302928 [==============================] - 20s 65us/step - loss: 0.5604 - accuracy: 0.9844\n",
      "Epoch 5/10\n",
      "302928/302928 [==============================] - 20s 65us/step - loss: 0.2043 - accuracy: 0.9879\n",
      "Epoch 6/10\n",
      "302928/302928 [==============================] - 20s 66us/step - loss: 0.2530 - accuracy: 0.9860\n",
      "Epoch 7/10\n",
      "302928/302928 [==============================] - 20s 65us/step - loss: 0.1621 - accuracy: 0.9849\n",
      "Epoch 8/10\n",
      "302928/302928 [==============================] - 20s 66us/step - loss: 0.0580 - accuracy: 0.9884\n",
      "Epoch 9/10\n",
      "302928/302928 [==============================] - 20s 67us/step - loss: 0.0563 - accuracy: 0.9868\n",
      "Epoch 10/10\n",
      "302928/302928 [==============================] - 20s 65us/step - loss: 0.0510 - accuracy: 0.9881\n",
      "score: 99.02425198732556%\n",
      "4\n",
      "Epoch 1/10\n",
      "302928/302928 [==============================] - 22s 72us/step - loss: 2.7200 - accuracy: 0.9704\n",
      "Epoch 2/10\n",
      "302928/302928 [==============================] - 21s 70us/step - loss: 1.4823 - accuracy: 0.9797\n",
      "Epoch 3/10\n",
      "302928/302928 [==============================] - 21s 70us/step - loss: 0.5540 - accuracy: 0.9845\n",
      "Epoch 4/10\n",
      "302928/302928 [==============================] - 21s 70us/step - loss: 0.8612 - accuracy: 0.9870\n",
      "Epoch 5/10\n",
      "302928/302928 [==============================] - 21s 70us/step - loss: 0.1000 - accuracy: 0.9884\n",
      "Epoch 6/10\n",
      "302928/302928 [==============================] - 21s 69us/step - loss: 0.0947 - accuracy: 0.9884\n",
      "Epoch 7/10\n",
      "302928/302928 [==============================] - 21s 70us/step - loss: 0.0665 - accuracy: 0.9885\n",
      "Epoch 8/10\n",
      "302928/302928 [==============================] - 21s 70us/step - loss: 0.0473 - accuracy: 0.9894\n",
      "Epoch 9/10\n",
      "302928/302928 [==============================] - 21s 70us/step - loss: 0.0462 - accuracy: 0.9894\n",
      "Epoch 10/10\n",
      "302928/302928 [==============================] - 21s 71us/step - loss: 0.0446 - accuracy: 0.9898\n",
      "score: 98.955525606469%\n",
      "5\n",
      "Epoch 1/10\n",
      "302928/302928 [==============================] - 23s 76us/step - loss: 2.8794 - accuracy: 0.9727\n",
      "Epoch 2/10\n",
      "302928/302928 [==============================] - 22s 74us/step - loss: 0.2045 - accuracy: 0.9865\n",
      "Epoch 3/10\n",
      "302928/302928 [==============================] - 22s 74us/step - loss: 0.0837 - accuracy: 0.9838\n",
      "Epoch 4/10\n",
      "302928/302928 [==============================] - 22s 74us/step - loss: 0.0649 - accuracy: 0.9847\n",
      "Epoch 5/10\n",
      "302928/302928 [==============================] - 22s 74us/step - loss: 0.0558 - accuracy: 0.9867\n",
      "Epoch 6/10\n",
      "302928/302928 [==============================] - 22s 74us/step - loss: 0.0500 - accuracy: 0.9893\n",
      "Epoch 7/10\n",
      "302928/302928 [==============================] - 22s 74us/step - loss: 0.0558 - accuracy: 0.9894\n",
      "Epoch 8/10\n",
      "302928/302928 [==============================] - 22s 74us/step - loss: 0.0540 - accuracy: 0.9874\n",
      "Epoch 9/10\n",
      "302928/302928 [==============================] - 22s 74us/step - loss: 0.0546 - accuracy: 0.9904\n",
      "Epoch 10/10\n",
      "302928/302928 [==============================] - 23s 74us/step - loss: 0.0591 - accuracy: 0.9895\n",
      "score: 98.65199653182272%\n",
      "6\n",
      "Epoch 1/10\n",
      "302928/302928 [==============================] - 25s 82us/step - loss: 1.5593 - accuracy: 0.9140\n",
      "Epoch 2/10\n",
      "302928/302928 [==============================] - 24s 80us/step - loss: 0.0864 - accuracy: 0.9778\n",
      "Epoch 3/10\n",
      "302928/302928 [==============================] - 24s 80us/step - loss: 0.0831 - accuracy: 0.9783\n",
      "Epoch 4/10\n",
      "302928/302928 [==============================] - 24s 79us/step - loss: 0.0805 - accuracy: 0.9786\n",
      "Epoch 5/10\n",
      "302928/302928 [==============================] - 24s 80us/step - loss: 0.0688 - accuracy: 0.9832\n",
      "Epoch 6/10\n",
      "302928/302928 [==============================] - 24s 79us/step - loss: 0.0545 - accuracy: 0.9873\n",
      "Epoch 7/10\n",
      "302928/302928 [==============================] - 23s 77us/step - loss: 0.0531 - accuracy: 0.9881\n",
      "Epoch 8/10\n",
      "302928/302928 [==============================] - 23s 76us/step - loss: 0.0574 - accuracy: 0.9869\n",
      "Epoch 9/10\n",
      "302928/302928 [==============================] - 23s 77us/step - loss: 0.0562 - accuracy: 0.9876\n",
      "Epoch 10/10\n",
      "302928/302928 [==============================] - 23s 77us/step - loss: 0.0440 - accuracy: 0.9903\n",
      "score: 99.22086243840373%\n",
      "7\n",
      "Epoch 1/10\n",
      "302928/302928 [==============================] - 26s 85us/step - loss: 0.9116 - accuracy: 0.9645\n",
      "Epoch 2/10\n",
      "302928/302928 [==============================] - 25s 82us/step - loss: 0.1157 - accuracy: 0.9783\n",
      "Epoch 3/10\n",
      "302928/302928 [==============================] - 25s 82us/step - loss: 0.0930 - accuracy: 0.9799\n",
      "Epoch 4/10\n",
      "302928/302928 [==============================] - 25s 82us/step - loss: 0.0697 - accuracy: 0.9797\n",
      "Epoch 5/10\n",
      "302928/302928 [==============================] - 25s 83us/step - loss: 0.0586 - accuracy: 0.9837\n",
      "Epoch 6/10\n",
      "302928/302928 [==============================] - 24s 81us/step - loss: 0.0531 - accuracy: 0.9859\n",
      "Epoch 7/10\n",
      "302928/302928 [==============================] - 25s 81us/step - loss: 0.0457 - accuracy: 0.9889\n",
      "Epoch 8/10\n",
      "302928/302928 [==============================] - 25s 81us/step - loss: 0.0446 - accuracy: 0.9897\n",
      "Epoch 9/10\n",
      "302928/302928 [==============================] - 25s 82us/step - loss: 0.0433 - accuracy: 0.9901\n",
      "Epoch 10/10\n",
      "302928/302928 [==============================] - 25s 82us/step - loss: 0.0445 - accuracy: 0.9900\n",
      "score: 99.07347430420292%\n",
      "8\n",
      "Epoch 1/10\n",
      "302928/302928 [==============================] - 27s 91us/step - loss: 7.6544 - accuracy: 0.9228\n",
      "Epoch 2/10\n",
      "302928/302928 [==============================] - 27s 88us/step - loss: 0.3212 - accuracy: 0.9703\n",
      "Epoch 3/10\n",
      "302928/302928 [==============================] - 27s 88us/step - loss: 0.1882 - accuracy: 0.9753\n",
      "Epoch 4/10\n",
      "302928/302928 [==============================] - 27s 88us/step - loss: 0.0783 - accuracy: 0.9798\n",
      "Epoch 5/10\n",
      "302928/302928 [==============================] - 27s 88us/step - loss: 0.0754 - accuracy: 0.9792\n",
      "Epoch 6/10\n",
      "302928/302928 [==============================] - 27s 89us/step - loss: 0.0670 - accuracy: 0.9842\n",
      "Epoch 7/10\n",
      "302928/302928 [==============================] - 27s 88us/step - loss: 0.0572 - accuracy: 0.9876\n",
      "Epoch 8/10\n",
      "302928/302928 [==============================] - 26s 87us/step - loss: 0.0693 - accuracy: 0.9828\n",
      "Epoch 9/10\n",
      "302928/302928 [==============================] - 26s 87us/step - loss: 0.0656 - accuracy: 0.9842\n",
      "Epoch 10/10\n",
      "302928/302928 [==============================] - 26s 87us/step - loss: 0.0654 - accuracy: 0.9849\n",
      "score: 99.19585842654509%\n",
      "9\n",
      "Epoch 1/10\n",
      "302928/302928 [==============================] - 29s 94us/step - loss: 0.5450 - accuracy: 0.9553\n",
      "Epoch 2/10\n",
      "302928/302928 [==============================] - 28s 93us/step - loss: 0.1028 - accuracy: 0.9838\n",
      "Epoch 3/10\n",
      "302928/302928 [==============================] - 28s 92us/step - loss: 0.0709 - accuracy: 0.9862\n",
      "Epoch 4/10\n",
      "302928/302928 [==============================] - 28s 93us/step - loss: 0.0577 - accuracy: 0.9871\n",
      "Epoch 5/10\n",
      "302928/302928 [==============================] - 29s 96us/step - loss: 0.0552 - accuracy: 0.9881\n",
      "Epoch 6/10\n",
      "302928/302928 [==============================] - 28s 93us/step - loss: 0.0490 - accuracy: 0.9882\n",
      "Epoch 7/10\n",
      "302928/302928 [==============================] - 28s 92us/step - loss: 0.0447 - accuracy: 0.9895\n",
      "Epoch 8/10\n",
      "302928/302928 [==============================] - 28s 92us/step - loss: 0.0439 - accuracy: 0.9899\n",
      "Epoch 9/10\n",
      "302928/302928 [==============================] - 28s 92us/step - loss: 0.0492 - accuracy: 0.9881\n",
      "Epoch 10/10\n",
      "302928/302928 [==============================] - 28s 92us/step - loss: 0.0440 - accuracy: 0.9898\n",
      "score: 99.21658431540278%\n"
     ]
    }
   ],
   "source": [
    "y_pred_list_nlayer = []\n",
    "for i in range(1,10):\n",
    "    print(i)\n",
    "    y_predict, y_test = ANN_regresion_nlayer(X, y, X.shape[1], layers=i, neurons=14 , activation='relu', epochs=10, batch_size=100, verbose=1)\n",
    "    score = metrics.roc_auc_score(y_test, y_predict)\n",
    "    \n",
    "    print(f'score: {score*100}%')\n",
    "    y_pred_list_nlayer.append(score)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {
    "colab_type": "text",
    "id": "Mro0DvciPO8t"
   },
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Plot functions y_pred_list_1layer\n",
    "plt.plot(range(1,10), y_pred_list_1layer, label=r\"$y=1-x$\")\n",
    "plt.show()\n",
    "# Plot functions y_pred_list_nNeuron\n",
    "plt.scatter(range(1,10), y_pred_list_nNeuron)\n",
    "plt.show()\n",
    "# Plot functions\n",
    "plt.scatter(range(1,10), y_pred_list_nlayer)\n",
    "plt.show()\n",
    "# print(f'Mean Squared Error{mean_squared_error(y_d, y_d_hat)}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "Mro0DvciPO8t"
   },
   "source": [
    "#### <a id=\"segundo\"></a>\n",
    "## 2. Challenge Kaggle\n",
    "\n",
    "Pendiente"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "ename": "FileNotFoundError",
     "evalue": "[WinError 3] El sistema no puede encontrar la ruta especificada: 'train_images'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mFileNotFoundError\u001b[0m                         Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-48-f608b2ac036c>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m     12\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     13\u001b[0m \u001b[0mpaths\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;33m[\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 14\u001b[1;33m \u001b[1;32mfor\u001b[0m \u001b[0mf\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mlistdir\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mdir\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     15\u001b[0m     \u001b[1;32mif\u001b[0m \u001b[0misfile\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mjoin\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mdir\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mf\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     16\u001b[0m         \u001b[0mpath\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mjoin\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mdir\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mf\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mFileNotFoundError\u001b[0m: [WinError 3] El sistema no puede encontrar la ruta especificada: 'train_images'"
     ]
    }
   ],
   "source": [
    "import numpy as np \n",
    "import pandas as pd\n",
    "from PIL import Image\n",
    "from os import listdir\n",
    "from os.path import isfile, join\n",
    "from keras.optimizers import Adam, SGD, Adagrad\n",
    "from keras.utils import to_categorical\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "dir = 'train_images'\n",
    "extension='jpg'\n",
    "\n",
    "paths = []\n",
    "for f in listdir(dir):\n",
    "    if isfile(join(dir,f)):\n",
    "        path = join(dir,f)\n",
    "        number = f.split('_')[1]\n",
    "        number = int(number.split('.')[0])\n",
    "        paths.append((number, path)) \n",
    "paths.sort(key= lambda file: file[0])\n",
    "\n",
    "imgs = []\n",
    "for _, path in paths:\n",
    "    image = Image.open(path).convert(\"RGB\")\n",
    "    image=np.asarray(image)\n",
    "    imgs.append(image)\n",
    "\n",
    "X = np.array(imgs)/255.0\n",
    "y = pd.read_csv('train_labels.csv')['Expected']\n",
    "\n",
    "\n",
    "classes = np.unique(y)\n",
    "n_classes = len(np.unique(y))\n",
    "count = 0\n",
    "labels ={}\n",
    "for l in classes:\n",
    "    labels[l] = count\n",
    "    count+=1\n",
    "y = np.array(y.replace(labels).tolist())\n",
    "y = to_categorical(y,n_classes)\n",
    "\n",
    "#Split train and test data\n",
    "# X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=10) \n",
    "X_train = X\n",
    "y_train = y\n",
    "\n",
    "print(f'Cantidad de clases a predecir: {n_classes}')\n",
    "print(f'Clases: {classes}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "N, width, height, depth = X_train.shape\n",
    "N, width, height, depth"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### VGG 19"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.models import Sequential\n",
    "from keras.layers import Activation, Dropout, Dense\n",
    "from keras.layers import Conv2D, MaxPooling2D,AveragePooling2D, Flatten\n",
    "\n",
    "def create_cnn(classes, width, height, depth):\n",
    "      \n",
    "    model = Sequential()\n",
    "    model.add(Conv2D(64, (3, 3), padding='same', input_shape=(width, height, depth), activation='relu'))\n",
    "    model.add(Conv2D(64,(3,3), padding='same', activation='relu'))\n",
    "    model.add(MaxPooling2D(pool_size=(2, 2)))\n",
    "\n",
    "    model.add(Conv2D(128, (3, 3), padding='same', activation='relu'))\n",
    "    model.add(Conv2D(128, (3, 3), padding='same', activation='relu'))\n",
    "    model.add(MaxPooling2D(pool_size=(2, 2)))\n",
    "\n",
    "    model.add(Conv2D(256, (3, 3), padding='same', activation='relu'))\n",
    "    model.add(Conv2D(256, (3, 3), padding='same', activation='relu'))\n",
    "    model.add(Conv2D(256, (3, 3), padding='same', activation='relu'))\n",
    "    model.add(MaxPooling2D(pool_size=(2, 2)))\n",
    "    \n",
    "    model.add(Conv2D(512, (3, 3), padding='same', activation='relu'))\n",
    "    model.add(Conv2D(512, (3, 3), padding='same', activation='relu'))\n",
    "    model.add(Conv2D(512, (3, 3), padding='same', activation='relu'))\n",
    "    model.add(Conv2D(512, (3, 3), padding='same', activation='relu'))\n",
    "    model.add(MaxPooling2D(pool_size=(2, 2)))\n",
    "    \n",
    "    model.add(Conv2D(512, (3, 3), padding='same', activation='relu'))\n",
    "    model.add(Conv2D(512, (3, 3), padding='same', activation='relu'))\n",
    "    model.add(Conv2D(512, (3, 3), padding='same', activation='relu'))\n",
    "    model.add(Conv2D(512, (3, 3), padding='same', activation='relu'))\n",
    "    model.add(MaxPooling2D(pool_size=(2, 2)))\n",
    "    \n",
    "    model.add(Flatten()) \n",
    "    model.add(Dense(units=4096,activation=\"relu\"))\n",
    "    model.add(Dense(units=4096,activation=\"relu\"))\n",
    "    model.add(Dense(units=1000, activation='relu'))\n",
    "    #model.add(Dropout(0.5))\n",
    "\n",
    "    if classes == 2:\n",
    "        model.add(Dense(1))\n",
    "        model.add(Activation('sigmoid'))\n",
    "    else:\n",
    "        model.add(Dense(classes, activation='softmax'))\n",
    "    return model\n",
    "\n",
    "CNN = create_cnn(n_classes, width, height, 3)\n",
    "CNN.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "optimizer = Adam()\n",
    "CNN.compile(loss='categorical_crossentropy', optimizer=optimizer, metrics=['accuracy'])\n",
    "CNN.fit(X_train,y_train, epochs=25, batch_size=32, verbose=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "CNN.evaluate(X_test, y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import keras\n",
    "from keras.layers import Dense, Conv2D, BatchNormalization, Activation\n",
    "from keras.layers import AveragePooling2D, Input, Flatten\n",
    "from keras.optimizers import Adam\n",
    "from keras.callbacks import ModelCheckpoint, LearningRateScheduler\n",
    "from keras.callbacks import ReduceLROnPlateau\n",
    "from keras.preprocessing.image import ImageDataGenerator\n",
    "from keras.regularizers import l2\n",
    "from keras import backend as K\n",
    "from keras.models import Model\n",
    "from keras.datasets import cifar10\n",
    "import numpy as np\n",
    "import os\n",
    "\n",
    "def lr_schedule(epoch):\n",
    "    \"\"\"Learning Rate Schedule\n",
    "\n",
    "    Learning rate is scheduled to be reduced after 80, 120, 160, 180 epochs.\n",
    "    Called automatically every epoch as part of callbacks during training.\n",
    "\n",
    "    # Arguments\n",
    "        epoch (int): The number of epochs\n",
    "\n",
    "    # Returns\n",
    "        lr (float32): learning rate\n",
    "    \"\"\"\n",
    "    lr = 1e-3\n",
    "    if epoch > 180:\n",
    "        lr *= 0.5e-3\n",
    "    elif epoch > 160:\n",
    "        lr *= 1e-3\n",
    "    elif epoch > 120:\n",
    "        lr *= 1e-2\n",
    "    elif epoch > 80:\n",
    "        lr *= 1e-1\n",
    "    print('Learning rate: ', lr)\n",
    "    return lr\n",
    "\n",
    "def resnet_layer(inputs,\n",
    "                 num_filters=16,\n",
    "                 kernel_size=3,\n",
    "                 strides=1,\n",
    "                 activation='relu',\n",
    "                 batch_normalization=True,\n",
    "                 conv_first=True\n",
    "                ):\n",
    "    \n",
    "    conv = Conv2D(num_filters,\n",
    "                  kernel_size=kernel_size,\n",
    "                  strides=strides,\n",
    "                  padding='same',\n",
    "                  kernel_initializer='he_normal',\n",
    "                  kernel_regularizer=l2(1e-4))\n",
    "\n",
    "    x = inputs\n",
    "    if conv_first:\n",
    "        x = conv(x)\n",
    "        if batch_normalization:\n",
    "            x = BatchNormalization()(x)\n",
    "        if activation is not None:\n",
    "            x = Activation(activation)(x)\n",
    "    else:\n",
    "        if batch_normalization:\n",
    "            x = BatchNormalization()(x)\n",
    "        if activation is not None:\n",
    "            x = Activation(activation)(x)\n",
    "        x = conv(x)\n",
    "    return x\n",
    "        \n",
    "def resnet(input_shape, depth, num_classes):\n",
    "    \"\"\"ResNet Version 2 Model builder [b]\n",
    "\n",
    "    Stacks of (1 x 1)-(3 x 3)-(1 x 1) BN-ReLU-Conv2D or also known as\n",
    "    bottleneck layer\n",
    "    First shortcut connection per layer is 1 x 1 Conv2D.\n",
    "    Second and onwards shortcut connection is identity.\n",
    "    At the beginning of each stage, the feature map size is halved (downsampled)\n",
    "    by a convolutional layer with strides=2, while the number of filter maps is\n",
    "    doubled. Within each stage, the layers have the same number filters and the\n",
    "    same filter map sizes.\n",
    "    Features maps sizes:\n",
    "    conv1  : 32x32,  16\n",
    "    stage 0: 32x32,  64\n",
    "    stage 1: 16x16, 128\n",
    "    stage 2:  8x8,  256\n",
    "\n",
    "    # Arguments\n",
    "        input_shape (tensor): shape of input image tensor\n",
    "        depth (int): number of core convolutional layers\n",
    "        num_classes (int): number of classes (CIFAR10 has 10)\n",
    "\n",
    "    # Returns\n",
    "        model (Model): Keras model instance\n",
    "    \"\"\"\n",
    "    if (depth - 2) % 9 != 0:\n",
    "        raise ValueError('depth should be 9n+2 (eg 56 or 110 in [b])')\n",
    "    # Start model definition.\n",
    "    num_filters_in = 16\n",
    "    num_res_blocks = int((depth - 2) / 9)\n",
    "\n",
    "    inputs = Input(shape=input_shape)\n",
    "    # v2 performs Conv2D with BN-ReLU on input before splitting into 2 paths\n",
    "    x = resnet_layer(inputs=inputs,\n",
    "                     num_filters=num_filters_in,\n",
    "                     conv_first=True)\n",
    "\n",
    "    # Instantiate the stack of residual units\n",
    "    for stage in range(3):\n",
    "        for res_block in range(num_res_blocks):\n",
    "            activation = 'relu'\n",
    "            batch_normalization = True\n",
    "            strides = 1\n",
    "            if stage == 0:\n",
    "                num_filters_out = num_filters_in * 4\n",
    "                if res_block == 0:  # first layer and first stage\n",
    "                    activation = None\n",
    "                    batch_normalization = False\n",
    "            else:\n",
    "                num_filters_out = num_filters_in * 2\n",
    "                if res_block == 0:  # first layer but not first stage\n",
    "                    strides = 2    # downsample\n",
    "\n",
    "            # bottleneck residual unit\n",
    "            y = resnet_layer(inputs=x,\n",
    "                             num_filters=num_filters_in,\n",
    "                             kernel_size=1,\n",
    "                             strides=strides,\n",
    "                             activation=activation,\n",
    "                             batch_normalization=batch_normalization,\n",
    "                             conv_first=False)\n",
    "            y = resnet_layer(inputs=y,\n",
    "                             num_filters=num_filters_in,\n",
    "                             conv_first=False)\n",
    "            y = resnet_layer(inputs=y,\n",
    "                             num_filters=num_filters_out,\n",
    "                             kernel_size=1,\n",
    "                             conv_first=False)\n",
    "            if res_block == 0:\n",
    "                # linear projection residual shortcut connection to match\n",
    "                # changed dims\n",
    "                x = resnet_layer(inputs=x,\n",
    "                                 num_filters=num_filters_out,\n",
    "                                 kernel_size=1,\n",
    "                                 strides=strides,\n",
    "                                 activation=None,\n",
    "                                 batch_normalization=False)\n",
    "            x = keras.layers.add([x, y])\n",
    "\n",
    "        num_filters_in = num_filters_out\n",
    "\n",
    "    # Add classifier on top.\n",
    "    # v2 has BN-ReLU before Pooling\n",
    "    x = BatchNormalization()(x)\n",
    "    x = Activation('relu')(x)\n",
    "    x = AveragePooling2D(pool_size=8)(x)\n",
    "    y = Flatten()(x)\n",
    "    outputs = Dense(num_classes,\n",
    "                    activation='softmax',\n",
    "                    kernel_initializer='he_normal')(y)\n",
    "\n",
    "    # Instantiate model.\n",
    "    model = Model(inputs=inputs, outputs=outputs)\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "os.environ[\"CUDA_VISIBLE_DEVICES\"] = \"1\"\n",
    "try:\n",
    "  %tensorflow_version 2.x\n",
    "except Exception:\n",
    "  pass\n",
    "import tensorflow as tf\n",
    "tf.keras.backend.clear_session()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "depth =  depth * 9 + 2\n",
    "resnetModel = resnet((128, 128, 3), depth, n_classes)\n",
    "resnetModel.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "optimizer = Adam()\n",
    "resnetModel.compile(loss='categorical_crossentropy', optimizer=optimizer, metrics=['accuracy'])\n",
    "resnetModel.fit(X_train,y_train, epochs=25, batch_size=32, verbose=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.models import load_model\n",
    "# resnetModel.save('1rst_resnet_80perc_traindata.h5')  # creates a HDF5 file 'my_model.h5'\n",
    "resnetModel.save('2d_resnet_100perc_traindata.h5')\n",
    "del resnetModel\n",
    "# returns a compiled model\n",
    "# identical to the previous one\n",
    "# model = load_model('1rst_resnet_80perc_traindata.h5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "resnetModel.evaluate(X_test, y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dir_test = 'test_images'\n",
    "extension='jpg'\n",
    "\n",
    "paths_test = []\n",
    "# print(listdir(dir_test))\n",
    "for f in listdir(dir_test):\n",
    "    if isfile(join(dir_test,f)):\n",
    "        path = join(dir_test,f)\n",
    "        number = f.split('_')[1]\n",
    "        number = int(number.split('.')[0])\n",
    "        paths_test.append((number, path)) \n",
    "paths_test.sort(key= lambda file: file[0])\n",
    "\n",
    "imgs_test = []\n",
    "for _, path in paths_test:\n",
    "    image_to_predict = Image.open(path).convert(\"RGB\")\n",
    "    image_to_predict=np.asarray(image_to_predict)\n",
    "    imgs_test.append(image_to_predict)\n",
    "\n",
    "X_kaggle= np.array(imgs_test)/255.0\n",
    "X_kaggle.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_kaggle = resnetModel.predict(X_kaggle)\n",
    "y_kaggle = y_kaggle.argmax(axis=-1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "inv_labels = {v: k for k, v in labels.items()}\n",
    "\n",
    "ids = [f'test_{i[0]}' for i in paths_test]\n",
    "\n",
    "data_kaggle = pd.DataFrame({'Id': ids , 'Expected':y_kaggle})\n",
    "data_kaggle['Expected'] = data_kaggle['Expected'].replace(inv_labels)\n",
    "data_kaggle.to_csv('1rst_try.csv', index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Dataset real 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = pd.read_csv('ks.csv',\n",
    "                 parse_dates=['deadline', 'launched'])\n",
    "\n",
    "data.drop('ID', axis = 1, inplace = True)\n",
    "data.drop('goal', axis = 1, inplace = True)\n",
    "data.drop('pledged', axis = 1, inplace = True)\n",
    "data.drop('usd pledged', axis = 1, inplace = True)\n",
    "\n",
    "data['deadline']=pd.to_datetime(data['deadline'], format=\"%Y/%m/%d\").dt.date\n",
    "data['launched']=pd.to_datetime(data['launched'], format=\"%Y/%m/%d\").dt.date\n",
    "\n",
    "data['days'] = (data['deadline'] - data['launched']).dt.days\n",
    "data['launch_year']=pd.to_datetime(data['launched'], format=\"%Y/%m/%d\").dt.year\n",
    "\n",
    "data[\"launch_year\"]=data['launch_year'].apply(str)\n",
    "\n",
    "data.corr()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_for_model = pd.read_csv('ks.csv')\n",
    "\n",
    "#Datetime Processing\n",
    "data_for_model['deadline']=pd.to_datetime(data_for_model['deadline'], format=\"%Y/%m/%d\")\n",
    "data_for_model['launched']=pd.to_datetime(data_for_model['launched'], format=\"%Y/%m/%d\")\n",
    "\n",
    "data_for_model['days'] = (data_for_model['deadline'] - data_for_model['launched']).dt.days\n",
    "data_for_model['launch_year']=pd.to_datetime(data_for_model['launched'], format=\"%Y/%m/%d\").dt.year\n",
    "data_for_model.drop(['ID',\"name\",\"category\",\"launched\",\"currency\",\"deadline\",\"usd pledged\",\"goal\",\"pledged\"], axis = 1, inplace = True)\n",
    "\n",
    "data_for_model[\"launch_year\"]=data_for_model['launch_year'].apply(str) #it has to be string.\n",
    "\n",
    "data_for_model.corr()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"Unbalanced Data shape\", len(data))\n",
    "datafail = data_for_model[data_for_model.state == \"failed\"]\n",
    "datasuccess = data_for_model[data_for_model.state == \"successful\"]\n",
    "data_for_model = pd.concat([datafail.sample(len(datasuccess), random_state=5), datasuccess])\n",
    "print(\"Balanced data shape:\", len(data))\n",
    "data_for_model.state.value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def state_process(cell_value):\n",
    "    if cell_value == 'successful':\n",
    "        return 1\n",
    "    else:\n",
    "        return 0    \n",
    "data_for_model.state = data_for_model.state.apply(state_process)\n",
    "data_for_model.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print('Original Features:\\n', list(data.columns), '\\n')\n",
    "data_for_model= pd.get_dummies(data_for_model)\n",
    "print('Features after One-Hot Encoding:\\n', list(data_for_model.columns))\n",
    "data_for_model.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def ANN_regresion_nN(X, y, input_dim, neurons=2, layers=1, activation='relu', epochs=10, batch_size=100, verbose=2):\n",
    "    \n",
    "    X_train, X_test, y_train, y_test = train_test_split(X, y, test_size = 0.20, random_state = 0)\n",
    "    \n",
    "    scaler = MinMaxScaler((-1,1))\n",
    "    X_train_scaled = scaler.fit_transform(X_train)\n",
    "    X_test_scaled = scaler.transform(X_test)\n",
    "    \n",
    "    model = Sequential()\n",
    "    neurons = int(np.round(neurons/layers)) if neurons > 1 else 1\n",
    "    model.add(Dense(units=neurons, input_dim=input_dim, activation='relu'))\n",
    "    for i in range(layers-1):\n",
    "        model.add(Dense(units=neurons, activation='relu'))\n",
    "    model.add(Dense(units=1, activation='sigmoid'))\n",
    "    \n",
    "    model.compile(loss='binary_crossentropy', optimizer='adam', metrics=['accuracy'])\n",
    "    model.fit(X_train, y_train, epochs=epochs, batch_size=batch_size, verbose=verbose)\n",
    "    \n",
    "    y_pred = model.predict(X_test, batch_size = batch_size)\n",
    "    y_pred = (y_pred > 0.5)\n",
    "    \n",
    "    return y_pred, y_test\n",
    "\n",
    "def ANN_regresion_nlayer(X, y, input_dim, layers, neurons=2 , activation='relu', epochs=10, batch_size=100, verbose=2):\n",
    "    \n",
    "    X_train, X_test, y_train, y_test = train_test_split(X, y, test_size = 0.20, random_state = 0)\n",
    "    \n",
    "    scaler = MinMaxScaler((-1,1))\n",
    "    X_train_scaled = scaler.fit_transform(X_train)\n",
    "    X_test_scaled = scaler.transform(X_test)\n",
    "    \n",
    "    model = Sequential()\n",
    "    model.add(Dense(units=neurons, input_dim=input_dim, activation='relu'))\n",
    "    for i in range(layers-1):\n",
    "        model.add(Dense(units=neurons, activation='relu'))\n",
    "    model.add(Dense(units=1, activation='sigmoid'))\n",
    "    \n",
    "    model.compile(loss='binary_crossentropy', optimizer='adam', metrics=['accuracy'])\n",
    "    model.fit(X_train, y_train, epochs=epochs, batch_size=batch_size, verbose=verbose)\n",
    "    \n",
    "    y_pred = model.predict(X_test, batch_size = batch_size)\n",
    "    y_pred = (y_pred > 0.5)\n",
    "    \n",
    "    return y_pred, y_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn import metrics\n",
    "\n",
    "X = data_for_model.iloc[:,data_for_model.columns != 'state']\n",
    "y = data_for_model.state"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred_list_1layer = []\n",
    "for i in range(1,10):\n",
    "    print(i)\n",
    "    y_predict, y_test = ANN_regresion_nlayer(X, y, X.shape[1], layers=1, neurons=i , activation='relu', epochs=10, batch_size=100, verbose=1)\n",
    "    score = metrics.roc_auc_score(y_test, y_predict)\n",
    "    \n",
    "    print(f'score: {score*100}%')\n",
    "    y_pred_list_1layer.append(score)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred_list_nNeuron = []\n",
    "for i in range(1,10):\n",
    "    print(i)\n",
    "    y_predict, y_test = ANN_regresion_nN(X, y, X.shape[1], layers=i, neurons=10 , activation='relu', epochs=10, batch_size=100, verbose=1)\n",
    "    score = metrics.roc_auc_score(y_test, y_predict)\n",
    "    \n",
    "    print(f'score: {score*100}%')\n",
    "    y_pred_list_nNeuron.append(score)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred_list_nlayer = []\n",
    "for i in range(1,10):\n",
    "    print(i)\n",
    "    y_predict, y_test = ANN_regresion_nlayer(X, y, X.shape[1], layers=i, neurons=10 , activation='relu', epochs=10, batch_size=100, verbose=1)\n",
    "    score = metrics.roc_auc_score(y_test, y_predict)\n",
    "    \n",
    "    print(f'score: {score*100}%')\n",
    "    y_pred_list_nlayer.append(score)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Plot functions y_pred_list_1layer\n",
    "plt.plot(range(1,10), y_pred_list_1layer, label=r\"$y=1-x$\")\n",
    "plt.show()\n",
    "# Plot functions y_pred_list_nNeuron\n",
    "plt.scatter(range(1,10), y_pred_list_nNeuron)\n",
    "plt.show()\n",
    "# Plot functions\n",
    "plt.scatter(range(1,10), y_pred_list_nlayer)\n",
    "plt.show()\n",
    "# print(f'Mean Squared Error{mean_squared_error(y_d, y_d_hat)}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = pd.read_csv('ks.csv',\n",
    "                 parse_dates=['deadline', 'launched'])\n",
    "\n",
    "data.drop('ID', axis = 1, inplace = True)\n",
    "data.drop('goal', axis = 1, inplace = True)\n",
    "data.drop('pledged', axis = 1, inplace = True)\n",
    "data.drop('usd pledged', axis = 1, inplace = True)\n",
    "\n",
    "data['deadline']=pd.to_datetime(data['deadline'], format=\"%Y/%m/%d\").dt.date\n",
    "data['launched']=pd.to_datetime(data['launched'], format=\"%Y/%m/%d\").dt.date\n",
    "\n",
    "data['days'] = (data['deadline'] - data['launched']).dt.days\n",
    "data['launch_year']=pd.to_datetime(data['launched'], format=\"%Y/%m/%d\").dt.year\n",
    "\n",
    "data[\"launch_year\"]=data['launch_year'].apply(str)\n",
    "\n",
    "data_for_model = pd.read_csv('ks.csv')\n",
    "\n",
    "#Datetime Processing\n",
    "data_for_model['deadline']=pd.to_datetime(data_for_model['deadline'], format=\"%Y/%m/%d\")\n",
    "data_for_model['launched']=pd.to_datetime(data_for_model['launched'], format=\"%Y/%m/%d\")\n",
    "\n",
    "data_for_model['days'] = (data_for_model['deadline'] - data_for_model['launched']).dt.days\n",
    "data_for_model['launch_year']=pd.to_datetime(data_for_model['launched'], format=\"%Y/%m/%d\").dt.year\n",
    "data_for_model.drop(['ID',\"name\",\"category\",\"launched\",\"currency\",\"deadline\",\"usd pledged\",\"pledged\", \"country\", \"main_category\"], axis = 1, inplace = True)\n",
    "\n",
    "data_for_model[\"launch_year\"]=data_for_model['launch_year'].apply(str) #it has to be string."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# print(\"Unbalanced Data shape\", len(data))\n",
    "# datafail = data_for_model[data_for_model.state == \"failed\"]\n",
    "# datasuccess = data_for_model[data_for_model.state == \"successful\"]\n",
    "# data_for_model = pd.concat([datafail.sample(len(datasuccess), random_state=5), datasuccess])\n",
    "# print(\"Balanced data shape:\", len(data))\n",
    "# data_for_model.state.value_counts()\n",
    "\n",
    "def state_process(cell_value):\n",
    "    if cell_value == 'successful':\n",
    "        return 1\n",
    "    else:\n",
    "        return 0    \n",
    "data_for_model.state = data_for_model.state.apply(state_process)\n",
    "\n",
    "data_for_model.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn import metrics\n",
    "\n",
    "X = data_for_model.iloc[:,data_for_model.columns != 'state']\n",
    "y = data_for_model.state"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred_list_1layer = []\n",
    "for i in range(1,10):\n",
    "    print(i)\n",
    "    y_predict, y_test = ANN_regresion_nlayer(X, y, X.shape[1], layers=1, neurons=i , activation='relu', epochs=10, batch_size=100, verbose=1)\n",
    "    score = metrics.roc_auc_score(y_test, y_predict)\n",
    "    \n",
    "    print(f'score: {score*100}%')\n",
    "    y_pred_list_1layer.append(score)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred_list_nNeuron = []\n",
    "for i in range(1,10):\n",
    "    print(i)\n",
    "    y_predict, y_test = ANN_regresion_nN(X, y, X.shape[1], layers=i, neurons=14 , activation='relu', epochs=10, batch_size=100, verbose=1)\n",
    "    score = metrics.roc_auc_score(y_test, y_predict)\n",
    "    \n",
    "    print(f'score: {score*100}%')\n",
    "    y_pred_list_nNeuron.append(score)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred_list_nlayer = []\n",
    "for i in range(1,10):\n",
    "    print(i)\n",
    "    y_predict, y_test = ANN_regresion_nlayer(X, y, X.shape[1], layers=i, neurons=14 , activation='relu', epochs=10, batch_size=100, verbose=1)\n",
    "    score = metrics.roc_auc_score(y_test, y_predict)\n",
    "    \n",
    "    print(f'score: {score*100}%')\n",
    "    y_pred_list_nlayer.append(score)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plot functions y_pred_list_1layer\n",
    "plt.plot(range(1,10), y_pred_list_1layer, label=r\"$y=1-x$\")\n",
    "plt.show()\n",
    "# Plot functions y_pred_list_nNeuron\n",
    "plt.scatter(range(1,10), y_pred_list_nNeuron)\n",
    "plt.show()\n",
    "# Plot functions\n",
    "plt.scatter(range(1,10), y_pred_list_nlayer)\n",
    "plt.show()\n",
    "# print(f'Mean Squared Error{mean_squared_error(y_d, y_d_hat)}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Resnet 50"
   ]
  }
 ],
 "metadata": {
  "colab": {
   "collapsed_sections": [],
   "name": "[ANN]Taller1.ipynb",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
