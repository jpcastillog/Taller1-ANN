{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "L5rfZ_hYaQ1Z"
   },
   "source": [
    "<img src=\"http://www.exalumnos.usm.cl/wp-content/uploads/2015/06/Isotipo-Negro.gif\" title=\"Title text\" width=\"30%\" />\n",
    "\n",
    "<hr style=\"height:2px;border:none\"/>\n",
    "<h1 align='center'> INF-395/477 Redes Neuronales Artificiales I-2020 </h1>\n",
    "\n",
    "<H3 align='center'> Tarea 1 - Redes Neuronales y *Deep Learning* </H3>\n",
    "<hr style=\"height:2px;border:none\"/>\n",
    "\n",
    "**Temas**  \n",
    "\n",
    "* Arquitectura Básica de Redes Neuronales. Redes *Feed-Forward*\n",
    "* Entrenamiento de Redes Neuronales. \n",
    "* Redes Convolucionales. \n",
    "\n",
    "**Formalidades**  \n",
    "* Equipos de trabajo de: 3 personas (*cada uno debe estar en condiciones de realizar una presentación y discutir sobre cada punto del trabajo realizado*)\n",
    "* Formato de entrega: envı́o de link Github y link de video Youtube o plataforma a convenir, todo esto vía Aula. \n",
    "\n",
    "<hr style=\"height:2px;border:none\"/>\n",
    "\n",
    "### **Propuesta**\n",
    "* Se debe preparar una presentación de **15 a 20 minutos** donde se explique el cómo se va a realizar/resolver el taller, la metodología o propuesta de las componentes a experimentar y explorar. Más detalles en el Syllabus.\n",
    "* Fecha de encuentro Zoom: 8 de Mayo en horario de clases.\n",
    "* Fecha de entrega de vídeo: Opcional para quienes presentaron y obligatorio para quienes no, a lo más 2 días después del encuentro.\n",
    "* Modalidad de Presentación (Zoom): En el primer bloque, se formarán 3 grupos para que alcancen a recibir feedback todos los equipos. En el segundo bloque, algunos equipos seleccionados presentarán a todo el curso. \n",
    "\n",
    "**Aún si la idea es aprender colaborativamente, valoraremos mucho la diversidad de ideas, por lo que las propuesta debiesen conservar su orientación inicial, excepto por el feedback que les entreguemos**\n",
    "\n",
    "### **Defensa**\n",
    "* Se debe preparar una presentación de **15 a 20 minutos** con los resultados obtenidos y conclusiones de la experiencia. \n",
    "* Se debe entregar el código, de preferencia en un (breve) Jupyter/IPython notebook, de modo que **permita reproducir los resultados** presentados. Si se entrega el código fuente se deben proveer instrucciones para su uso.\n",
    "* Fecha de encuentro Zoom: 29 de Mayo, horario de clases.\n",
    "* Fecha de entrega de vídeo: 27 de Mayo (2 días antes de encuentro).\n",
    "* Fecha de entrega de Jypter (notebook): 27 de Mayo (commits hasta el 29 de Mayo en horario de clases). \n",
    "* Modalidad de Presentación (Zoom): En ambos bloques algunos equipos seleccionados presentarán ante todo el curso, discusión y debate se generará en base a los resultados.\n",
    "\n",
    "<hr style=\"height:2px;border:none\"/>\n",
    "\n",
    "La tarea se divide en secciones:\n",
    "\n",
    "[1.](#primero) Pregunta Libre   \n",
    "[2.](#segundo) Challenge Kaggle\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "fTkbRyusPMok"
   },
   "source": [
    "#### <a id=\"primero\"></a>\n",
    "## 1. Pregunta Libre\n",
    "\n",
    "Refute o evidencie experimentalmente una de las siguientes afirmaciones \n",
    "\n",
    "> **1. Rol de la Profundidad**: Si se toma una arquitectura base cualquiera, $A$, de red neuronal y se añade una capa, $A^{+1}$, siempre se mejorará la tarea objetivo en el conjunto de entrenamiento, validación y pruebas. Eso no depende de la forma de entrenar.\n",
    "\n",
    "R: ¿Que pasa si agrego capas con una neurona?\n",
    "\n",
    "> **2. Teorema de approx. universal**: Una arquitectura de red neuronal tiene la capacidad de aproximar cualquier función y esto es independiente del número de neuronas o capas.\n",
    "\n",
    "R: El detalle, es que la red neuronal tiene la capacidad de aproximar solo funciones **continuas**\n",
    "\n",
    "> **3. Rol de la Profundidad**: Si se toma una arquitectura base $A$ con $n$ neuronas y $L$ capas, y se redistribuyen las neuronas aumentando $L$, será posible aprender mejor y más rápido la tarea. \n",
    "\n",
    "R:\n",
    "\n",
    "> **4. Convergencia**: Con la suficiente cantidad de iteraciones, una red neuronal siempre podrá converger algun mínimo local. El tiempo que tarda es independiente de la tasa de aprendizaje y el tamaño de batch.\n",
    "\n",
    "> **5. Convergencia (2)**: La velocidad de aprendizaje es independiente de la función de activación que se utilice en las capas ocultas y del número de ejemplos de entrenamiento. \n",
    "\n",
    "> **6. Approx universal y tolerancia a ruido**: Una red neuronal tiene la capacidad de aprender en el conjunto entrenado, incluso si el *target* (objetivo de la tarea) es aleatorio. Si el porcentaje de etiquetas corruptas  (por ejemplo con un *shift* o *shuffle* sobre $y$) es pequeño, la red aprende la tarea correcta.\n",
    "\n",
    "> **7. Arquitectura y parámetros de CNN**: Una red convolucional siempre tendrá menor cantidad de parámetros que una red *Feed Forward*, por ende, su desempeño en la tarea estará limitado.\n",
    "\n",
    "> **8. Ventajas de una CNN**: En cualquier problema que se tenga estructura espacial (uni-dimensional como texto o bi-dimensional como imágenes), una red neuronal con arquitectura convolucional será la más **adecuada** para resolverlo.\n",
    "\n",
    "> **9. Aplicaciones de una CNN**: No resulta ventajoso aplicar una red con arquitectura convolucional en problemas de regresión. \n",
    "\n",
    "> **10. Aplicaciones de una NN**: Las redes neuroanles no se aplican correctamente a problemas multi-label.\n",
    "\n",
    "> **11. Limitaciones de una NN**: El desbalanceo de las clases no tiene ningún efecto en el entrenamiento de la red.\n",
    "\n",
    "**Reglas mínimas**: Validar en al menos 1 dataset sintético y 2 reales.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## XOR Example"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "matrix size of train set (100000, 2)\n",
      "\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0.7516599893569946"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from keras.models import Sequential\n",
    "from keras.layers.core import Dense, Dropout, Activation\n",
    "from keras.optimizers import SGD\n",
    "import numpy as np\n",
    "\n",
    "size_train = 100000\n",
    "\n",
    "# Create pair of numbers (a, b)\n",
    "a = np.random.randint(0,2,size_train)[:,np.newaxis]\n",
    "b = np.random.randint(0,2,size_train)[:,np.newaxis]\n",
    "# Label of xor, between a and b \n",
    "y = np.logical_xor(a, b).astype(int)\n",
    "x = np.concatenate([a,b], axis=1)\n",
    "print(f'matrix size of train set {x.shape}\\n')\n",
    "\n",
    "# Parameters\n",
    "n_neurons = 2\n",
    "n_layers = 1\n",
    "\n",
    "model = Sequential()\n",
    "model.add(Dense(units=n_neurons, input_dim=x.shape[1], activation='relu'))\n",
    "for i in range (n_layers-1):\n",
    "    model.add(Dense(units=n_neurons,activation='relu'))\n",
    "model.add(Dense(units=1, activation='sigmoid'))\n",
    "model.compile(optimizer=SGD(lr=0.1), loss='binary_crossentropy', metrics=['accuracy'])\n",
    "model.fit(x,y, epochs=25, batch_size=128, verbose=0)\n",
    "y_hat = model.predict(x)\n",
    "model.evaluate(x, y, verbose=0)[1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import mean_squared_error\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "from matplotlib import pyplot as plt "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "def ANN_regresion(X, y, input_dim,neurons=2, layers=1, activation='relu', epochs=25, batch_size=128,verbose=0):\n",
    "    model = Sequential()\n",
    "    model.add(Dense(units=neurons, input_dim=input_dim, activation='relu'))\n",
    "    for i in range(layers-1):\n",
    "        model.add(Dense(units=neurons, activation='relu'))\n",
    "    model.add(Dense(units=1))\n",
    "    model.compile(optimizer=SGD(lr=0.1), loss='mse')\n",
    "    model.fit(X, y, epochs=epochs, batch_size=batch_size, verbose=0)\n",
    "    return model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##  Continous Function Example"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mean Squared Error: 0.03314741199223279\n"
     ]
    }
   ],
   "source": [
    "# Continuous function\n",
    "f_c = lambda x: np.sin(x)\n",
    "f_c = np.vectorize(f_c)\n",
    "\n",
    "x_c = np.random.uniform(low=-10, high=10, size=(100000,))[:,np.newaxis]\n",
    "y_c = f_c(x_c)\n",
    "\n",
    "# transform to [0~1] scale\n",
    "scale_x = MinMaxScaler()\n",
    "x_c = scale_x.fit_transform(x_c)\n",
    "scale_y = MinMaxScaler()\n",
    "y_c = scale_y.fit_transform(y_c)\n",
    "\n",
    "neurons = 100\n",
    "layers = 2\n",
    "act_function = 'relu'\n",
    "\n",
    "model = ANN_regresion(x_c, y_c, 1,\n",
    "                      neurons=neurons,\n",
    "                      layers=layers,\n",
    "                      activation=act_function,\n",
    "                      epochs=25,\n",
    "                      batch_size=128,\n",
    "                      verbose=0)\n",
    "#  Predict Train Data\n",
    "y_c_hat = model.predict(x_c)\n",
    "\n",
    "# Transform to real scale\n",
    "x_c = scale_x.inverse_transform(x_c)\n",
    "y_c = scale_y.inverse_transform(y_c)\n",
    "y_c_hat = scale_y.inverse_transform(y_c_hat)\n",
    "\n",
    "# Plot functions\n",
    "plt.scatter(x_c, y_c)\n",
    "plt.show()\n",
    "plt.scatter(x_c, y_c_hat)\n",
    "plt.show()\n",
    "\n",
    "print(f'Mean Squared Error: {mean_squared_error(y_c, y_c_hat)}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Discontinuous Function Example"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(200000, 1)\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mean Squared Error437649.7412916858\n"
     ]
    }
   ],
   "source": [
    "# Discontinuous function\n",
    "# f_d = lambda x: x**2 if x <0 else 40 + 10*x\n",
    "f_d = lambda x: 1 /(x)\n",
    "f_d = np.vectorize(f_d)\n",
    "x_d_1 = np.random.uniform(low=-5, high=-1e-17, size=(100000,))[:,np.newaxis]\n",
    "x_d_2 = np.random.uniform(low=1e-17, high=5, size=(100000,))[:,np.newaxis]\n",
    "x_d = np.concatenate((x_d_1, x_d_2), axis = 0)\n",
    "print(x_d.shape)\n",
    "y_d = f_d(x_d)\n",
    "\n",
    "# transform to [0~1] scale\n",
    "scale_x = MinMaxScaler()\n",
    "x_d = scale_x.fit_transform(x_d)\n",
    "scale_y = MinMaxScaler()\n",
    "y_d = scale_y.fit_transform(y_d)\n",
    "\n",
    "neurons = 10\n",
    "layers = 100\n",
    "act_function='relu'\n",
    "\n",
    "model = ANN_regresion(x_d, y_d, 1,\n",
    "                      neurons=neurons,\n",
    "                      layers=layers,\n",
    "                      activation=act_function,\n",
    "                      epochs=25,\n",
    "                      batch_size=128,\n",
    "                      verbose=0)\n",
    "# Predict Train Data\n",
    "y_d_hat = model.predict(x_d)\n",
    "\n",
    "# Transform to real scale\n",
    "x_d = scale_x.inverse_transform(x_d)\n",
    "y_d = scale_y.inverse_transform(y_d)\n",
    "y_d_hat = scale_y.inverse_transform(y_d_hat)\n",
    "\n",
    "# Plot functions\n",
    "plt.scatter(x_d, y_d)\n",
    "plt.ylim(-100,100)\n",
    "plt.show()\n",
    "plt.scatter(x_d, y_d_hat)\n",
    "plt.show()\n",
    "print(f'Mean Squared Error{mean_squared_error(y_d, y_d_hat)}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "import math\n",
    "\n",
    "math.ceil(0.1)\n",
    "f_ceil = lambda x: math.ceil(x)\n",
    "f_ceil = np.vectorize(f_ceil)\n",
    "x = np.random.uniform(low=0, high=10, size=(100000,))[:,np.newaxis]\n",
    "y = f_ceil(x)\n",
    "\n",
    "scale_x = MinMaxScaler()\n",
    "x = scale_x.fit_transform(x)\n",
    "scale_y = MinMaxScaler()\n",
    "y = scale_y.fit_transform(y)\n",
    "\n",
    "neurons = 10\n",
    "layers = 10\n",
    "act_function='relu'\n",
    "\n",
    "model = ANN_regresion(x, y, 1,\n",
    "                      neurons=neurons,\n",
    "                      layers=layers,\n",
    "                      activation=act_function,\n",
    "                      epochs=25,\n",
    "                      batch_size=128,\n",
    "                      verbose=0)\n",
    "# Predict Train Data\n",
    "y_hat = model.predict(x)\n",
    "\n",
    "# Transform to real scale\n",
    "x = scale_x.inverse_transform(x)\n",
    "y = scale_y.inverse_transform(y)\n",
    "y_hat = scale_y.inverse_transform(y_hat)\n",
    "\n",
    "\n",
    "plt.scatter(x,y)\n",
    "plt.show()\n",
    "plt.scatter(x,y_hat)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Primer Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn import preprocessing\n",
    "from sklearn.model_selection import train_test_split\n",
    "from keras.optimizers import Adam\n",
    "from keras.callbacks import EarlyStopping"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "df = pd.read_csv('high_diamond_ranked_10min.csv')\n",
    "df = df.drop(['gameId','blueWardsDestroyed','blueFirstBlood','blueDragons','blueHeralds','blueTotalExperience','blueCSPerMin','redWardsPlaced','redWardsDestroyed','redFirstBlood','redDragons','redHeralds','redTotalExperience','redCSPerMin'],axis= 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>blueWardsPlaced</th>\n",
       "      <th>blueKills</th>\n",
       "      <th>blueDeaths</th>\n",
       "      <th>blueAssists</th>\n",
       "      <th>blueEliteMonsters</th>\n",
       "      <th>blueTowersDestroyed</th>\n",
       "      <th>blueTotalGold</th>\n",
       "      <th>blueAvgLevel</th>\n",
       "      <th>blueTotalMinionsKilled</th>\n",
       "      <th>blueTotalJungleMinionsKilled</th>\n",
       "      <th>...</th>\n",
       "      <th>redAssists</th>\n",
       "      <th>redEliteMonsters</th>\n",
       "      <th>redTowersDestroyed</th>\n",
       "      <th>redTotalGold</th>\n",
       "      <th>redAvgLevel</th>\n",
       "      <th>redTotalMinionsKilled</th>\n",
       "      <th>redTotalJungleMinionsKilled</th>\n",
       "      <th>redGoldDiff</th>\n",
       "      <th>redExperienceDiff</th>\n",
       "      <th>redGoldPerMin</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>28</td>\n",
       "      <td>9</td>\n",
       "      <td>6</td>\n",
       "      <td>11</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>17210</td>\n",
       "      <td>6.6</td>\n",
       "      <td>195</td>\n",
       "      <td>36</td>\n",
       "      <td>...</td>\n",
       "      <td>8</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>16567</td>\n",
       "      <td>6.8</td>\n",
       "      <td>197</td>\n",
       "      <td>55</td>\n",
       "      <td>-643</td>\n",
       "      <td>8</td>\n",
       "      <td>1656.7</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>12</td>\n",
       "      <td>5</td>\n",
       "      <td>5</td>\n",
       "      <td>5</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>14712</td>\n",
       "      <td>6.6</td>\n",
       "      <td>174</td>\n",
       "      <td>43</td>\n",
       "      <td>...</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>17620</td>\n",
       "      <td>6.8</td>\n",
       "      <td>240</td>\n",
       "      <td>52</td>\n",
       "      <td>2908</td>\n",
       "      <td>1173</td>\n",
       "      <td>1762.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>15</td>\n",
       "      <td>7</td>\n",
       "      <td>11</td>\n",
       "      <td>4</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>16113</td>\n",
       "      <td>6.4</td>\n",
       "      <td>186</td>\n",
       "      <td>46</td>\n",
       "      <td>...</td>\n",
       "      <td>14</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>17285</td>\n",
       "      <td>6.8</td>\n",
       "      <td>203</td>\n",
       "      <td>28</td>\n",
       "      <td>1172</td>\n",
       "      <td>1033</td>\n",
       "      <td>1728.5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>43</td>\n",
       "      <td>4</td>\n",
       "      <td>5</td>\n",
       "      <td>5</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>15157</td>\n",
       "      <td>7.0</td>\n",
       "      <td>201</td>\n",
       "      <td>55</td>\n",
       "      <td>...</td>\n",
       "      <td>10</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>16478</td>\n",
       "      <td>7.0</td>\n",
       "      <td>235</td>\n",
       "      <td>47</td>\n",
       "      <td>1321</td>\n",
       "      <td>7</td>\n",
       "      <td>1647.8</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>75</td>\n",
       "      <td>6</td>\n",
       "      <td>6</td>\n",
       "      <td>6</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>16400</td>\n",
       "      <td>7.0</td>\n",
       "      <td>210</td>\n",
       "      <td>57</td>\n",
       "      <td>...</td>\n",
       "      <td>7</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>17404</td>\n",
       "      <td>7.0</td>\n",
       "      <td>225</td>\n",
       "      <td>67</td>\n",
       "      <td>1004</td>\n",
       "      <td>-230</td>\n",
       "      <td>1740.4</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 25 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   blueWardsPlaced  blueKills  blueDeaths  blueAssists  blueEliteMonsters  \\\n",
       "0               28          9           6           11                  0   \n",
       "1               12          5           5            5                  0   \n",
       "2               15          7          11            4                  1   \n",
       "3               43          4           5            5                  1   \n",
       "4               75          6           6            6                  0   \n",
       "\n",
       "   blueTowersDestroyed  blueTotalGold  blueAvgLevel  blueTotalMinionsKilled  \\\n",
       "0                    0          17210           6.6                     195   \n",
       "1                    0          14712           6.6                     174   \n",
       "2                    0          16113           6.4                     186   \n",
       "3                    0          15157           7.0                     201   \n",
       "4                    0          16400           7.0                     210   \n",
       "\n",
       "   blueTotalJungleMinionsKilled  ...  redAssists  redEliteMonsters  \\\n",
       "0                            36  ...           8                 0   \n",
       "1                            43  ...           2                 2   \n",
       "2                            46  ...          14                 0   \n",
       "3                            55  ...          10                 0   \n",
       "4                            57  ...           7                 1   \n",
       "\n",
       "   redTowersDestroyed  redTotalGold  redAvgLevel  redTotalMinionsKilled  \\\n",
       "0                   0         16567          6.8                    197   \n",
       "1                   1         17620          6.8                    240   \n",
       "2                   0         17285          6.8                    203   \n",
       "3                   0         16478          7.0                    235   \n",
       "4                   0         17404          7.0                    225   \n",
       "\n",
       "   redTotalJungleMinionsKilled  redGoldDiff  redExperienceDiff  redGoldPerMin  \n",
       "0                           55         -643                  8         1656.7  \n",
       "1                           52         2908               1173         1762.0  \n",
       "2                           28         1172               1033         1728.5  \n",
       "3                           47         1321                  7         1647.8  \n",
       "4                           67         1004               -230         1740.4  \n",
       "\n",
       "[5 rows x 25 columns]"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df1 = df.loc[:, df.columns != 'blueWins']\n",
    "df2 = df['blueWins']\n",
    "\n",
    "df1.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "df1 = preprocessing.scale(df1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(df1, df2, test_size=0.2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = Sequential()\n",
    "model.add(Dense(22,input_shape=(25,), activation = 'relu'))\n",
    "model.add(Dense(1,activation='sigmoid'))\n",
    "model.compile(loss='binary_crossentropy', optimizer=Adam(lr=0.001), metrics = ['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 00046: early stopping\n"
     ]
    }
   ],
   "source": [
    "earlystopper = EarlyStopping(monitor='val_loss', min_delta=0, patience=15, verbose=1, mode='auto')\n",
    "history = model.fit(X_train, y_train, epochs = 2000, validation_split = 0.15, verbose = 0, \n",
    "                    callbacks = [earlystopper])\n",
    "history_dict=history.history"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1976/1976 [==============================] - 0s 20us/step\n",
      "Test loss:  0.5318500650556464\n",
      "Test accuracy:  0.7252024412155151\n"
     ]
    }
   ],
   "source": [
    "loss, acc = model.evaluate(X_test, y_test)\n",
    "print(\"Test loss: \", loss)\n",
    "print(\"Test accuracy: \", acc)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Primer dataset variando el numero de capas "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 00052: early stopping\n",
      "1976/1976 [==============================] - 0s 17us/step\n",
      "Epoch 00024: early stopping\n",
      "1976/1976 [==============================] - 0s 20us/step\n",
      "Epoch 00044: early stopping\n",
      "1976/1976 [==============================] - 0s 21us/step\n"
     ]
    }
   ],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(df1, df2, test_size=0.2)\n",
    "model = Sequential()\n",
    "model.add(Dense(22,input_shape=(25,), activation = 'relu'))\n",
    "capas = [4,8,12]\n",
    "resultados = []\n",
    "for j in range(0,len(capas)):\n",
    "    for i in range(0,capas[j]):\n",
    "        model.add(Dense(14,activation = 'relu'))\n",
    "    model.add(Dense(1,activation='sigmoid'))\n",
    "    model.compile(loss='binary_crossentropy', optimizer=Adam(lr=0.001), metrics = ['accuracy'])\n",
    "    earlystopper = EarlyStopping(monitor='val_loss', min_delta=0, patience=15, verbose=1, mode='auto')\n",
    "    history = model.fit(X_train, y_train, epochs = 2000, validation_split = 0.15, verbose = 0, \n",
    "                    callbacks = [earlystopper])\n",
    "    loss, acc = model.evaluate(X_test, y_test)\n",
    "    resultados.append((loss,acc))\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>loss</th>\n",
       "      <th>acc</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>4 capas</th>\n",
       "      <td>0.554342</td>\n",
       "      <td>0.726215</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8 capas</th>\n",
       "      <td>0.693276</td>\n",
       "      <td>0.494939</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12 capas</th>\n",
       "      <td>0.693152</td>\n",
       "      <td>0.494433</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "              loss       acc\n",
       "4 capas   0.554342  0.726215\n",
       "8 capas   0.693276  0.494939\n",
       "12 capas  0.693152  0.494433"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tabla = pd.DataFrame(resultados, index =['4 capas', '8 capas', '12 capas'], columns = ['loss', 'acc'])\n",
    "tabla"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "hola\n",
      "hola\n",
      "hola\n",
      "hola\n",
      "hola\n",
      "hola\n",
      "hola\n",
      "hola\n",
      "hola\n",
      "hola\n",
      "hola\n",
      "hola\n",
      "hola\n",
      "hola\n",
      "hola\n",
      "hola\n",
      "hola\n",
      "hola\n",
      "hola\n",
      "hola\n",
      "hola\n",
      "hola\n",
      "hola\n",
      "hola\n"
     ]
    }
   ],
   "source": [
    "lista = [4,8,12]\n",
    "for j in range(0,len(lista)):\n",
    "    for i in range(0,lista[j]):\n",
    "        print(\"hola\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "Mro0DvciPO8t"
   },
   "source": [
    "#### <a id=\"segundo\"></a>\n",
    "## 2. Challenge Kaggle\n",
    "\n",
    "Pendiente"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Cantidad de clases a predecir: 10\n",
      "Clases: ['altar' 'apse' 'bell_tower' 'column' 'dome_inner' 'dome_outer'\n",
      " 'flying_buttress' 'gargoyle' 'stained_glass' 'vault']\n"
     ]
    }
   ],
   "source": [
    "import numpy as np \n",
    "import pandas as pd\n",
    "from PIL import Image\n",
    "from os import listdir\n",
    "from os.path import isfile, join\n",
    "from keras.optimizers import Adam, SGD, Adagrad\n",
    "from keras.utils import to_categorical\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "dir = 'train_images'\n",
    "extension='jpg'\n",
    "\n",
    "paths = []\n",
    "for f in listdir(dir):\n",
    "    if isfile(join(dir,f)):\n",
    "        path = join(dir,f)\n",
    "        number = f.split('_')[1]\n",
    "        number = int(number.split('.')[0])\n",
    "        paths.append((number, path)) \n",
    "paths.sort(key= lambda file: file[0])\n",
    "\n",
    "imgs = []\n",
    "for _, path in paths:\n",
    "    image = Image.open(path).convert(\"RGB\")\n",
    "    image=np.asarray(image)\n",
    "    imgs.append(image)\n",
    "\n",
    "X = np.array(imgs)/255.0\n",
    "y = pd.read_csv('train_labels.csv')['Expected']\n",
    "\n",
    "\n",
    "classes = np.unique(y)\n",
    "n_classes = len(np.unique(y))\n",
    "count = 0\n",
    "labels ={}\n",
    "for l in classes:\n",
    "    labels[l] = count\n",
    "    count+=1\n",
    "y = np.array(y.replace(labels).tolist())\n",
    "y = to_categorical(y,n_classes)\n",
    "\n",
    "#Split train and test data\n",
    "# X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=10) \n",
    "X_train = X\n",
    "y_train = y\n",
    "\n",
    "print(f'Cantidad de clases a predecir: {n_classes}')\n",
    "print(f'Clases: {classes}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(9212, 128, 128, 3)"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "N, width, height, depth = X_train.shape\n",
    "N, width, height, depth"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### VGG 19"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_2\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "conv2d_16 (Conv2D)           (None, 128, 128, 64)      1792      \n",
      "_________________________________________________________________\n",
      "conv2d_17 (Conv2D)           (None, 128, 128, 64)      36928     \n",
      "_________________________________________________________________\n",
      "max_pooling2d_6 (MaxPooling2 (None, 64, 64, 64)        0         \n",
      "_________________________________________________________________\n",
      "conv2d_18 (Conv2D)           (None, 64, 64, 128)       73856     \n",
      "_________________________________________________________________\n",
      "conv2d_19 (Conv2D)           (None, 64, 64, 128)       147584    \n",
      "_________________________________________________________________\n",
      "max_pooling2d_7 (MaxPooling2 (None, 32, 32, 128)       0         \n",
      "_________________________________________________________________\n",
      "conv2d_20 (Conv2D)           (None, 32, 32, 256)       295168    \n",
      "_________________________________________________________________\n",
      "conv2d_21 (Conv2D)           (None, 32, 32, 256)       590080    \n",
      "_________________________________________________________________\n",
      "conv2d_22 (Conv2D)           (None, 32, 32, 256)       590080    \n",
      "_________________________________________________________________\n",
      "max_pooling2d_8 (MaxPooling2 (None, 16, 16, 256)       0         \n",
      "_________________________________________________________________\n",
      "conv2d_23 (Conv2D)           (None, 16, 16, 512)       1180160   \n",
      "_________________________________________________________________\n",
      "conv2d_24 (Conv2D)           (None, 16, 16, 512)       2359808   \n",
      "_________________________________________________________________\n",
      "conv2d_25 (Conv2D)           (None, 16, 16, 512)       2359808   \n",
      "_________________________________________________________________\n",
      "conv2d_26 (Conv2D)           (None, 16, 16, 512)       2359808   \n",
      "_________________________________________________________________\n",
      "max_pooling2d_9 (MaxPooling2 (None, 8, 8, 512)         0         \n",
      "_________________________________________________________________\n",
      "conv2d_27 (Conv2D)           (None, 8, 8, 512)         2359808   \n",
      "_________________________________________________________________\n",
      "conv2d_28 (Conv2D)           (None, 8, 8, 512)         2359808   \n",
      "_________________________________________________________________\n",
      "conv2d_29 (Conv2D)           (None, 8, 8, 512)         2359808   \n",
      "_________________________________________________________________\n",
      "conv2d_30 (Conv2D)           (None, 8, 8, 512)         2359808   \n",
      "_________________________________________________________________\n",
      "max_pooling2d_10 (MaxPooling (None, 4, 4, 512)         0         \n",
      "_________________________________________________________________\n",
      "flatten_2 (Flatten)          (None, 8192)              0         \n",
      "_________________________________________________________________\n",
      "dense_4 (Dense)              (None, 4096)              33558528  \n",
      "_________________________________________________________________\n",
      "dense_5 (Dense)              (None, 4096)              16781312  \n",
      "_________________________________________________________________\n",
      "dense_6 (Dense)              (None, 1000)              4097000   \n",
      "_________________________________________________________________\n",
      "dense_7 (Dense)              (None, 10)                10010     \n",
      "=================================================================\n",
      "Total params: 73,881,154\n",
      "Trainable params: 73,881,154\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "from keras.models import Sequential\n",
    "from keras.layers import Activation, Dropout, Dense\n",
    "from keras.layers import Conv2D, MaxPooling2D,AveragePooling2D, Flatten\n",
    "\n",
    "def create_cnn(classes, width, height, depth):\n",
    "      \n",
    "    model = Sequential()\n",
    "    model.add(Conv2D(64, (3, 3), padding='same', input_shape=(width, height, depth), activation='relu'))\n",
    "    model.add(Conv2D(64,(3,3), padding='same', activation='relu'))\n",
    "    model.add(MaxPooling2D(pool_size=(2, 2)))\n",
    "\n",
    "    model.add(Conv2D(128, (3, 3), padding='same', activation='relu'))\n",
    "    model.add(Conv2D(128, (3, 3), padding='same', activation='relu'))\n",
    "    model.add(MaxPooling2D(pool_size=(2, 2)))\n",
    "\n",
    "    model.add(Conv2D(256, (3, 3), padding='same', activation='relu'))\n",
    "    model.add(Conv2D(256, (3, 3), padding='same', activation='relu'))\n",
    "    model.add(Conv2D(256, (3, 3), padding='same', activation='relu'))\n",
    "    model.add(MaxPooling2D(pool_size=(2, 2)))\n",
    "    \n",
    "    model.add(Conv2D(512, (3, 3), padding='same', activation='relu'))\n",
    "    model.add(Conv2D(512, (3, 3), padding='same', activation='relu'))\n",
    "    model.add(Conv2D(512, (3, 3), padding='same', activation='relu'))\n",
    "    model.add(Conv2D(512, (3, 3), padding='same', activation='relu'))\n",
    "    model.add(MaxPooling2D(pool_size=(2, 2)))\n",
    "    \n",
    "    model.add(Conv2D(512, (3, 3), padding='same', activation='relu'))\n",
    "    model.add(Conv2D(512, (3, 3), padding='same', activation='relu'))\n",
    "    model.add(Conv2D(512, (3, 3), padding='same', activation='relu'))\n",
    "    model.add(Conv2D(512, (3, 3), padding='same', activation='relu'))\n",
    "    model.add(MaxPooling2D(pool_size=(2, 2)))\n",
    "    \n",
    "    model.add(Flatten()) \n",
    "    model.add(Dense(units=4096,activation=\"relu\"))\n",
    "    model.add(Dense(units=4096,activation=\"relu\"))\n",
    "    model.add(Dense(units=1000, activation='relu'))\n",
    "    #model.add(Dropout(0.5))\n",
    "\n",
    "    if classes == 2:\n",
    "        model.add(Dense(1))\n",
    "        model.add(Activation('sigmoid'))\n",
    "    else:\n",
    "        model.add(Dense(classes, activation='softmax'))\n",
    "    return model\n",
    "\n",
    "CNN = create_cnn(n_classes, width, height, 3)\n",
    "CNN.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/25\n",
      "3168/9212 [=========>....................] - ETA: 1:16 - loss: 2.2439 - accuracy: 0.1695"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-8-516cd8cf1d52>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[0moptimizer\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mAdam\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      2\u001b[0m \u001b[0mCNN\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mcompile\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mloss\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;34m'categorical_crossentropy'\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0moptimizer\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0moptimizer\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mmetrics\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m'accuracy'\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 3\u001b[1;33m \u001b[0mCNN\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mX_train\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0my_train\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mepochs\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m25\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mbatch_size\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m32\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mverbose\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;32mc:\\users\\castillo\\appdata\\local\\programs\\python\\python36\\lib\\site-packages\\keras\\engine\\training.py\u001b[0m in \u001b[0;36mfit\u001b[1;34m(self, x, y, batch_size, epochs, verbose, callbacks, validation_split, validation_data, shuffle, class_weight, sample_weight, initial_epoch, steps_per_epoch, validation_steps, validation_freq, max_queue_size, workers, use_multiprocessing, **kwargs)\u001b[0m\n\u001b[0;32m   1237\u001b[0m                                         \u001b[0msteps_per_epoch\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0msteps_per_epoch\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1238\u001b[0m                                         \u001b[0mvalidation_steps\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mvalidation_steps\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1239\u001b[1;33m                                         validation_freq=validation_freq)\n\u001b[0m\u001b[0;32m   1240\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1241\u001b[0m     def evaluate(self,\n",
      "\u001b[1;32mc:\\users\\castillo\\appdata\\local\\programs\\python\\python36\\lib\\site-packages\\keras\\engine\\training_arrays.py\u001b[0m in \u001b[0;36mfit_loop\u001b[1;34m(model, fit_function, fit_inputs, out_labels, batch_size, epochs, verbose, callbacks, val_function, val_inputs, shuffle, initial_epoch, steps_per_epoch, validation_steps, validation_freq)\u001b[0m\n\u001b[0;32m    194\u001b[0m                     \u001b[0mins_batch\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mi\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mins_batch\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mi\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mtoarray\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    195\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 196\u001b[1;33m                 \u001b[0mouts\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mfit_function\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mins_batch\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    197\u001b[0m                 \u001b[0mouts\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mto_list\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mouts\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    198\u001b[0m                 \u001b[1;32mfor\u001b[0m \u001b[0ml\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mo\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mzip\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mout_labels\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mouts\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\users\\castillo\\appdata\\local\\programs\\python\\python36\\lib\\site-packages\\tensorflow\\python\\keras\\backend.py\u001b[0m in \u001b[0;36m__call__\u001b[1;34m(self, inputs)\u001b[0m\n\u001b[0;32m   3798\u001b[0m     return nest.pack_sequence_as(\n\u001b[0;32m   3799\u001b[0m         \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_outputs_structure\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 3800\u001b[1;33m         \u001b[1;33m[\u001b[0m\u001b[0mx\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_numpy\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;32mfor\u001b[0m \u001b[0mx\u001b[0m \u001b[1;32min\u001b[0m \u001b[0moutputs\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m,\u001b[0m  \u001b[1;31m# pylint: disable=protected-access\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   3801\u001b[0m         expand_composites=True)\n\u001b[0;32m   3802\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\users\\castillo\\appdata\\local\\programs\\python\\python36\\lib\\site-packages\\tensorflow\\python\\keras\\backend.py\u001b[0m in \u001b[0;36m<listcomp>\u001b[1;34m(.0)\u001b[0m\n\u001b[0;32m   3798\u001b[0m     return nest.pack_sequence_as(\n\u001b[0;32m   3799\u001b[0m         \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_outputs_structure\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 3800\u001b[1;33m         \u001b[1;33m[\u001b[0m\u001b[0mx\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_numpy\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;32mfor\u001b[0m \u001b[0mx\u001b[0m \u001b[1;32min\u001b[0m \u001b[0moutputs\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m,\u001b[0m  \u001b[1;31m# pylint: disable=protected-access\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   3801\u001b[0m         expand_composites=True)\n\u001b[0;32m   3802\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\users\\castillo\\appdata\\local\\programs\\python\\python36\\lib\\site-packages\\tensorflow\\python\\framework\\ops.py\u001b[0m in \u001b[0;36m_numpy\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m    925\u001b[0m     \u001b[1;31m# pylint: disable=protected-access\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    926\u001b[0m     \u001b[1;32mtry\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 927\u001b[1;33m       \u001b[1;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_numpy_internal\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    928\u001b[0m     \u001b[1;32mexcept\u001b[0m \u001b[0mcore\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_NotOkStatusException\u001b[0m \u001b[1;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    929\u001b[0m       \u001b[0msix\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mraise_from\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mcore\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_status_to_exception\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0me\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mcode\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0me\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mmessage\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "optimizer = Adam()\n",
    "CNN.compile(loss='categorical_crossentropy', optimizer=optimizer, metrics=['accuracy'])\n",
    "CNN.fit(X_train,y_train, epochs=25, batch_size=32, verbose=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1843/1843 [==============================] - 1s 678us/step\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[2.173364925306903, 0.647314190864563]"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "CNN.evaluate(X_test, y_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Resnet 50"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import keras\n",
    "from keras.layers import Dense, Conv2D, BatchNormalization, Activation\n",
    "from keras.layers import AveragePooling2D, Input, Flatten\n",
    "from keras.optimizers import Adam\n",
    "from keras.callbacks import ModelCheckpoint, LearningRateScheduler\n",
    "from keras.callbacks import ReduceLROnPlateau\n",
    "from keras.preprocessing.image import ImageDataGenerator\n",
    "from keras.regularizers import l2\n",
    "from keras import backend as K\n",
    "from keras.models import Model\n",
    "from keras.datasets import cifar10\n",
    "import numpy as np\n",
    "import os\n",
    "\n",
    "def lr_schedule(epoch):\n",
    "    \"\"\"Learning Rate Schedule\n",
    "\n",
    "    Learning rate is scheduled to be reduced after 80, 120, 160, 180 epochs.\n",
    "    Called automatically every epoch as part of callbacks during training.\n",
    "\n",
    "    # Arguments\n",
    "        epoch (int): The number of epochs\n",
    "\n",
    "    # Returns\n",
    "        lr (float32): learning rate\n",
    "    \"\"\"\n",
    "    lr = 1e-3\n",
    "    if epoch > 180:\n",
    "        lr *= 0.5e-3\n",
    "    elif epoch > 160:\n",
    "        lr *= 1e-3\n",
    "    elif epoch > 120:\n",
    "        lr *= 1e-2\n",
    "    elif epoch > 80:\n",
    "        lr *= 1e-1\n",
    "    print('Learning rate: ', lr)\n",
    "    return lr\n",
    "\n",
    "def resnet_layer(inputs,\n",
    "                 num_filters=16,\n",
    "                 kernel_size=3,\n",
    "                 strides=1,\n",
    "                 activation='relu',\n",
    "                 batch_normalization=True,\n",
    "                 conv_first=True\n",
    "                ):\n",
    "    \n",
    "    conv = Conv2D(num_filters,\n",
    "                  kernel_size=kernel_size,\n",
    "                  strides=strides,\n",
    "                  padding='same',\n",
    "                  kernel_initializer='he_normal',\n",
    "                  kernel_regularizer=l2(1e-4))\n",
    "\n",
    "    x = inputs\n",
    "    if conv_first:\n",
    "        x = conv(x)\n",
    "        if batch_normalization:\n",
    "            x = BatchNormalization()(x)\n",
    "        if activation is not None:\n",
    "            x = Activation(activation)(x)\n",
    "    else:\n",
    "        if batch_normalization:\n",
    "            x = BatchNormalization()(x)\n",
    "        if activation is not None:\n",
    "            x = Activation(activation)(x)\n",
    "        x = conv(x)\n",
    "    return x\n",
    "        \n",
    "def resnet(input_shape, depth, num_classes):\n",
    "    \"\"\"ResNet Version 2 Model builder [b]\n",
    "\n",
    "    Stacks of (1 x 1)-(3 x 3)-(1 x 1) BN-ReLU-Conv2D or also known as\n",
    "    bottleneck layer\n",
    "    First shortcut connection per layer is 1 x 1 Conv2D.\n",
    "    Second and onwards shortcut connection is identity.\n",
    "    At the beginning of each stage, the feature map size is halved (downsampled)\n",
    "    by a convolutional layer with strides=2, while the number of filter maps is\n",
    "    doubled. Within each stage, the layers have the same number filters and the\n",
    "    same filter map sizes.\n",
    "    Features maps sizes:\n",
    "    conv1  : 32x32,  16\n",
    "    stage 0: 32x32,  64\n",
    "    stage 1: 16x16, 128\n",
    "    stage 2:  8x8,  256\n",
    "\n",
    "    # Arguments\n",
    "        input_shape (tensor): shape of input image tensor\n",
    "        depth (int): number of core convolutional layers\n",
    "        num_classes (int): number of classes (CIFAR10 has 10)\n",
    "\n",
    "    # Returns\n",
    "        model (Model): Keras model instance\n",
    "    \"\"\"\n",
    "    if (depth - 2) % 9 != 0:\n",
    "        raise ValueError('depth should be 9n+2 (eg 56 or 110 in [b])')\n",
    "    # Start model definition.\n",
    "    num_filters_in = 16\n",
    "    num_res_blocks = int((depth - 2) / 9)\n",
    "\n",
    "    inputs = Input(shape=input_shape)\n",
    "    # v2 performs Conv2D with BN-ReLU on input before splitting into 2 paths\n",
    "    x = resnet_layer(inputs=inputs,\n",
    "                     num_filters=num_filters_in,\n",
    "                     conv_first=True)\n",
    "\n",
    "    # Instantiate the stack of residual units\n",
    "    for stage in range(3):\n",
    "        for res_block in range(num_res_blocks):\n",
    "            activation = 'relu'\n",
    "            batch_normalization = True\n",
    "            strides = 1\n",
    "            if stage == 0:\n",
    "                num_filters_out = num_filters_in * 4\n",
    "                if res_block == 0:  # first layer and first stage\n",
    "                    activation = None\n",
    "                    batch_normalization = False\n",
    "            else:\n",
    "                num_filters_out = num_filters_in * 2\n",
    "                if res_block == 0:  # first layer but not first stage\n",
    "                    strides = 2    # downsample\n",
    "\n",
    "            # bottleneck residual unit\n",
    "            y = resnet_layer(inputs=x,\n",
    "                             num_filters=num_filters_in,\n",
    "                             kernel_size=1,\n",
    "                             strides=strides,\n",
    "                             activation=activation,\n",
    "                             batch_normalization=batch_normalization,\n",
    "                             conv_first=False)\n",
    "            y = resnet_layer(inputs=y,\n",
    "                             num_filters=num_filters_in,\n",
    "                             conv_first=False)\n",
    "            y = resnet_layer(inputs=y,\n",
    "                             num_filters=num_filters_out,\n",
    "                             kernel_size=1,\n",
    "                             conv_first=False)\n",
    "            if res_block == 0:\n",
    "                # linear projection residual shortcut connection to match\n",
    "                # changed dims\n",
    "                x = resnet_layer(inputs=x,\n",
    "                                 num_filters=num_filters_out,\n",
    "                                 kernel_size=1,\n",
    "                                 strides=strides,\n",
    "                                 activation=None,\n",
    "                                 batch_normalization=False)\n",
    "            x = keras.layers.add([x, y])\n",
    "\n",
    "        num_filters_in = num_filters_out\n",
    "\n",
    "    # Add classifier on top.\n",
    "    # v2 has BN-ReLU before Pooling\n",
    "    x = BatchNormalization()(x)\n",
    "    x = Activation('relu')(x)\n",
    "    x = AveragePooling2D(pool_size=8)(x)\n",
    "    y = Flatten()(x)\n",
    "    outputs = Dense(num_classes,\n",
    "                    activation='softmax',\n",
    "                    kernel_initializer='he_normal')(y)\n",
    "\n",
    "    # Instantiate model.\n",
    "    model = Model(inputs=inputs, outputs=outputs)\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "os.environ[\"CUDA_VISIBLE_DEVICES\"] = \"1\"\n",
    "try:\n",
    "  %tensorflow_version 2.x\n",
    "except Exception:\n",
    "  pass\n",
    "import tensorflow as tf\n",
    "tf.keras.backend.clear_session()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"model_1\"\n",
      "__________________________________________________________________________________________________\n",
      "Layer (type)                    Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      "input_1 (InputLayer)            (None, 128, 128, 3)  0                                            \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_1 (Conv2D)               (None, 128, 128, 16) 448         input_1[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_1 (BatchNor (None, 128, 128, 16) 64          conv2d_1[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "activation_1 (Activation)       (None, 128, 128, 16) 0           batch_normalization_1[0][0]      \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_2 (Conv2D)               (None, 128, 128, 16) 272         activation_1[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_2 (BatchNor (None, 128, 128, 16) 64          conv2d_2[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "activation_2 (Activation)       (None, 128, 128, 16) 0           batch_normalization_2[0][0]      \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_3 (Conv2D)               (None, 128, 128, 16) 2320        activation_2[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_3 (BatchNor (None, 128, 128, 16) 64          conv2d_3[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "activation_3 (Activation)       (None, 128, 128, 16) 0           batch_normalization_3[0][0]      \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_5 (Conv2D)               (None, 128, 128, 64) 1088        activation_1[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_4 (Conv2D)               (None, 128, 128, 64) 1088        activation_3[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "add_1 (Add)                     (None, 128, 128, 64) 0           conv2d_5[0][0]                   \n",
      "                                                                 conv2d_4[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_4 (BatchNor (None, 128, 128, 64) 256         add_1[0][0]                      \n",
      "__________________________________________________________________________________________________\n",
      "activation_4 (Activation)       (None, 128, 128, 64) 0           batch_normalization_4[0][0]      \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_6 (Conv2D)               (None, 128, 128, 16) 1040        activation_4[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_5 (BatchNor (None, 128, 128, 16) 64          conv2d_6[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "activation_5 (Activation)       (None, 128, 128, 16) 0           batch_normalization_5[0][0]      \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_7 (Conv2D)               (None, 128, 128, 16) 2320        activation_5[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_6 (BatchNor (None, 128, 128, 16) 64          conv2d_7[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "activation_6 (Activation)       (None, 128, 128, 16) 0           batch_normalization_6[0][0]      \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_8 (Conv2D)               (None, 128, 128, 64) 1088        activation_6[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "add_2 (Add)                     (None, 128, 128, 64) 0           add_1[0][0]                      \n",
      "                                                                 conv2d_8[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_7 (BatchNor (None, 128, 128, 64) 256         add_2[0][0]                      \n",
      "__________________________________________________________________________________________________\n",
      "activation_7 (Activation)       (None, 128, 128, 64) 0           batch_normalization_7[0][0]      \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_9 (Conv2D)               (None, 128, 128, 16) 1040        activation_7[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_8 (BatchNor (None, 128, 128, 16) 64          conv2d_9[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "activation_8 (Activation)       (None, 128, 128, 16) 0           batch_normalization_8[0][0]      \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_10 (Conv2D)              (None, 128, 128, 16) 2320        activation_8[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_9 (BatchNor (None, 128, 128, 16) 64          conv2d_10[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "activation_9 (Activation)       (None, 128, 128, 16) 0           batch_normalization_9[0][0]      \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_11 (Conv2D)              (None, 128, 128, 64) 1088        activation_9[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "add_3 (Add)                     (None, 128, 128, 64) 0           add_2[0][0]                      \n",
      "                                                                 conv2d_11[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_10 (BatchNo (None, 128, 128, 64) 256         add_3[0][0]                      \n",
      "__________________________________________________________________________________________________\n",
      "activation_10 (Activation)      (None, 128, 128, 64) 0           batch_normalization_10[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_12 (Conv2D)              (None, 128, 128, 16) 1040        activation_10[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_11 (BatchNo (None, 128, 128, 16) 64          conv2d_12[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "activation_11 (Activation)      (None, 128, 128, 16) 0           batch_normalization_11[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_13 (Conv2D)              (None, 128, 128, 16) 2320        activation_11[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_12 (BatchNo (None, 128, 128, 16) 64          conv2d_13[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "activation_12 (Activation)      (None, 128, 128, 16) 0           batch_normalization_12[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_14 (Conv2D)              (None, 128, 128, 64) 1088        activation_12[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "add_4 (Add)                     (None, 128, 128, 64) 0           add_3[0][0]                      \n",
      "                                                                 conv2d_14[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_13 (BatchNo (None, 128, 128, 64) 256         add_4[0][0]                      \n",
      "__________________________________________________________________________________________________\n",
      "activation_13 (Activation)      (None, 128, 128, 64) 0           batch_normalization_13[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_15 (Conv2D)              (None, 128, 128, 16) 1040        activation_13[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_14 (BatchNo (None, 128, 128, 16) 64          conv2d_15[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "activation_14 (Activation)      (None, 128, 128, 16) 0           batch_normalization_14[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_16 (Conv2D)              (None, 128, 128, 16) 2320        activation_14[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_15 (BatchNo (None, 128, 128, 16) 64          conv2d_16[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "activation_15 (Activation)      (None, 128, 128, 16) 0           batch_normalization_15[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_17 (Conv2D)              (None, 128, 128, 64) 1088        activation_15[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "add_5 (Add)                     (None, 128, 128, 64) 0           add_4[0][0]                      \n",
      "                                                                 conv2d_17[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_16 (BatchNo (None, 128, 128, 64) 256         add_5[0][0]                      \n",
      "__________________________________________________________________________________________________\n",
      "activation_16 (Activation)      (None, 128, 128, 64) 0           batch_normalization_16[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_18 (Conv2D)              (None, 128, 128, 16) 1040        activation_16[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_17 (BatchNo (None, 128, 128, 16) 64          conv2d_18[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "activation_17 (Activation)      (None, 128, 128, 16) 0           batch_normalization_17[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_19 (Conv2D)              (None, 128, 128, 16) 2320        activation_17[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_18 (BatchNo (None, 128, 128, 16) 64          conv2d_19[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "activation_18 (Activation)      (None, 128, 128, 16) 0           batch_normalization_18[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_20 (Conv2D)              (None, 128, 128, 64) 1088        activation_18[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "add_6 (Add)                     (None, 128, 128, 64) 0           add_5[0][0]                      \n",
      "                                                                 conv2d_20[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_19 (BatchNo (None, 128, 128, 64) 256         add_6[0][0]                      \n",
      "__________________________________________________________________________________________________\n",
      "activation_19 (Activation)      (None, 128, 128, 64) 0           batch_normalization_19[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_21 (Conv2D)              (None, 128, 128, 16) 1040        activation_19[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_20 (BatchNo (None, 128, 128, 16) 64          conv2d_21[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "activation_20 (Activation)      (None, 128, 128, 16) 0           batch_normalization_20[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_22 (Conv2D)              (None, 128, 128, 16) 2320        activation_20[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_21 (BatchNo (None, 128, 128, 16) 64          conv2d_22[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "activation_21 (Activation)      (None, 128, 128, 16) 0           batch_normalization_21[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_23 (Conv2D)              (None, 128, 128, 64) 1088        activation_21[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "add_7 (Add)                     (None, 128, 128, 64) 0           add_6[0][0]                      \n",
      "                                                                 conv2d_23[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_22 (BatchNo (None, 128, 128, 64) 256         add_7[0][0]                      \n",
      "__________________________________________________________________________________________________\n",
      "activation_22 (Activation)      (None, 128, 128, 64) 0           batch_normalization_22[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_24 (Conv2D)              (None, 128, 128, 16) 1040        activation_22[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_23 (BatchNo (None, 128, 128, 16) 64          conv2d_24[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "activation_23 (Activation)      (None, 128, 128, 16) 0           batch_normalization_23[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_25 (Conv2D)              (None, 128, 128, 16) 2320        activation_23[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_24 (BatchNo (None, 128, 128, 16) 64          conv2d_25[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "activation_24 (Activation)      (None, 128, 128, 16) 0           batch_normalization_24[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_26 (Conv2D)              (None, 128, 128, 64) 1088        activation_24[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "add_8 (Add)                     (None, 128, 128, 64) 0           add_7[0][0]                      \n",
      "                                                                 conv2d_26[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_25 (BatchNo (None, 128, 128, 64) 256         add_8[0][0]                      \n",
      "__________________________________________________________________________________________________\n",
      "activation_25 (Activation)      (None, 128, 128, 64) 0           batch_normalization_25[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_27 (Conv2D)              (None, 128, 128, 16) 1040        activation_25[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_26 (BatchNo (None, 128, 128, 16) 64          conv2d_27[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "activation_26 (Activation)      (None, 128, 128, 16) 0           batch_normalization_26[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_28 (Conv2D)              (None, 128, 128, 16) 2320        activation_26[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_27 (BatchNo (None, 128, 128, 16) 64          conv2d_28[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "activation_27 (Activation)      (None, 128, 128, 16) 0           batch_normalization_27[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_29 (Conv2D)              (None, 128, 128, 64) 1088        activation_27[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "add_9 (Add)                     (None, 128, 128, 64) 0           add_8[0][0]                      \n",
      "                                                                 conv2d_29[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_28 (BatchNo (None, 128, 128, 64) 256         add_9[0][0]                      \n",
      "__________________________________________________________________________________________________\n",
      "activation_28 (Activation)      (None, 128, 128, 64) 0           batch_normalization_28[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_30 (Conv2D)              (None, 128, 128, 16) 1040        activation_28[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_29 (BatchNo (None, 128, 128, 16) 64          conv2d_30[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "activation_29 (Activation)      (None, 128, 128, 16) 0           batch_normalization_29[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_31 (Conv2D)              (None, 128, 128, 16) 2320        activation_29[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_30 (BatchNo (None, 128, 128, 16) 64          conv2d_31[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "activation_30 (Activation)      (None, 128, 128, 16) 0           batch_normalization_30[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_32 (Conv2D)              (None, 128, 128, 64) 1088        activation_30[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "add_10 (Add)                    (None, 128, 128, 64) 0           add_9[0][0]                      \n",
      "                                                                 conv2d_32[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_31 (BatchNo (None, 128, 128, 64) 256         add_10[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "activation_31 (Activation)      (None, 128, 128, 64) 0           batch_normalization_31[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_33 (Conv2D)              (None, 128, 128, 16) 1040        activation_31[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_32 (BatchNo (None, 128, 128, 16) 64          conv2d_33[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "activation_32 (Activation)      (None, 128, 128, 16) 0           batch_normalization_32[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_34 (Conv2D)              (None, 128, 128, 16) 2320        activation_32[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_33 (BatchNo (None, 128, 128, 16) 64          conv2d_34[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "activation_33 (Activation)      (None, 128, 128, 16) 0           batch_normalization_33[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_35 (Conv2D)              (None, 128, 128, 64) 1088        activation_33[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "add_11 (Add)                    (None, 128, 128, 64) 0           add_10[0][0]                     \n",
      "                                                                 conv2d_35[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_34 (BatchNo (None, 128, 128, 64) 256         add_11[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "activation_34 (Activation)      (None, 128, 128, 64) 0           batch_normalization_34[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_36 (Conv2D)              (None, 128, 128, 16) 1040        activation_34[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_35 (BatchNo (None, 128, 128, 16) 64          conv2d_36[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "activation_35 (Activation)      (None, 128, 128, 16) 0           batch_normalization_35[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_37 (Conv2D)              (None, 128, 128, 16) 2320        activation_35[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_36 (BatchNo (None, 128, 128, 16) 64          conv2d_37[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "activation_36 (Activation)      (None, 128, 128, 16) 0           batch_normalization_36[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_38 (Conv2D)              (None, 128, 128, 64) 1088        activation_36[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "add_12 (Add)                    (None, 128, 128, 64) 0           add_11[0][0]                     \n",
      "                                                                 conv2d_38[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_37 (BatchNo (None, 128, 128, 64) 256         add_12[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "activation_37 (Activation)      (None, 128, 128, 64) 0           batch_normalization_37[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_39 (Conv2D)              (None, 128, 128, 16) 1040        activation_37[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_38 (BatchNo (None, 128, 128, 16) 64          conv2d_39[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "activation_38 (Activation)      (None, 128, 128, 16) 0           batch_normalization_38[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_40 (Conv2D)              (None, 128, 128, 16) 2320        activation_38[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_39 (BatchNo (None, 128, 128, 16) 64          conv2d_40[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "activation_39 (Activation)      (None, 128, 128, 16) 0           batch_normalization_39[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_41 (Conv2D)              (None, 128, 128, 64) 1088        activation_39[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "add_13 (Add)                    (None, 128, 128, 64) 0           add_12[0][0]                     \n",
      "                                                                 conv2d_41[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_40 (BatchNo (None, 128, 128, 64) 256         add_13[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "activation_40 (Activation)      (None, 128, 128, 64) 0           batch_normalization_40[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_42 (Conv2D)              (None, 128, 128, 16) 1040        activation_40[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_41 (BatchNo (None, 128, 128, 16) 64          conv2d_42[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "activation_41 (Activation)      (None, 128, 128, 16) 0           batch_normalization_41[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_43 (Conv2D)              (None, 128, 128, 16) 2320        activation_41[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_42 (BatchNo (None, 128, 128, 16) 64          conv2d_43[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "activation_42 (Activation)      (None, 128, 128, 16) 0           batch_normalization_42[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_44 (Conv2D)              (None, 128, 128, 64) 1088        activation_42[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "add_14 (Add)                    (None, 128, 128, 64) 0           add_13[0][0]                     \n",
      "                                                                 conv2d_44[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_43 (BatchNo (None, 128, 128, 64) 256         add_14[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "activation_43 (Activation)      (None, 128, 128, 64) 0           batch_normalization_43[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_45 (Conv2D)              (None, 128, 128, 16) 1040        activation_43[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_44 (BatchNo (None, 128, 128, 16) 64          conv2d_45[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "activation_44 (Activation)      (None, 128, 128, 16) 0           batch_normalization_44[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_46 (Conv2D)              (None, 128, 128, 16) 2320        activation_44[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_45 (BatchNo (None, 128, 128, 16) 64          conv2d_46[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "activation_45 (Activation)      (None, 128, 128, 16) 0           batch_normalization_45[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_47 (Conv2D)              (None, 128, 128, 64) 1088        activation_45[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "add_15 (Add)                    (None, 128, 128, 64) 0           add_14[0][0]                     \n",
      "                                                                 conv2d_47[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_46 (BatchNo (None, 128, 128, 64) 256         add_15[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "activation_46 (Activation)      (None, 128, 128, 64) 0           batch_normalization_46[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_48 (Conv2D)              (None, 128, 128, 16) 1040        activation_46[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_47 (BatchNo (None, 128, 128, 16) 64          conv2d_48[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "activation_47 (Activation)      (None, 128, 128, 16) 0           batch_normalization_47[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_49 (Conv2D)              (None, 128, 128, 16) 2320        activation_47[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_48 (BatchNo (None, 128, 128, 16) 64          conv2d_49[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "activation_48 (Activation)      (None, 128, 128, 16) 0           batch_normalization_48[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_50 (Conv2D)              (None, 128, 128, 64) 1088        activation_48[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "add_16 (Add)                    (None, 128, 128, 64) 0           add_15[0][0]                     \n",
      "                                                                 conv2d_50[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_49 (BatchNo (None, 128, 128, 64) 256         add_16[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "activation_49 (Activation)      (None, 128, 128, 64) 0           batch_normalization_49[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_51 (Conv2D)              (None, 128, 128, 16) 1040        activation_49[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_50 (BatchNo (None, 128, 128, 16) 64          conv2d_51[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "activation_50 (Activation)      (None, 128, 128, 16) 0           batch_normalization_50[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_52 (Conv2D)              (None, 128, 128, 16) 2320        activation_50[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_51 (BatchNo (None, 128, 128, 16) 64          conv2d_52[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "activation_51 (Activation)      (None, 128, 128, 16) 0           batch_normalization_51[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_53 (Conv2D)              (None, 128, 128, 64) 1088        activation_51[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "add_17 (Add)                    (None, 128, 128, 64) 0           add_16[0][0]                     \n",
      "                                                                 conv2d_53[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_52 (BatchNo (None, 128, 128, 64) 256         add_17[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "activation_52 (Activation)      (None, 128, 128, 64) 0           batch_normalization_52[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_54 (Conv2D)              (None, 128, 128, 16) 1040        activation_52[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_53 (BatchNo (None, 128, 128, 16) 64          conv2d_54[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "activation_53 (Activation)      (None, 128, 128, 16) 0           batch_normalization_53[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_55 (Conv2D)              (None, 128, 128, 16) 2320        activation_53[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_54 (BatchNo (None, 128, 128, 16) 64          conv2d_55[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "activation_54 (Activation)      (None, 128, 128, 16) 0           batch_normalization_54[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_56 (Conv2D)              (None, 128, 128, 64) 1088        activation_54[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "add_18 (Add)                    (None, 128, 128, 64) 0           add_17[0][0]                     \n",
      "                                                                 conv2d_56[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_55 (BatchNo (None, 128, 128, 64) 256         add_18[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "activation_55 (Activation)      (None, 128, 128, 64) 0           batch_normalization_55[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_57 (Conv2D)              (None, 128, 128, 16) 1040        activation_55[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_56 (BatchNo (None, 128, 128, 16) 64          conv2d_57[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "activation_56 (Activation)      (None, 128, 128, 16) 0           batch_normalization_56[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_58 (Conv2D)              (None, 128, 128, 16) 2320        activation_56[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_57 (BatchNo (None, 128, 128, 16) 64          conv2d_58[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "activation_57 (Activation)      (None, 128, 128, 16) 0           batch_normalization_57[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_59 (Conv2D)              (None, 128, 128, 64) 1088        activation_57[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "add_19 (Add)                    (None, 128, 128, 64) 0           add_18[0][0]                     \n",
      "                                                                 conv2d_59[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_58 (BatchNo (None, 128, 128, 64) 256         add_19[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "activation_58 (Activation)      (None, 128, 128, 64) 0           batch_normalization_58[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_60 (Conv2D)              (None, 128, 128, 16) 1040        activation_58[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_59 (BatchNo (None, 128, 128, 16) 64          conv2d_60[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "activation_59 (Activation)      (None, 128, 128, 16) 0           batch_normalization_59[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_61 (Conv2D)              (None, 128, 128, 16) 2320        activation_59[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_60 (BatchNo (None, 128, 128, 16) 64          conv2d_61[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "activation_60 (Activation)      (None, 128, 128, 16) 0           batch_normalization_60[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_62 (Conv2D)              (None, 128, 128, 64) 1088        activation_60[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "add_20 (Add)                    (None, 128, 128, 64) 0           add_19[0][0]                     \n",
      "                                                                 conv2d_62[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_61 (BatchNo (None, 128, 128, 64) 256         add_20[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "activation_61 (Activation)      (None, 128, 128, 64) 0           batch_normalization_61[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_63 (Conv2D)              (None, 128, 128, 16) 1040        activation_61[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_62 (BatchNo (None, 128, 128, 16) 64          conv2d_63[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "activation_62 (Activation)      (None, 128, 128, 16) 0           batch_normalization_62[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_64 (Conv2D)              (None, 128, 128, 16) 2320        activation_62[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_63 (BatchNo (None, 128, 128, 16) 64          conv2d_64[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "activation_63 (Activation)      (None, 128, 128, 16) 0           batch_normalization_63[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_65 (Conv2D)              (None, 128, 128, 64) 1088        activation_63[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "add_21 (Add)                    (None, 128, 128, 64) 0           add_20[0][0]                     \n",
      "                                                                 conv2d_65[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_64 (BatchNo (None, 128, 128, 64) 256         add_21[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "activation_64 (Activation)      (None, 128, 128, 64) 0           batch_normalization_64[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_66 (Conv2D)              (None, 128, 128, 16) 1040        activation_64[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_65 (BatchNo (None, 128, 128, 16) 64          conv2d_66[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "activation_65 (Activation)      (None, 128, 128, 16) 0           batch_normalization_65[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_67 (Conv2D)              (None, 128, 128, 16) 2320        activation_65[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_66 (BatchNo (None, 128, 128, 16) 64          conv2d_67[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "activation_66 (Activation)      (None, 128, 128, 16) 0           batch_normalization_66[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_68 (Conv2D)              (None, 128, 128, 64) 1088        activation_66[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "add_22 (Add)                    (None, 128, 128, 64) 0           add_21[0][0]                     \n",
      "                                                                 conv2d_68[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_67 (BatchNo (None, 128, 128, 64) 256         add_22[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "activation_67 (Activation)      (None, 128, 128, 64) 0           batch_normalization_67[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_69 (Conv2D)              (None, 128, 128, 16) 1040        activation_67[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_68 (BatchNo (None, 128, 128, 16) 64          conv2d_69[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "activation_68 (Activation)      (None, 128, 128, 16) 0           batch_normalization_68[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_70 (Conv2D)              (None, 128, 128, 16) 2320        activation_68[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_69 (BatchNo (None, 128, 128, 16) 64          conv2d_70[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "activation_69 (Activation)      (None, 128, 128, 16) 0           batch_normalization_69[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_71 (Conv2D)              (None, 128, 128, 64) 1088        activation_69[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "add_23 (Add)                    (None, 128, 128, 64) 0           add_22[0][0]                     \n",
      "                                                                 conv2d_71[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_70 (BatchNo (None, 128, 128, 64) 256         add_23[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "activation_70 (Activation)      (None, 128, 128, 64) 0           batch_normalization_70[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_72 (Conv2D)              (None, 128, 128, 16) 1040        activation_70[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_71 (BatchNo (None, 128, 128, 16) 64          conv2d_72[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "activation_71 (Activation)      (None, 128, 128, 16) 0           batch_normalization_71[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_73 (Conv2D)              (None, 128, 128, 16) 2320        activation_71[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_72 (BatchNo (None, 128, 128, 16) 64          conv2d_73[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "activation_72 (Activation)      (None, 128, 128, 16) 0           batch_normalization_72[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_74 (Conv2D)              (None, 128, 128, 64) 1088        activation_72[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "add_24 (Add)                    (None, 128, 128, 64) 0           add_23[0][0]                     \n",
      "                                                                 conv2d_74[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_73 (BatchNo (None, 128, 128, 64) 256         add_24[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "activation_73 (Activation)      (None, 128, 128, 64) 0           batch_normalization_73[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_75 (Conv2D)              (None, 128, 128, 16) 1040        activation_73[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_74 (BatchNo (None, 128, 128, 16) 64          conv2d_75[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "activation_74 (Activation)      (None, 128, 128, 16) 0           batch_normalization_74[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_76 (Conv2D)              (None, 128, 128, 16) 2320        activation_74[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_75 (BatchNo (None, 128, 128, 16) 64          conv2d_76[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "activation_75 (Activation)      (None, 128, 128, 16) 0           batch_normalization_75[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_77 (Conv2D)              (None, 128, 128, 64) 1088        activation_75[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "add_25 (Add)                    (None, 128, 128, 64) 0           add_24[0][0]                     \n",
      "                                                                 conv2d_77[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_76 (BatchNo (None, 128, 128, 64) 256         add_25[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "activation_76 (Activation)      (None, 128, 128, 64) 0           batch_normalization_76[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_78 (Conv2D)              (None, 128, 128, 16) 1040        activation_76[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_77 (BatchNo (None, 128, 128, 16) 64          conv2d_78[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "activation_77 (Activation)      (None, 128, 128, 16) 0           batch_normalization_77[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_79 (Conv2D)              (None, 128, 128, 16) 2320        activation_77[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_78 (BatchNo (None, 128, 128, 16) 64          conv2d_79[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "activation_78 (Activation)      (None, 128, 128, 16) 0           batch_normalization_78[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_80 (Conv2D)              (None, 128, 128, 64) 1088        activation_78[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "add_26 (Add)                    (None, 128, 128, 64) 0           add_25[0][0]                     \n",
      "                                                                 conv2d_80[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_79 (BatchNo (None, 128, 128, 64) 256         add_26[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "activation_79 (Activation)      (None, 128, 128, 64) 0           batch_normalization_79[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_81 (Conv2D)              (None, 128, 128, 16) 1040        activation_79[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_80 (BatchNo (None, 128, 128, 16) 64          conv2d_81[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "activation_80 (Activation)      (None, 128, 128, 16) 0           batch_normalization_80[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_82 (Conv2D)              (None, 128, 128, 16) 2320        activation_80[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_81 (BatchNo (None, 128, 128, 16) 64          conv2d_82[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "activation_81 (Activation)      (None, 128, 128, 16) 0           batch_normalization_81[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_83 (Conv2D)              (None, 128, 128, 64) 1088        activation_81[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "add_27 (Add)                    (None, 128, 128, 64) 0           add_26[0][0]                     \n",
      "                                                                 conv2d_83[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_82 (BatchNo (None, 128, 128, 64) 256         add_27[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "activation_82 (Activation)      (None, 128, 128, 64) 0           batch_normalization_82[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_84 (Conv2D)              (None, 128, 128, 16) 1040        activation_82[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_83 (BatchNo (None, 128, 128, 16) 64          conv2d_84[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "activation_83 (Activation)      (None, 128, 128, 16) 0           batch_normalization_83[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_85 (Conv2D)              (None, 128, 128, 16) 2320        activation_83[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_84 (BatchNo (None, 128, 128, 16) 64          conv2d_85[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "activation_84 (Activation)      (None, 128, 128, 16) 0           batch_normalization_84[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_86 (Conv2D)              (None, 128, 128, 64) 1088        activation_84[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "add_28 (Add)                    (None, 128, 128, 64) 0           add_27[0][0]                     \n",
      "                                                                 conv2d_86[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_85 (BatchNo (None, 128, 128, 64) 256         add_28[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "activation_85 (Activation)      (None, 128, 128, 64) 0           batch_normalization_85[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_87 (Conv2D)              (None, 128, 128, 16) 1040        activation_85[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_86 (BatchNo (None, 128, 128, 16) 64          conv2d_87[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "activation_86 (Activation)      (None, 128, 128, 16) 0           batch_normalization_86[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_88 (Conv2D)              (None, 128, 128, 16) 2320        activation_86[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_87 (BatchNo (None, 128, 128, 16) 64          conv2d_88[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "activation_87 (Activation)      (None, 128, 128, 16) 0           batch_normalization_87[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_89 (Conv2D)              (None, 128, 128, 64) 1088        activation_87[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "add_29 (Add)                    (None, 128, 128, 64) 0           add_28[0][0]                     \n",
      "                                                                 conv2d_89[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_88 (BatchNo (None, 128, 128, 64) 256         add_29[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "activation_88 (Activation)      (None, 128, 128, 64) 0           batch_normalization_88[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_90 (Conv2D)              (None, 64, 64, 64)   4160        activation_88[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_89 (BatchNo (None, 64, 64, 64)   256         conv2d_90[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "activation_89 (Activation)      (None, 64, 64, 64)   0           batch_normalization_89[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_91 (Conv2D)              (None, 64, 64, 64)   36928       activation_89[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_90 (BatchNo (None, 64, 64, 64)   256         conv2d_91[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "activation_90 (Activation)      (None, 64, 64, 64)   0           batch_normalization_90[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_93 (Conv2D)              (None, 64, 64, 128)  8320        add_29[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_92 (Conv2D)              (None, 64, 64, 128)  8320        activation_90[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "add_30 (Add)                    (None, 64, 64, 128)  0           conv2d_93[0][0]                  \n",
      "                                                                 conv2d_92[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_91 (BatchNo (None, 64, 64, 128)  512         add_30[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "activation_91 (Activation)      (None, 64, 64, 128)  0           batch_normalization_91[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_94 (Conv2D)              (None, 64, 64, 64)   8256        activation_91[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_92 (BatchNo (None, 64, 64, 64)   256         conv2d_94[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "activation_92 (Activation)      (None, 64, 64, 64)   0           batch_normalization_92[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_95 (Conv2D)              (None, 64, 64, 64)   36928       activation_92[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_93 (BatchNo (None, 64, 64, 64)   256         conv2d_95[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "activation_93 (Activation)      (None, 64, 64, 64)   0           batch_normalization_93[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_96 (Conv2D)              (None, 64, 64, 128)  8320        activation_93[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "add_31 (Add)                    (None, 64, 64, 128)  0           add_30[0][0]                     \n",
      "                                                                 conv2d_96[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_94 (BatchNo (None, 64, 64, 128)  512         add_31[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "activation_94 (Activation)      (None, 64, 64, 128)  0           batch_normalization_94[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_97 (Conv2D)              (None, 64, 64, 64)   8256        activation_94[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_95 (BatchNo (None, 64, 64, 64)   256         conv2d_97[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "activation_95 (Activation)      (None, 64, 64, 64)   0           batch_normalization_95[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_98 (Conv2D)              (None, 64, 64, 64)   36928       activation_95[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_96 (BatchNo (None, 64, 64, 64)   256         conv2d_98[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "activation_96 (Activation)      (None, 64, 64, 64)   0           batch_normalization_96[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_99 (Conv2D)              (None, 64, 64, 128)  8320        activation_96[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "add_32 (Add)                    (None, 64, 64, 128)  0           add_31[0][0]                     \n",
      "                                                                 conv2d_99[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_97 (BatchNo (None, 64, 64, 128)  512         add_32[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "activation_97 (Activation)      (None, 64, 64, 128)  0           batch_normalization_97[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_100 (Conv2D)             (None, 64, 64, 64)   8256        activation_97[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_98 (BatchNo (None, 64, 64, 64)   256         conv2d_100[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "activation_98 (Activation)      (None, 64, 64, 64)   0           batch_normalization_98[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_101 (Conv2D)             (None, 64, 64, 64)   36928       activation_98[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_99 (BatchNo (None, 64, 64, 64)   256         conv2d_101[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "activation_99 (Activation)      (None, 64, 64, 64)   0           batch_normalization_99[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_102 (Conv2D)             (None, 64, 64, 128)  8320        activation_99[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "add_33 (Add)                    (None, 64, 64, 128)  0           add_32[0][0]                     \n",
      "                                                                 conv2d_102[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_100 (BatchN (None, 64, 64, 128)  512         add_33[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "activation_100 (Activation)     (None, 64, 64, 128)  0           batch_normalization_100[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_103 (Conv2D)             (None, 64, 64, 64)   8256        activation_100[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_101 (BatchN (None, 64, 64, 64)   256         conv2d_103[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "activation_101 (Activation)     (None, 64, 64, 64)   0           batch_normalization_101[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_104 (Conv2D)             (None, 64, 64, 64)   36928       activation_101[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_102 (BatchN (None, 64, 64, 64)   256         conv2d_104[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "activation_102 (Activation)     (None, 64, 64, 64)   0           batch_normalization_102[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_105 (Conv2D)             (None, 64, 64, 128)  8320        activation_102[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "add_34 (Add)                    (None, 64, 64, 128)  0           add_33[0][0]                     \n",
      "                                                                 conv2d_105[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_103 (BatchN (None, 64, 64, 128)  512         add_34[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "activation_103 (Activation)     (None, 64, 64, 128)  0           batch_normalization_103[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_106 (Conv2D)             (None, 64, 64, 64)   8256        activation_103[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_104 (BatchN (None, 64, 64, 64)   256         conv2d_106[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "activation_104 (Activation)     (None, 64, 64, 64)   0           batch_normalization_104[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_107 (Conv2D)             (None, 64, 64, 64)   36928       activation_104[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_105 (BatchN (None, 64, 64, 64)   256         conv2d_107[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "activation_105 (Activation)     (None, 64, 64, 64)   0           batch_normalization_105[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_108 (Conv2D)             (None, 64, 64, 128)  8320        activation_105[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "add_35 (Add)                    (None, 64, 64, 128)  0           add_34[0][0]                     \n",
      "                                                                 conv2d_108[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_106 (BatchN (None, 64, 64, 128)  512         add_35[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "activation_106 (Activation)     (None, 64, 64, 128)  0           batch_normalization_106[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_109 (Conv2D)             (None, 64, 64, 64)   8256        activation_106[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_107 (BatchN (None, 64, 64, 64)   256         conv2d_109[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "activation_107 (Activation)     (None, 64, 64, 64)   0           batch_normalization_107[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_110 (Conv2D)             (None, 64, 64, 64)   36928       activation_107[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_108 (BatchN (None, 64, 64, 64)   256         conv2d_110[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "activation_108 (Activation)     (None, 64, 64, 64)   0           batch_normalization_108[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_111 (Conv2D)             (None, 64, 64, 128)  8320        activation_108[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "add_36 (Add)                    (None, 64, 64, 128)  0           add_35[0][0]                     \n",
      "                                                                 conv2d_111[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_109 (BatchN (None, 64, 64, 128)  512         add_36[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "activation_109 (Activation)     (None, 64, 64, 128)  0           batch_normalization_109[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_112 (Conv2D)             (None, 64, 64, 64)   8256        activation_109[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_110 (BatchN (None, 64, 64, 64)   256         conv2d_112[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "activation_110 (Activation)     (None, 64, 64, 64)   0           batch_normalization_110[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_113 (Conv2D)             (None, 64, 64, 64)   36928       activation_110[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_111 (BatchN (None, 64, 64, 64)   256         conv2d_113[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "activation_111 (Activation)     (None, 64, 64, 64)   0           batch_normalization_111[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_114 (Conv2D)             (None, 64, 64, 128)  8320        activation_111[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "add_37 (Add)                    (None, 64, 64, 128)  0           add_36[0][0]                     \n",
      "                                                                 conv2d_114[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_112 (BatchN (None, 64, 64, 128)  512         add_37[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "activation_112 (Activation)     (None, 64, 64, 128)  0           batch_normalization_112[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_115 (Conv2D)             (None, 64, 64, 64)   8256        activation_112[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_113 (BatchN (None, 64, 64, 64)   256         conv2d_115[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "activation_113 (Activation)     (None, 64, 64, 64)   0           batch_normalization_113[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_116 (Conv2D)             (None, 64, 64, 64)   36928       activation_113[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_114 (BatchN (None, 64, 64, 64)   256         conv2d_116[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "activation_114 (Activation)     (None, 64, 64, 64)   0           batch_normalization_114[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_117 (Conv2D)             (None, 64, 64, 128)  8320        activation_114[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "add_38 (Add)                    (None, 64, 64, 128)  0           add_37[0][0]                     \n",
      "                                                                 conv2d_117[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_115 (BatchN (None, 64, 64, 128)  512         add_38[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "activation_115 (Activation)     (None, 64, 64, 128)  0           batch_normalization_115[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_118 (Conv2D)             (None, 64, 64, 64)   8256        activation_115[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_116 (BatchN (None, 64, 64, 64)   256         conv2d_118[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "activation_116 (Activation)     (None, 64, 64, 64)   0           batch_normalization_116[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_119 (Conv2D)             (None, 64, 64, 64)   36928       activation_116[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_117 (BatchN (None, 64, 64, 64)   256         conv2d_119[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "activation_117 (Activation)     (None, 64, 64, 64)   0           batch_normalization_117[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_120 (Conv2D)             (None, 64, 64, 128)  8320        activation_117[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "add_39 (Add)                    (None, 64, 64, 128)  0           add_38[0][0]                     \n",
      "                                                                 conv2d_120[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_118 (BatchN (None, 64, 64, 128)  512         add_39[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "activation_118 (Activation)     (None, 64, 64, 128)  0           batch_normalization_118[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_121 (Conv2D)             (None, 64, 64, 64)   8256        activation_118[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_119 (BatchN (None, 64, 64, 64)   256         conv2d_121[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "activation_119 (Activation)     (None, 64, 64, 64)   0           batch_normalization_119[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_122 (Conv2D)             (None, 64, 64, 64)   36928       activation_119[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_120 (BatchN (None, 64, 64, 64)   256         conv2d_122[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "activation_120 (Activation)     (None, 64, 64, 64)   0           batch_normalization_120[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_123 (Conv2D)             (None, 64, 64, 128)  8320        activation_120[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "add_40 (Add)                    (None, 64, 64, 128)  0           add_39[0][0]                     \n",
      "                                                                 conv2d_123[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_121 (BatchN (None, 64, 64, 128)  512         add_40[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "activation_121 (Activation)     (None, 64, 64, 128)  0           batch_normalization_121[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_124 (Conv2D)             (None, 64, 64, 64)   8256        activation_121[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_122 (BatchN (None, 64, 64, 64)   256         conv2d_124[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "activation_122 (Activation)     (None, 64, 64, 64)   0           batch_normalization_122[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_125 (Conv2D)             (None, 64, 64, 64)   36928       activation_122[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_123 (BatchN (None, 64, 64, 64)   256         conv2d_125[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "activation_123 (Activation)     (None, 64, 64, 64)   0           batch_normalization_123[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_126 (Conv2D)             (None, 64, 64, 128)  8320        activation_123[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "add_41 (Add)                    (None, 64, 64, 128)  0           add_40[0][0]                     \n",
      "                                                                 conv2d_126[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_124 (BatchN (None, 64, 64, 128)  512         add_41[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "activation_124 (Activation)     (None, 64, 64, 128)  0           batch_normalization_124[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_127 (Conv2D)             (None, 64, 64, 64)   8256        activation_124[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_125 (BatchN (None, 64, 64, 64)   256         conv2d_127[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "activation_125 (Activation)     (None, 64, 64, 64)   0           batch_normalization_125[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_128 (Conv2D)             (None, 64, 64, 64)   36928       activation_125[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_126 (BatchN (None, 64, 64, 64)   256         conv2d_128[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "activation_126 (Activation)     (None, 64, 64, 64)   0           batch_normalization_126[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_129 (Conv2D)             (None, 64, 64, 128)  8320        activation_126[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "add_42 (Add)                    (None, 64, 64, 128)  0           add_41[0][0]                     \n",
      "                                                                 conv2d_129[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_127 (BatchN (None, 64, 64, 128)  512         add_42[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "activation_127 (Activation)     (None, 64, 64, 128)  0           batch_normalization_127[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_130 (Conv2D)             (None, 64, 64, 64)   8256        activation_127[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_128 (BatchN (None, 64, 64, 64)   256         conv2d_130[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "activation_128 (Activation)     (None, 64, 64, 64)   0           batch_normalization_128[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_131 (Conv2D)             (None, 64, 64, 64)   36928       activation_128[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_129 (BatchN (None, 64, 64, 64)   256         conv2d_131[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "activation_129 (Activation)     (None, 64, 64, 64)   0           batch_normalization_129[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_132 (Conv2D)             (None, 64, 64, 128)  8320        activation_129[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "add_43 (Add)                    (None, 64, 64, 128)  0           add_42[0][0]                     \n",
      "                                                                 conv2d_132[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_130 (BatchN (None, 64, 64, 128)  512         add_43[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "activation_130 (Activation)     (None, 64, 64, 128)  0           batch_normalization_130[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_133 (Conv2D)             (None, 64, 64, 64)   8256        activation_130[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_131 (BatchN (None, 64, 64, 64)   256         conv2d_133[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "activation_131 (Activation)     (None, 64, 64, 64)   0           batch_normalization_131[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_134 (Conv2D)             (None, 64, 64, 64)   36928       activation_131[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_132 (BatchN (None, 64, 64, 64)   256         conv2d_134[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "activation_132 (Activation)     (None, 64, 64, 64)   0           batch_normalization_132[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_135 (Conv2D)             (None, 64, 64, 128)  8320        activation_132[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "add_44 (Add)                    (None, 64, 64, 128)  0           add_43[0][0]                     \n",
      "                                                                 conv2d_135[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_133 (BatchN (None, 64, 64, 128)  512         add_44[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "activation_133 (Activation)     (None, 64, 64, 128)  0           batch_normalization_133[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_136 (Conv2D)             (None, 64, 64, 64)   8256        activation_133[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_134 (BatchN (None, 64, 64, 64)   256         conv2d_136[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "activation_134 (Activation)     (None, 64, 64, 64)   0           batch_normalization_134[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_137 (Conv2D)             (None, 64, 64, 64)   36928       activation_134[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_135 (BatchN (None, 64, 64, 64)   256         conv2d_137[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "activation_135 (Activation)     (None, 64, 64, 64)   0           batch_normalization_135[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_138 (Conv2D)             (None, 64, 64, 128)  8320        activation_135[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "add_45 (Add)                    (None, 64, 64, 128)  0           add_44[0][0]                     \n",
      "                                                                 conv2d_138[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_136 (BatchN (None, 64, 64, 128)  512         add_45[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "activation_136 (Activation)     (None, 64, 64, 128)  0           batch_normalization_136[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_139 (Conv2D)             (None, 64, 64, 64)   8256        activation_136[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_137 (BatchN (None, 64, 64, 64)   256         conv2d_139[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "activation_137 (Activation)     (None, 64, 64, 64)   0           batch_normalization_137[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_140 (Conv2D)             (None, 64, 64, 64)   36928       activation_137[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_138 (BatchN (None, 64, 64, 64)   256         conv2d_140[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "activation_138 (Activation)     (None, 64, 64, 64)   0           batch_normalization_138[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_141 (Conv2D)             (None, 64, 64, 128)  8320        activation_138[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "add_46 (Add)                    (None, 64, 64, 128)  0           add_45[0][0]                     \n",
      "                                                                 conv2d_141[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_139 (BatchN (None, 64, 64, 128)  512         add_46[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "activation_139 (Activation)     (None, 64, 64, 128)  0           batch_normalization_139[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_142 (Conv2D)             (None, 64, 64, 64)   8256        activation_139[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_140 (BatchN (None, 64, 64, 64)   256         conv2d_142[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "activation_140 (Activation)     (None, 64, 64, 64)   0           batch_normalization_140[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_143 (Conv2D)             (None, 64, 64, 64)   36928       activation_140[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_141 (BatchN (None, 64, 64, 64)   256         conv2d_143[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "activation_141 (Activation)     (None, 64, 64, 64)   0           batch_normalization_141[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_144 (Conv2D)             (None, 64, 64, 128)  8320        activation_141[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "add_47 (Add)                    (None, 64, 64, 128)  0           add_46[0][0]                     \n",
      "                                                                 conv2d_144[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_142 (BatchN (None, 64, 64, 128)  512         add_47[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "activation_142 (Activation)     (None, 64, 64, 128)  0           batch_normalization_142[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_145 (Conv2D)             (None, 64, 64, 64)   8256        activation_142[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_143 (BatchN (None, 64, 64, 64)   256         conv2d_145[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "activation_143 (Activation)     (None, 64, 64, 64)   0           batch_normalization_143[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_146 (Conv2D)             (None, 64, 64, 64)   36928       activation_143[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_144 (BatchN (None, 64, 64, 64)   256         conv2d_146[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "activation_144 (Activation)     (None, 64, 64, 64)   0           batch_normalization_144[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_147 (Conv2D)             (None, 64, 64, 128)  8320        activation_144[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "add_48 (Add)                    (None, 64, 64, 128)  0           add_47[0][0]                     \n",
      "                                                                 conv2d_147[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_145 (BatchN (None, 64, 64, 128)  512         add_48[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "activation_145 (Activation)     (None, 64, 64, 128)  0           batch_normalization_145[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_148 (Conv2D)             (None, 64, 64, 64)   8256        activation_145[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_146 (BatchN (None, 64, 64, 64)   256         conv2d_148[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "activation_146 (Activation)     (None, 64, 64, 64)   0           batch_normalization_146[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_149 (Conv2D)             (None, 64, 64, 64)   36928       activation_146[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_147 (BatchN (None, 64, 64, 64)   256         conv2d_149[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "activation_147 (Activation)     (None, 64, 64, 64)   0           batch_normalization_147[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_150 (Conv2D)             (None, 64, 64, 128)  8320        activation_147[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "add_49 (Add)                    (None, 64, 64, 128)  0           add_48[0][0]                     \n",
      "                                                                 conv2d_150[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_148 (BatchN (None, 64, 64, 128)  512         add_49[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "activation_148 (Activation)     (None, 64, 64, 128)  0           batch_normalization_148[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_151 (Conv2D)             (None, 64, 64, 64)   8256        activation_148[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_149 (BatchN (None, 64, 64, 64)   256         conv2d_151[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "activation_149 (Activation)     (None, 64, 64, 64)   0           batch_normalization_149[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_152 (Conv2D)             (None, 64, 64, 64)   36928       activation_149[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_150 (BatchN (None, 64, 64, 64)   256         conv2d_152[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "activation_150 (Activation)     (None, 64, 64, 64)   0           batch_normalization_150[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_153 (Conv2D)             (None, 64, 64, 128)  8320        activation_150[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "add_50 (Add)                    (None, 64, 64, 128)  0           add_49[0][0]                     \n",
      "                                                                 conv2d_153[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_151 (BatchN (None, 64, 64, 128)  512         add_50[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "activation_151 (Activation)     (None, 64, 64, 128)  0           batch_normalization_151[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_154 (Conv2D)             (None, 64, 64, 64)   8256        activation_151[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_152 (BatchN (None, 64, 64, 64)   256         conv2d_154[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "activation_152 (Activation)     (None, 64, 64, 64)   0           batch_normalization_152[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_155 (Conv2D)             (None, 64, 64, 64)   36928       activation_152[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_153 (BatchN (None, 64, 64, 64)   256         conv2d_155[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "activation_153 (Activation)     (None, 64, 64, 64)   0           batch_normalization_153[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_156 (Conv2D)             (None, 64, 64, 128)  8320        activation_153[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "add_51 (Add)                    (None, 64, 64, 128)  0           add_50[0][0]                     \n",
      "                                                                 conv2d_156[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_154 (BatchN (None, 64, 64, 128)  512         add_51[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "activation_154 (Activation)     (None, 64, 64, 128)  0           batch_normalization_154[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_157 (Conv2D)             (None, 64, 64, 64)   8256        activation_154[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_155 (BatchN (None, 64, 64, 64)   256         conv2d_157[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "activation_155 (Activation)     (None, 64, 64, 64)   0           batch_normalization_155[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_158 (Conv2D)             (None, 64, 64, 64)   36928       activation_155[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_156 (BatchN (None, 64, 64, 64)   256         conv2d_158[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "activation_156 (Activation)     (None, 64, 64, 64)   0           batch_normalization_156[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_159 (Conv2D)             (None, 64, 64, 128)  8320        activation_156[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "add_52 (Add)                    (None, 64, 64, 128)  0           add_51[0][0]                     \n",
      "                                                                 conv2d_159[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_157 (BatchN (None, 64, 64, 128)  512         add_52[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "activation_157 (Activation)     (None, 64, 64, 128)  0           batch_normalization_157[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_160 (Conv2D)             (None, 64, 64, 64)   8256        activation_157[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_158 (BatchN (None, 64, 64, 64)   256         conv2d_160[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "activation_158 (Activation)     (None, 64, 64, 64)   0           batch_normalization_158[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_161 (Conv2D)             (None, 64, 64, 64)   36928       activation_158[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_159 (BatchN (None, 64, 64, 64)   256         conv2d_161[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "activation_159 (Activation)     (None, 64, 64, 64)   0           batch_normalization_159[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_162 (Conv2D)             (None, 64, 64, 128)  8320        activation_159[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "add_53 (Add)                    (None, 64, 64, 128)  0           add_52[0][0]                     \n",
      "                                                                 conv2d_162[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_160 (BatchN (None, 64, 64, 128)  512         add_53[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "activation_160 (Activation)     (None, 64, 64, 128)  0           batch_normalization_160[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_163 (Conv2D)             (None, 64, 64, 64)   8256        activation_160[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_161 (BatchN (None, 64, 64, 64)   256         conv2d_163[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "activation_161 (Activation)     (None, 64, 64, 64)   0           batch_normalization_161[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_164 (Conv2D)             (None, 64, 64, 64)   36928       activation_161[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_162 (BatchN (None, 64, 64, 64)   256         conv2d_164[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "activation_162 (Activation)     (None, 64, 64, 64)   0           batch_normalization_162[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_165 (Conv2D)             (None, 64, 64, 128)  8320        activation_162[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "add_54 (Add)                    (None, 64, 64, 128)  0           add_53[0][0]                     \n",
      "                                                                 conv2d_165[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_163 (BatchN (None, 64, 64, 128)  512         add_54[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "activation_163 (Activation)     (None, 64, 64, 128)  0           batch_normalization_163[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_166 (Conv2D)             (None, 64, 64, 64)   8256        activation_163[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_164 (BatchN (None, 64, 64, 64)   256         conv2d_166[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "activation_164 (Activation)     (None, 64, 64, 64)   0           batch_normalization_164[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_167 (Conv2D)             (None, 64, 64, 64)   36928       activation_164[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_165 (BatchN (None, 64, 64, 64)   256         conv2d_167[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "activation_165 (Activation)     (None, 64, 64, 64)   0           batch_normalization_165[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_168 (Conv2D)             (None, 64, 64, 128)  8320        activation_165[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "add_55 (Add)                    (None, 64, 64, 128)  0           add_54[0][0]                     \n",
      "                                                                 conv2d_168[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_166 (BatchN (None, 64, 64, 128)  512         add_55[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "activation_166 (Activation)     (None, 64, 64, 128)  0           batch_normalization_166[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_169 (Conv2D)             (None, 64, 64, 64)   8256        activation_166[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_167 (BatchN (None, 64, 64, 64)   256         conv2d_169[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "activation_167 (Activation)     (None, 64, 64, 64)   0           batch_normalization_167[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_170 (Conv2D)             (None, 64, 64, 64)   36928       activation_167[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_168 (BatchN (None, 64, 64, 64)   256         conv2d_170[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "activation_168 (Activation)     (None, 64, 64, 64)   0           batch_normalization_168[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_171 (Conv2D)             (None, 64, 64, 128)  8320        activation_168[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "add_56 (Add)                    (None, 64, 64, 128)  0           add_55[0][0]                     \n",
      "                                                                 conv2d_171[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_169 (BatchN (None, 64, 64, 128)  512         add_56[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "activation_169 (Activation)     (None, 64, 64, 128)  0           batch_normalization_169[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_172 (Conv2D)             (None, 64, 64, 64)   8256        activation_169[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_170 (BatchN (None, 64, 64, 64)   256         conv2d_172[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "activation_170 (Activation)     (None, 64, 64, 64)   0           batch_normalization_170[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_173 (Conv2D)             (None, 64, 64, 64)   36928       activation_170[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_171 (BatchN (None, 64, 64, 64)   256         conv2d_173[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "activation_171 (Activation)     (None, 64, 64, 64)   0           batch_normalization_171[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_174 (Conv2D)             (None, 64, 64, 128)  8320        activation_171[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "add_57 (Add)                    (None, 64, 64, 128)  0           add_56[0][0]                     \n",
      "                                                                 conv2d_174[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_172 (BatchN (None, 64, 64, 128)  512         add_57[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "activation_172 (Activation)     (None, 64, 64, 128)  0           batch_normalization_172[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_175 (Conv2D)             (None, 64, 64, 64)   8256        activation_172[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_173 (BatchN (None, 64, 64, 64)   256         conv2d_175[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "activation_173 (Activation)     (None, 64, 64, 64)   0           batch_normalization_173[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_176 (Conv2D)             (None, 64, 64, 64)   36928       activation_173[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_174 (BatchN (None, 64, 64, 64)   256         conv2d_176[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "activation_174 (Activation)     (None, 64, 64, 64)   0           batch_normalization_174[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_177 (Conv2D)             (None, 64, 64, 128)  8320        activation_174[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "add_58 (Add)                    (None, 64, 64, 128)  0           add_57[0][0]                     \n",
      "                                                                 conv2d_177[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_175 (BatchN (None, 64, 64, 128)  512         add_58[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "activation_175 (Activation)     (None, 64, 64, 128)  0           batch_normalization_175[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_178 (Conv2D)             (None, 32, 32, 128)  16512       activation_175[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_176 (BatchN (None, 32, 32, 128)  512         conv2d_178[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "activation_176 (Activation)     (None, 32, 32, 128)  0           batch_normalization_176[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_179 (Conv2D)             (None, 32, 32, 128)  147584      activation_176[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_177 (BatchN (None, 32, 32, 128)  512         conv2d_179[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "activation_177 (Activation)     (None, 32, 32, 128)  0           batch_normalization_177[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_181 (Conv2D)             (None, 32, 32, 256)  33024       add_58[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_180 (Conv2D)             (None, 32, 32, 256)  33024       activation_177[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "add_59 (Add)                    (None, 32, 32, 256)  0           conv2d_181[0][0]                 \n",
      "                                                                 conv2d_180[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_178 (BatchN (None, 32, 32, 256)  1024        add_59[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "activation_178 (Activation)     (None, 32, 32, 256)  0           batch_normalization_178[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_182 (Conv2D)             (None, 32, 32, 128)  32896       activation_178[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_179 (BatchN (None, 32, 32, 128)  512         conv2d_182[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "activation_179 (Activation)     (None, 32, 32, 128)  0           batch_normalization_179[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_183 (Conv2D)             (None, 32, 32, 128)  147584      activation_179[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_180 (BatchN (None, 32, 32, 128)  512         conv2d_183[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "activation_180 (Activation)     (None, 32, 32, 128)  0           batch_normalization_180[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_184 (Conv2D)             (None, 32, 32, 256)  33024       activation_180[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "add_60 (Add)                    (None, 32, 32, 256)  0           add_59[0][0]                     \n",
      "                                                                 conv2d_184[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_181 (BatchN (None, 32, 32, 256)  1024        add_60[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "activation_181 (Activation)     (None, 32, 32, 256)  0           batch_normalization_181[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_185 (Conv2D)             (None, 32, 32, 128)  32896       activation_181[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_182 (BatchN (None, 32, 32, 128)  512         conv2d_185[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "activation_182 (Activation)     (None, 32, 32, 128)  0           batch_normalization_182[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_186 (Conv2D)             (None, 32, 32, 128)  147584      activation_182[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_183 (BatchN (None, 32, 32, 128)  512         conv2d_186[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "activation_183 (Activation)     (None, 32, 32, 128)  0           batch_normalization_183[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_187 (Conv2D)             (None, 32, 32, 256)  33024       activation_183[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "add_61 (Add)                    (None, 32, 32, 256)  0           add_60[0][0]                     \n",
      "                                                                 conv2d_187[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_184 (BatchN (None, 32, 32, 256)  1024        add_61[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "activation_184 (Activation)     (None, 32, 32, 256)  0           batch_normalization_184[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_188 (Conv2D)             (None, 32, 32, 128)  32896       activation_184[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_185 (BatchN (None, 32, 32, 128)  512         conv2d_188[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "activation_185 (Activation)     (None, 32, 32, 128)  0           batch_normalization_185[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_189 (Conv2D)             (None, 32, 32, 128)  147584      activation_185[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_186 (BatchN (None, 32, 32, 128)  512         conv2d_189[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "activation_186 (Activation)     (None, 32, 32, 128)  0           batch_normalization_186[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_190 (Conv2D)             (None, 32, 32, 256)  33024       activation_186[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "add_62 (Add)                    (None, 32, 32, 256)  0           add_61[0][0]                     \n",
      "                                                                 conv2d_190[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_187 (BatchN (None, 32, 32, 256)  1024        add_62[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "activation_187 (Activation)     (None, 32, 32, 256)  0           batch_normalization_187[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_191 (Conv2D)             (None, 32, 32, 128)  32896       activation_187[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_188 (BatchN (None, 32, 32, 128)  512         conv2d_191[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "activation_188 (Activation)     (None, 32, 32, 128)  0           batch_normalization_188[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_192 (Conv2D)             (None, 32, 32, 128)  147584      activation_188[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_189 (BatchN (None, 32, 32, 128)  512         conv2d_192[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "activation_189 (Activation)     (None, 32, 32, 128)  0           batch_normalization_189[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_193 (Conv2D)             (None, 32, 32, 256)  33024       activation_189[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "add_63 (Add)                    (None, 32, 32, 256)  0           add_62[0][0]                     \n",
      "                                                                 conv2d_193[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_190 (BatchN (None, 32, 32, 256)  1024        add_63[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "activation_190 (Activation)     (None, 32, 32, 256)  0           batch_normalization_190[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_194 (Conv2D)             (None, 32, 32, 128)  32896       activation_190[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_191 (BatchN (None, 32, 32, 128)  512         conv2d_194[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "activation_191 (Activation)     (None, 32, 32, 128)  0           batch_normalization_191[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_195 (Conv2D)             (None, 32, 32, 128)  147584      activation_191[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_192 (BatchN (None, 32, 32, 128)  512         conv2d_195[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "activation_192 (Activation)     (None, 32, 32, 128)  0           batch_normalization_192[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_196 (Conv2D)             (None, 32, 32, 256)  33024       activation_192[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "add_64 (Add)                    (None, 32, 32, 256)  0           add_63[0][0]                     \n",
      "                                                                 conv2d_196[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_193 (BatchN (None, 32, 32, 256)  1024        add_64[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "activation_193 (Activation)     (None, 32, 32, 256)  0           batch_normalization_193[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_197 (Conv2D)             (None, 32, 32, 128)  32896       activation_193[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_194 (BatchN (None, 32, 32, 128)  512         conv2d_197[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "activation_194 (Activation)     (None, 32, 32, 128)  0           batch_normalization_194[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_198 (Conv2D)             (None, 32, 32, 128)  147584      activation_194[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_195 (BatchN (None, 32, 32, 128)  512         conv2d_198[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "activation_195 (Activation)     (None, 32, 32, 128)  0           batch_normalization_195[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_199 (Conv2D)             (None, 32, 32, 256)  33024       activation_195[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "add_65 (Add)                    (None, 32, 32, 256)  0           add_64[0][0]                     \n",
      "                                                                 conv2d_199[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_196 (BatchN (None, 32, 32, 256)  1024        add_65[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "activation_196 (Activation)     (None, 32, 32, 256)  0           batch_normalization_196[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_200 (Conv2D)             (None, 32, 32, 128)  32896       activation_196[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_197 (BatchN (None, 32, 32, 128)  512         conv2d_200[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "activation_197 (Activation)     (None, 32, 32, 128)  0           batch_normalization_197[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_201 (Conv2D)             (None, 32, 32, 128)  147584      activation_197[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_198 (BatchN (None, 32, 32, 128)  512         conv2d_201[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "activation_198 (Activation)     (None, 32, 32, 128)  0           batch_normalization_198[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_202 (Conv2D)             (None, 32, 32, 256)  33024       activation_198[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "add_66 (Add)                    (None, 32, 32, 256)  0           add_65[0][0]                     \n",
      "                                                                 conv2d_202[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_199 (BatchN (None, 32, 32, 256)  1024        add_66[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "activation_199 (Activation)     (None, 32, 32, 256)  0           batch_normalization_199[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_203 (Conv2D)             (None, 32, 32, 128)  32896       activation_199[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_200 (BatchN (None, 32, 32, 128)  512         conv2d_203[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "activation_200 (Activation)     (None, 32, 32, 128)  0           batch_normalization_200[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_204 (Conv2D)             (None, 32, 32, 128)  147584      activation_200[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_201 (BatchN (None, 32, 32, 128)  512         conv2d_204[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "activation_201 (Activation)     (None, 32, 32, 128)  0           batch_normalization_201[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_205 (Conv2D)             (None, 32, 32, 256)  33024       activation_201[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "add_67 (Add)                    (None, 32, 32, 256)  0           add_66[0][0]                     \n",
      "                                                                 conv2d_205[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_202 (BatchN (None, 32, 32, 256)  1024        add_67[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "activation_202 (Activation)     (None, 32, 32, 256)  0           batch_normalization_202[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_206 (Conv2D)             (None, 32, 32, 128)  32896       activation_202[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_203 (BatchN (None, 32, 32, 128)  512         conv2d_206[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "activation_203 (Activation)     (None, 32, 32, 128)  0           batch_normalization_203[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_207 (Conv2D)             (None, 32, 32, 128)  147584      activation_203[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_204 (BatchN (None, 32, 32, 128)  512         conv2d_207[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "activation_204 (Activation)     (None, 32, 32, 128)  0           batch_normalization_204[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_208 (Conv2D)             (None, 32, 32, 256)  33024       activation_204[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "add_68 (Add)                    (None, 32, 32, 256)  0           add_67[0][0]                     \n",
      "                                                                 conv2d_208[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_205 (BatchN (None, 32, 32, 256)  1024        add_68[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "activation_205 (Activation)     (None, 32, 32, 256)  0           batch_normalization_205[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_209 (Conv2D)             (None, 32, 32, 128)  32896       activation_205[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_206 (BatchN (None, 32, 32, 128)  512         conv2d_209[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "activation_206 (Activation)     (None, 32, 32, 128)  0           batch_normalization_206[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_210 (Conv2D)             (None, 32, 32, 128)  147584      activation_206[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_207 (BatchN (None, 32, 32, 128)  512         conv2d_210[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "activation_207 (Activation)     (None, 32, 32, 128)  0           batch_normalization_207[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_211 (Conv2D)             (None, 32, 32, 256)  33024       activation_207[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "add_69 (Add)                    (None, 32, 32, 256)  0           add_68[0][0]                     \n",
      "                                                                 conv2d_211[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_208 (BatchN (None, 32, 32, 256)  1024        add_69[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "activation_208 (Activation)     (None, 32, 32, 256)  0           batch_normalization_208[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_212 (Conv2D)             (None, 32, 32, 128)  32896       activation_208[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_209 (BatchN (None, 32, 32, 128)  512         conv2d_212[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "activation_209 (Activation)     (None, 32, 32, 128)  0           batch_normalization_209[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_213 (Conv2D)             (None, 32, 32, 128)  147584      activation_209[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_210 (BatchN (None, 32, 32, 128)  512         conv2d_213[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "activation_210 (Activation)     (None, 32, 32, 128)  0           batch_normalization_210[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_214 (Conv2D)             (None, 32, 32, 256)  33024       activation_210[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "add_70 (Add)                    (None, 32, 32, 256)  0           add_69[0][0]                     \n",
      "                                                                 conv2d_214[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_211 (BatchN (None, 32, 32, 256)  1024        add_70[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "activation_211 (Activation)     (None, 32, 32, 256)  0           batch_normalization_211[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_215 (Conv2D)             (None, 32, 32, 128)  32896       activation_211[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_212 (BatchN (None, 32, 32, 128)  512         conv2d_215[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "activation_212 (Activation)     (None, 32, 32, 128)  0           batch_normalization_212[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_216 (Conv2D)             (None, 32, 32, 128)  147584      activation_212[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_213 (BatchN (None, 32, 32, 128)  512         conv2d_216[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "activation_213 (Activation)     (None, 32, 32, 128)  0           batch_normalization_213[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_217 (Conv2D)             (None, 32, 32, 256)  33024       activation_213[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "add_71 (Add)                    (None, 32, 32, 256)  0           add_70[0][0]                     \n",
      "                                                                 conv2d_217[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_214 (BatchN (None, 32, 32, 256)  1024        add_71[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "activation_214 (Activation)     (None, 32, 32, 256)  0           batch_normalization_214[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_218 (Conv2D)             (None, 32, 32, 128)  32896       activation_214[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_215 (BatchN (None, 32, 32, 128)  512         conv2d_218[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "activation_215 (Activation)     (None, 32, 32, 128)  0           batch_normalization_215[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_219 (Conv2D)             (None, 32, 32, 128)  147584      activation_215[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_216 (BatchN (None, 32, 32, 128)  512         conv2d_219[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "activation_216 (Activation)     (None, 32, 32, 128)  0           batch_normalization_216[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_220 (Conv2D)             (None, 32, 32, 256)  33024       activation_216[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "add_72 (Add)                    (None, 32, 32, 256)  0           add_71[0][0]                     \n",
      "                                                                 conv2d_220[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_217 (BatchN (None, 32, 32, 256)  1024        add_72[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "activation_217 (Activation)     (None, 32, 32, 256)  0           batch_normalization_217[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_221 (Conv2D)             (None, 32, 32, 128)  32896       activation_217[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_218 (BatchN (None, 32, 32, 128)  512         conv2d_221[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "activation_218 (Activation)     (None, 32, 32, 128)  0           batch_normalization_218[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_222 (Conv2D)             (None, 32, 32, 128)  147584      activation_218[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_219 (BatchN (None, 32, 32, 128)  512         conv2d_222[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "activation_219 (Activation)     (None, 32, 32, 128)  0           batch_normalization_219[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_223 (Conv2D)             (None, 32, 32, 256)  33024       activation_219[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "add_73 (Add)                    (None, 32, 32, 256)  0           add_72[0][0]                     \n",
      "                                                                 conv2d_223[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_220 (BatchN (None, 32, 32, 256)  1024        add_73[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "activation_220 (Activation)     (None, 32, 32, 256)  0           batch_normalization_220[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_224 (Conv2D)             (None, 32, 32, 128)  32896       activation_220[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_221 (BatchN (None, 32, 32, 128)  512         conv2d_224[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "activation_221 (Activation)     (None, 32, 32, 128)  0           batch_normalization_221[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_225 (Conv2D)             (None, 32, 32, 128)  147584      activation_221[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_222 (BatchN (None, 32, 32, 128)  512         conv2d_225[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "activation_222 (Activation)     (None, 32, 32, 128)  0           batch_normalization_222[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_226 (Conv2D)             (None, 32, 32, 256)  33024       activation_222[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "add_74 (Add)                    (None, 32, 32, 256)  0           add_73[0][0]                     \n",
      "                                                                 conv2d_226[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_223 (BatchN (None, 32, 32, 256)  1024        add_74[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "activation_223 (Activation)     (None, 32, 32, 256)  0           batch_normalization_223[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_227 (Conv2D)             (None, 32, 32, 128)  32896       activation_223[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_224 (BatchN (None, 32, 32, 128)  512         conv2d_227[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "activation_224 (Activation)     (None, 32, 32, 128)  0           batch_normalization_224[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_228 (Conv2D)             (None, 32, 32, 128)  147584      activation_224[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_225 (BatchN (None, 32, 32, 128)  512         conv2d_228[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "activation_225 (Activation)     (None, 32, 32, 128)  0           batch_normalization_225[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_229 (Conv2D)             (None, 32, 32, 256)  33024       activation_225[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "add_75 (Add)                    (None, 32, 32, 256)  0           add_74[0][0]                     \n",
      "                                                                 conv2d_229[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_226 (BatchN (None, 32, 32, 256)  1024        add_75[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "activation_226 (Activation)     (None, 32, 32, 256)  0           batch_normalization_226[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_230 (Conv2D)             (None, 32, 32, 128)  32896       activation_226[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_227 (BatchN (None, 32, 32, 128)  512         conv2d_230[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "activation_227 (Activation)     (None, 32, 32, 128)  0           batch_normalization_227[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_231 (Conv2D)             (None, 32, 32, 128)  147584      activation_227[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_228 (BatchN (None, 32, 32, 128)  512         conv2d_231[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "activation_228 (Activation)     (None, 32, 32, 128)  0           batch_normalization_228[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_232 (Conv2D)             (None, 32, 32, 256)  33024       activation_228[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "add_76 (Add)                    (None, 32, 32, 256)  0           add_75[0][0]                     \n",
      "                                                                 conv2d_232[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_229 (BatchN (None, 32, 32, 256)  1024        add_76[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "activation_229 (Activation)     (None, 32, 32, 256)  0           batch_normalization_229[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_233 (Conv2D)             (None, 32, 32, 128)  32896       activation_229[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_230 (BatchN (None, 32, 32, 128)  512         conv2d_233[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "activation_230 (Activation)     (None, 32, 32, 128)  0           batch_normalization_230[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_234 (Conv2D)             (None, 32, 32, 128)  147584      activation_230[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_231 (BatchN (None, 32, 32, 128)  512         conv2d_234[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "activation_231 (Activation)     (None, 32, 32, 128)  0           batch_normalization_231[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_235 (Conv2D)             (None, 32, 32, 256)  33024       activation_231[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "add_77 (Add)                    (None, 32, 32, 256)  0           add_76[0][0]                     \n",
      "                                                                 conv2d_235[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_232 (BatchN (None, 32, 32, 256)  1024        add_77[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "activation_232 (Activation)     (None, 32, 32, 256)  0           batch_normalization_232[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_236 (Conv2D)             (None, 32, 32, 128)  32896       activation_232[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_233 (BatchN (None, 32, 32, 128)  512         conv2d_236[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "activation_233 (Activation)     (None, 32, 32, 128)  0           batch_normalization_233[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_237 (Conv2D)             (None, 32, 32, 128)  147584      activation_233[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_234 (BatchN (None, 32, 32, 128)  512         conv2d_237[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "activation_234 (Activation)     (None, 32, 32, 128)  0           batch_normalization_234[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_238 (Conv2D)             (None, 32, 32, 256)  33024       activation_234[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "add_78 (Add)                    (None, 32, 32, 256)  0           add_77[0][0]                     \n",
      "                                                                 conv2d_238[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_235 (BatchN (None, 32, 32, 256)  1024        add_78[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "activation_235 (Activation)     (None, 32, 32, 256)  0           batch_normalization_235[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_239 (Conv2D)             (None, 32, 32, 128)  32896       activation_235[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_236 (BatchN (None, 32, 32, 128)  512         conv2d_239[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "activation_236 (Activation)     (None, 32, 32, 128)  0           batch_normalization_236[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_240 (Conv2D)             (None, 32, 32, 128)  147584      activation_236[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_237 (BatchN (None, 32, 32, 128)  512         conv2d_240[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "activation_237 (Activation)     (None, 32, 32, 128)  0           batch_normalization_237[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_241 (Conv2D)             (None, 32, 32, 256)  33024       activation_237[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "add_79 (Add)                    (None, 32, 32, 256)  0           add_78[0][0]                     \n",
      "                                                                 conv2d_241[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_238 (BatchN (None, 32, 32, 256)  1024        add_79[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "activation_238 (Activation)     (None, 32, 32, 256)  0           batch_normalization_238[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_242 (Conv2D)             (None, 32, 32, 128)  32896       activation_238[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_239 (BatchN (None, 32, 32, 128)  512         conv2d_242[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "activation_239 (Activation)     (None, 32, 32, 128)  0           batch_normalization_239[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_243 (Conv2D)             (None, 32, 32, 128)  147584      activation_239[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_240 (BatchN (None, 32, 32, 128)  512         conv2d_243[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "activation_240 (Activation)     (None, 32, 32, 128)  0           batch_normalization_240[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_244 (Conv2D)             (None, 32, 32, 256)  33024       activation_240[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "add_80 (Add)                    (None, 32, 32, 256)  0           add_79[0][0]                     \n",
      "                                                                 conv2d_244[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_241 (BatchN (None, 32, 32, 256)  1024        add_80[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "activation_241 (Activation)     (None, 32, 32, 256)  0           batch_normalization_241[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_245 (Conv2D)             (None, 32, 32, 128)  32896       activation_241[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_242 (BatchN (None, 32, 32, 128)  512         conv2d_245[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "activation_242 (Activation)     (None, 32, 32, 128)  0           batch_normalization_242[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_246 (Conv2D)             (None, 32, 32, 128)  147584      activation_242[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_243 (BatchN (None, 32, 32, 128)  512         conv2d_246[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "activation_243 (Activation)     (None, 32, 32, 128)  0           batch_normalization_243[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_247 (Conv2D)             (None, 32, 32, 256)  33024       activation_243[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "add_81 (Add)                    (None, 32, 32, 256)  0           add_80[0][0]                     \n",
      "                                                                 conv2d_247[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_244 (BatchN (None, 32, 32, 256)  1024        add_81[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "activation_244 (Activation)     (None, 32, 32, 256)  0           batch_normalization_244[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_248 (Conv2D)             (None, 32, 32, 128)  32896       activation_244[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_245 (BatchN (None, 32, 32, 128)  512         conv2d_248[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "activation_245 (Activation)     (None, 32, 32, 128)  0           batch_normalization_245[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_249 (Conv2D)             (None, 32, 32, 128)  147584      activation_245[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_246 (BatchN (None, 32, 32, 128)  512         conv2d_249[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "activation_246 (Activation)     (None, 32, 32, 128)  0           batch_normalization_246[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_250 (Conv2D)             (None, 32, 32, 256)  33024       activation_246[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "add_82 (Add)                    (None, 32, 32, 256)  0           add_81[0][0]                     \n",
      "                                                                 conv2d_250[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_247 (BatchN (None, 32, 32, 256)  1024        add_82[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "activation_247 (Activation)     (None, 32, 32, 256)  0           batch_normalization_247[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_251 (Conv2D)             (None, 32, 32, 128)  32896       activation_247[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_248 (BatchN (None, 32, 32, 128)  512         conv2d_251[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "activation_248 (Activation)     (None, 32, 32, 128)  0           batch_normalization_248[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_252 (Conv2D)             (None, 32, 32, 128)  147584      activation_248[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_249 (BatchN (None, 32, 32, 128)  512         conv2d_252[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "activation_249 (Activation)     (None, 32, 32, 128)  0           batch_normalization_249[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_253 (Conv2D)             (None, 32, 32, 256)  33024       activation_249[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "add_83 (Add)                    (None, 32, 32, 256)  0           add_82[0][0]                     \n",
      "                                                                 conv2d_253[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_250 (BatchN (None, 32, 32, 256)  1024        add_83[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "activation_250 (Activation)     (None, 32, 32, 256)  0           batch_normalization_250[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_254 (Conv2D)             (None, 32, 32, 128)  32896       activation_250[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_251 (BatchN (None, 32, 32, 128)  512         conv2d_254[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "activation_251 (Activation)     (None, 32, 32, 128)  0           batch_normalization_251[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_255 (Conv2D)             (None, 32, 32, 128)  147584      activation_251[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_252 (BatchN (None, 32, 32, 128)  512         conv2d_255[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "activation_252 (Activation)     (None, 32, 32, 128)  0           batch_normalization_252[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_256 (Conv2D)             (None, 32, 32, 256)  33024       activation_252[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "add_84 (Add)                    (None, 32, 32, 256)  0           add_83[0][0]                     \n",
      "                                                                 conv2d_256[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_253 (BatchN (None, 32, 32, 256)  1024        add_84[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "activation_253 (Activation)     (None, 32, 32, 256)  0           batch_normalization_253[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_257 (Conv2D)             (None, 32, 32, 128)  32896       activation_253[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_254 (BatchN (None, 32, 32, 128)  512         conv2d_257[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "activation_254 (Activation)     (None, 32, 32, 128)  0           batch_normalization_254[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_258 (Conv2D)             (None, 32, 32, 128)  147584      activation_254[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_255 (BatchN (None, 32, 32, 128)  512         conv2d_258[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "activation_255 (Activation)     (None, 32, 32, 128)  0           batch_normalization_255[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_259 (Conv2D)             (None, 32, 32, 256)  33024       activation_255[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "add_85 (Add)                    (None, 32, 32, 256)  0           add_84[0][0]                     \n",
      "                                                                 conv2d_259[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_256 (BatchN (None, 32, 32, 256)  1024        add_85[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "activation_256 (Activation)     (None, 32, 32, 256)  0           batch_normalization_256[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_260 (Conv2D)             (None, 32, 32, 128)  32896       activation_256[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_257 (BatchN (None, 32, 32, 128)  512         conv2d_260[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "activation_257 (Activation)     (None, 32, 32, 128)  0           batch_normalization_257[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_261 (Conv2D)             (None, 32, 32, 128)  147584      activation_257[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_258 (BatchN (None, 32, 32, 128)  512         conv2d_261[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "activation_258 (Activation)     (None, 32, 32, 128)  0           batch_normalization_258[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_262 (Conv2D)             (None, 32, 32, 256)  33024       activation_258[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "add_86 (Add)                    (None, 32, 32, 256)  0           add_85[0][0]                     \n",
      "                                                                 conv2d_262[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_259 (BatchN (None, 32, 32, 256)  1024        add_86[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "activation_259 (Activation)     (None, 32, 32, 256)  0           batch_normalization_259[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_263 (Conv2D)             (None, 32, 32, 128)  32896       activation_259[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_260 (BatchN (None, 32, 32, 128)  512         conv2d_263[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "activation_260 (Activation)     (None, 32, 32, 128)  0           batch_normalization_260[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_264 (Conv2D)             (None, 32, 32, 128)  147584      activation_260[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_261 (BatchN (None, 32, 32, 128)  512         conv2d_264[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "activation_261 (Activation)     (None, 32, 32, 128)  0           batch_normalization_261[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_265 (Conv2D)             (None, 32, 32, 256)  33024       activation_261[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "add_87 (Add)                    (None, 32, 32, 256)  0           add_86[0][0]                     \n",
      "                                                                 conv2d_265[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_262 (BatchN (None, 32, 32, 256)  1024        add_87[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "activation_262 (Activation)     (None, 32, 32, 256)  0           batch_normalization_262[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "average_pooling2d_1 (AveragePoo (None, 4, 4, 256)    0           activation_262[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "flatten_1 (Flatten)             (None, 4096)         0           average_pooling2d_1[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "dense_1 (Dense)                 (None, 10)           40970       flatten_1[0][0]                  \n",
      "==================================================================================================\n",
      "Total params: 8,035,114\n",
      "Trainable params: 7,984,970\n",
      "Non-trainable params: 50,144\n",
      "__________________________________________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "depth =  depth * 9 + 2\n",
    "resnetModel = resnet((128, 128, 3), depth, n_classes)\n",
    "resnetModel.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/25\n"
     ]
    }
   ],
   "source": [
    "optimizer = Adam()\n",
    "resnetModel.compile(loss='categorical_crossentropy', optimizer=optimizer, metrics=['accuracy'])\n",
    "resnetModel.fit(X_train,y_train, epochs=25, batch_size=32, verbose=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.models import load_model\n",
    "# resnetModel.save('1rst_resnet_80perc_traindata.h5')  # creates a HDF5 file 'my_model.h5'\n",
    "resnetModel.save('2d_resnet_100perc_traindata.h5')\n",
    "del resnetModel\n",
    "# returns a compiled model\n",
    "# identical to the previous one\n",
    "# model = load_model('1rst_resnet_80perc_traindata.h5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'resnetModel' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-34-6c84e64413a2>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[1;32m----> 1\u001b[1;33m \u001b[0mresnetModel\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mevaluate\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mX_test\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0my_test\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m: name 'resnetModel' is not defined"
     ]
    }
   ],
   "source": [
    "resnetModel.evaluate(X_test, y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1023, 128, 128, 3)"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dir_test = 'test_images'\n",
    "extension='jpg'\n",
    "\n",
    "paths_test = []\n",
    "# print(listdir(dir_test))\n",
    "for f in listdir(dir_test):\n",
    "    if isfile(join(dir_test,f)):\n",
    "        path = join(dir_test,f)\n",
    "        number = f.split('_')[1]\n",
    "        number = int(number.split('.')[0])\n",
    "        paths_test.append((number, path)) \n",
    "paths_test.sort(key= lambda file: file[0])\n",
    "\n",
    "imgs_test = []\n",
    "for _, path in paths_test:\n",
    "    image_to_predict = Image.open(path).convert(\"RGB\")\n",
    "    image_to_predict=np.asarray(image_to_predict)\n",
    "    imgs_test.append(image_to_predict)\n",
    "\n",
    "X_kaggle= np.array(imgs_test)/255.0\n",
    "X_kaggle.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_kaggle = resnetModel.predict(X_kaggle)\n",
    "y_kaggle = y_kaggle.argmax(axis=-1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "inv_labels = {v: k for k, v in labels.items()}\n",
    "\n",
    "ids = [f'test_{i[0]}' for i in paths_test]\n",
    "\n",
    "data_kaggle = pd.DataFrame({'Id': ids , 'Expected':y_kaggle})\n",
    "data_kaggle['Expected'] = data_kaggle['Expected'].replace(inv_labels)\n",
    "data_kaggle.to_csv('1rst_try.csv', index=False)"
   ]
  }
 ],
 "metadata": {
  "colab": {
   "collapsed_sections": [],
   "name": "[ANN]Taller1.ipynb",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
